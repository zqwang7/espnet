<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.asr_transducer package &mdash; ESPnet 202308 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet2.st package" href="espnet2.st.html" />
    <link rel="prev" title="espnet2.asr package" href="espnet2.asr.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ESPnet
          </a>
              <div class="version">
                202308
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Common usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet1_tutorial.html">Usage</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_format_wav_scp.html">Converting audio file formats using format_wav_scp.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html">CMU 11492/11692 Spring 2023: Data preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html#Data-preparation-in-ESPnet">Data preparation in ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html">CMU 11492/11692 Spring 2023: Speech Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html">CMU 11492/11692 Spring 2023: Spoken Language Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html">CMU 11492/11692 Spring 2023: Text to Speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.asr_transducer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-espnet-transducer-model-1">espnet2.asr_transducer.espnet_transducer_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-beam-search-transducer-1">espnet2.asr_transducer.beam_search_transducer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-activation-1">espnet2.asr_transducer.activation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-error-calculator-1">espnet2.asr_transducer.error_calculator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-normalization-1">espnet2.asr_transducer.normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-joint-network-1">espnet2.asr_transducer.joint_network</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-utils-1">espnet2.asr_transducer.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-init-1">espnet2.asr_transducer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-abs-decoder-1">espnet2.asr_transducer.decoder.abs_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-stateless-decoder-1">espnet2.asr_transducer.decoder.stateless_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-rwkv-decoder-1">espnet2.asr_transducer.decoder.rwkv_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-rnn-decoder-1">espnet2.asr_transducer.decoder.rnn_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-mega-decoder-1">espnet2.asr_transducer.decoder.mega_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-init-1">espnet2.asr_transducer.decoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-blocks-mega-1">espnet2.asr_transducer.decoder.blocks.mega</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-blocks-rwkv-1">espnet2.asr_transducer.decoder.blocks.rwkv</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-blocks-init-1">espnet2.asr_transducer.decoder.blocks.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-init-1">espnet2.asr_transducer.decoder.modules.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-mega-feed-forward-1">espnet2.asr_transducer.decoder.modules.mega.feed_forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-mega-positional-bias-1">espnet2.asr_transducer.decoder.modules.mega.positional_bias</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-mega-multi-head-damped-ema-1">espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-mega-init-1">espnet2.asr_transducer.decoder.modules.mega.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-rwkv-feed-forward-1">espnet2.asr_transducer.decoder.modules.rwkv.feed_forward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-rwkv-attention-1">espnet2.asr_transducer.decoder.modules.rwkv.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-decoder-modules-rwkv-init-1">espnet2.asr_transducer.decoder.modules.rwkv.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-frontend-online-audio-processor-1">espnet2.asr_transducer.frontend.online_audio_processor</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-frontend-init-1">espnet2.asr_transducer.frontend.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-encoder-1">espnet2.asr_transducer.encoder.encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-validation-1">espnet2.asr_transducer.encoder.validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-building-1">espnet2.asr_transducer.encoder.building</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-init-1">espnet2.asr_transducer.encoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-conformer-1">espnet2.asr_transducer.encoder.blocks.conformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-conv1d-1">espnet2.asr_transducer.encoder.blocks.conv1d</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-ebranchformer-1">espnet2.asr_transducer.encoder.blocks.ebranchformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-branchformer-1">espnet2.asr_transducer.encoder.blocks.branchformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-init-1">espnet2.asr_transducer.encoder.blocks.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-blocks-conv-input-1">espnet2.asr_transducer.encoder.blocks.conv_input</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-multi-blocks-1">espnet2.asr_transducer.encoder.modules.multi_blocks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-positional-encoding-1">espnet2.asr_transducer.encoder.modules.positional_encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-attention-1">espnet2.asr_transducer.encoder.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-init-1">espnet2.asr_transducer.encoder.modules.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-encoder-modules-convolution-1">espnet2.asr_transducer.encoder.modules.convolution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asvspoof.html">espnet2.asvspoof package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_svs.html">espnet2.gan_svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.spk.html">espnet2.spk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">espnet2.asr_transducer package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet2.asr_transducer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="espnet2-asr-transducer-package">
<h1>espnet2.asr_transducer package<a class="headerlink" href="#espnet2-asr-transducer-package" title="Permalink to this headline">¶</a></h1>
<section id="espnet2-asr-transducer-espnet-transducer-model-1">
<span id="espnet2-asr-transducer-espnet-transducer-model"></span><h2>espnet2.asr_transducer.espnet_transducer_model<a class="headerlink" href="#espnet2-asr-transducer-espnet-transducer-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.espnet_transducer_model"></span><p>ESPnet2 ASR Transducer model.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.espnet_transducer_model.</code><code class="sig-name descname">ESPnetASRTransducerModel</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int, token_list: Union[Tuple[str, ...], List[str]], frontend: Optional[espnet2.asr.frontend.abs_frontend.AbsFrontend], specaug: Optional[espnet2.asr.specaug.abs_specaug.AbsSpecAug], normalize: Optional[espnet2.layers.abs_normalize.AbsNormalize], encoder: espnet2.asr_transducer.encoder.encoder.Encoder, decoder: espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder, joint_network: espnet2.asr_transducer.joint_network.JointNetwork, transducer_weight: float = 1.0, use_k2_pruned_loss: bool = False, k2_pruned_loss_args: Dict = {}, warmup_steps: int = 25000, validation_nstep: int = 2, fastemit_lambda: float = 0.0, auxiliary_ctc_weight: float = 0.0, auxiliary_ctc_dropout_rate: float = 0.0, auxiliary_lm_loss_weight: float = 0.0, auxiliary_lm_loss_smoothing: float = 0.05, ignore_id: int = -1, sym_space: str = '&lt;space&gt;', sym_blank: str = '&lt;blank&gt;', report_cer: bool = False, report_wer: bool = False, extract_feats_in_collect_stats: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_espnet_model.AbsESPnetModel" title="espnet2.train.abs_espnet_model.AbsESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_espnet_model.AbsESPnetModel</span></code></a></p>
<p>ESPnet2ASRTransducerModel module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Size of complete vocabulary (w/ SOS/EOS and blank included).</p></li>
<li><p><strong>token_list</strong> – List of tokens in vocabulary (minus reserved tokens).</p></li>
<li><p><strong>frontend</strong> – Frontend module.</p></li>
<li><p><strong>specaug</strong> – SpecAugment module.</p></li>
<li><p><strong>normalize</strong> – Normalization module.</p></li>
<li><p><strong>encoder</strong> – Encoder module.</p></li>
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint Network module.</p></li>
<li><p><strong>transducer_weight</strong> – Weight of the Transducer loss.</p></li>
<li><p><strong>use_k2_pruned_loss</strong> – Whether to use k2 pruned Transducer loss.</p></li>
<li><p><strong>k2_pruned_loss_args</strong> – Arguments of the k2 loss pruned Transducer loss.</p></li>
<li><p><strong>warmup_steps</strong> – Number of steps in warmup, used for pruned loss scaling.</p></li>
<li><p><strong>validation_nstep</strong> – Maximum number of symbol expansions at each time step
when reporting CER or/and WER using mAES.</p></li>
<li><p><strong>fastemit_lambda</strong> – FastEmit lambda value.</p></li>
<li><p><strong>auxiliary_ctc_weight</strong> – Weight of auxiliary CTC loss.</p></li>
<li><p><strong>auxiliary_ctc_dropout_rate</strong> – Dropout rate for auxiliary CTC loss inputs.</p></li>
<li><p><strong>auxiliary_lm_loss_weight</strong> – Weight of auxiliary LM loss.</p></li>
<li><p><strong>auxiliary_lm_loss_smoothing</strong> – Smoothing rate for LM loss’ label smoothing.</p></li>
<li><p><strong>ignore_id</strong> – Initial padding ID.</p></li>
<li><p><strong>sym_space</strong> – Space symbol.</p></li>
<li><p><strong>sym_blank</strong> – Blank Symbol.</p></li>
<li><p><strong>report_cer</strong> – Whether to report Character Error Rate during validation.</p></li>
<li><p><strong>report_wer</strong> – Whether to report Word Error Rate during validation.</p></li>
<li><p><strong>extract_feats_in_collect_stats</strong> – Whether to use extract_feats stats collection.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ESPnetASRTransducerModel object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect features sequences and features lengths sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – Speech sequences. (B, S)</p></li>
<li><p><strong>speech_lengths</strong> – Speech sequences lengths. (B,)</p></li>
<li><p><strong>text</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>text_lengths</strong> – Label ID sequences lengths. (B,)</p></li>
<li><p><strong>kwargs</strong> – Contains “utts_id”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>“feats”: Features sequences. (B, T, D_feats),</dt><dd><p>”feats_lengths”: Features sequences lengths. (B,)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>{}</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder speech sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – Speech sequences. (B, S)</p></li>
<li><p><strong>speech_lengths</strong> – Speech sequences lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Encoder outputs. (B, T, D_enc)
encoder_out_lens: Encoder outputs lengths. (B,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>encoder_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/espnet_transducer_model.html#ESPnetASRTransducerModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.espnet_transducer_model.ESPnetASRTransducerModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward architecture and compute loss(es).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – Speech sequences. (B, S)</p></li>
<li><p><strong>speech_lengths</strong> – Speech sequences lengths. (B,)</p></li>
<li><p><strong>text</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>text_lengths</strong> – Label ID sequences lengths. (B,)</p></li>
<li><p><strong>kwargs</strong> – Contains “utts_id”.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Main loss value.
stats: Task statistics.
weight: Task weights.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>loss</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-beam-search-transducer-1">
<span id="espnet2-asr-transducer-beam-search-transducer"></span><h2>espnet2.asr_transducer.beam_search_transducer<a class="headerlink" href="#espnet2-asr-transducer-beam-search-transducer-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.beam_search_transducer"></span><p>Search algorithms for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.beam_search_transducer.</code><code class="sig-name descname">BeamSearchTransducer</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</em>, <em class="sig-param">joint_network: espnet2.asr_transducer.joint_network.JointNetwork</em>, <em class="sig-param">beam_size: int</em>, <em class="sig-param">lm: Optional[torch.nn.modules.module.Module] = None</em>, <em class="sig-param">lm_weight: float = 0.1</em>, <em class="sig-param">search_type: str = 'default'</em>, <em class="sig-param">max_sym_exp: int = 3</em>, <em class="sig-param">u_max: int = 50</em>, <em class="sig-param">nstep: int = 2</em>, <em class="sig-param">expansion_gamma: float = 2.3</em>, <em class="sig-param">expansion_beta: int = 2</em>, <em class="sig-param">score_norm: bool = False</em>, <em class="sig-param">nbest: int = 1</em>, <em class="sig-param">streaming: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Beam search implementation for Transducer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint network module.</p></li>
<li><p><strong>beam_size</strong> – Size of the beam.</p></li>
<li><p><strong>lm</strong> – LM module.</p></li>
<li><p><strong>lm_weight</strong> – LM weight for soft fusion.</p></li>
<li><p><strong>search_type</strong> – Search algorithm to use during inference.</p></li>
<li><p><strong>max_sym_exp</strong> – Number of maximum symbol expansions at each time step. (TSD)</p></li>
<li><p><strong>u_max</strong> – Maximum expected target sequence length. (ALSD)</p></li>
<li><p><strong>nstep</strong> – Number of maximum expansion steps at each time step. (mAES)</p></li>
<li><p><strong>expansion_gamma</strong> – Allowed logp difference for prune-by-value method. (mAES)</p></li>
<li><p><strong>expansion_beta</strong> – Number of additional candidates for expanded hypotheses selection. (mAES)</p></li>
<li><p><strong>score_norm</strong> – Normalize final scores by length.</p></li>
<li><p><strong>nbest</strong> – Number of final hypothesis.</p></li>
<li><p><strong>streaming</strong> – Whether to perform chunk-by-chunk beam search.</p></li>
</ul>
</dd>
</dl>
<p>Construct a BeamSearchTransducer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding">
<code class="sig-name descname">align_length_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.align_length_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Alignment-length synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>h</strong> – Encoder output sequences. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.create_lm_batch_inputs">
<code class="sig-name descname">create_lm_batch_inputs</code><span class="sig-paren">(</span><em class="sig-param">hyps_seq: List[List[int]]</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.create_lm_batch_inputs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.create_lm_batch_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Make batch of inputs with left padding for LM scoring.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps_seq</strong> – Hypothesis sequences.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Padded batch of sequences.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.default_beam_search">
<code class="sig-name descname">default_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.default_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.default_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation without prefix search.</p>
<p>Modified from <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search">
<code class="sig-name descname">modified_adaptive_expansion_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.modified_adaptive_expansion_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Modified version of Adaptive Expansion Search (mAES).</p>
<dl class="simple">
<dt>Based on AES (<a class="reference external" href="https://ieeexplore.ieee.org/document/9250505">https://ieeexplore.ieee.org/document/9250505</a>) and</dt><dd><p>NSC (<a class="reference external" href="https://arxiv.org/abs/2201.05420">https://arxiv.org/abs/2201.05420</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.recombine_hyps">
<code class="sig-name descname">recombine_hyps</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.recombine_hyps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.recombine_hyps" title="Permalink to this definition">¶</a></dt>
<dd><p>Recombine hypotheses with same label ID sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Recombined hypotheses.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>final</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.reset_cache">
<code class="sig-name descname">reset_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.reset_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.reset_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset cache for streaming decoding.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.select_k_expansions">
<code class="sig-name descname">select_k_expansions</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis], topk_idx: torch.Tensor, topk_logp: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.select_k_expansions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.select_k_expansions" title="Permalink to this definition">¶</a></dt>
<dd><p>Return K hypotheses candidates for expansion from a list of hypothesis.</p>
<p>K candidates are selected according to the extended hypotheses probabilities
and a prune-by-value method. Where K is equal to beam_size + beta.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>topk_idx</strong> – Indices of candidates hypothesis.</p></li>
<li><p><strong>topk_logp</strong> – Log-probabilities of candidates hypothesis.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Best K expansion hypotheses candidates.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>k_expansions</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.sort_nbest">
<code class="sig-name descname">sort_nbest</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.sort_nbest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.sort_nbest" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort in-place hypotheses by score or score given sequence length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypothesis.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sorted hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.time_sync_decoding">
<code class="sig-name descname">time_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#BeamSearchTransducer.time_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.BeamSearchTransducer.time_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Time synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.beam_search_transducer.</code><code class="sig-name descname">ExtendedHypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]] = None, lm_state: Union[Dict[str, Any], List[Any], None] = None, dec_out: torch.Tensor = None, lm_score: torch.Tensor = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#ExtendedHypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis" title="espnet2.asr_transducer.beam_search_transducer.Hypothesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.beam_search_transducer.Hypothesis</span></code></a></p>
<p>Extended hypothesis definition for NSC beam search and mAES.</p>
<p>:param : Hypothesis dataclass arguments.
:param dec_out: Decoder output sequence. (B, D_dec)
:param lm_score: Log-probabilities of the LM for given label. (vocab_size)</p>
<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.dec_out">
<code class="sig-name descname">dec_out</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.dec_out" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.lm_score">
<code class="sig-name descname">lm_score</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.ExtendedHypothesis.lm_score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.beam_search_transducer.Hypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.beam_search_transducer.</code><code class="sig-name descname">Hypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Optional[Tuple[torch.Tensor, Optional[torch.Tensor]]] = None, lm_state: Union[Dict[str, Any], List[Any], None] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/beam_search_transducer.html#Hypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Default hypothesis definition for Transducer search algorithms.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> – Total log-probability.</p></li>
<li><p><strong>yseq</strong> – Label sequence as integer ID sequence.</p></li>
<li><p><strong>dec_state</strong> – RNN/MEGA Decoder state (None if Stateless).</p></li>
<li><p><strong>lm_state</strong> – RNNLM state. ((N, D_lm), (N, D_lm)) or None</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.Hypothesis.dec_state">
<code class="sig-name descname">dec_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis.dec_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr_transducer.beam_search_transducer.Hypothesis.lm_state">
<code class="sig-name descname">lm_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr_transducer.beam_search_transducer.Hypothesis.lm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-activation-1">
<span id="espnet2-asr-transducer-activation"></span><h2>espnet2.asr_transducer.activation<a class="headerlink" href="#espnet2-asr-transducer-activation-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.activation"></span><p>Activation functions for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.activation.FTSwish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">FTSwish</code><span class="sig-paren">(</span><em class="sig-param">threshold: float = -0.2</em>, <em class="sig-param">mean_shift: float = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#FTSwish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.FTSwish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Flatten-T Swish activation definition.</p>
<dl class="simple">
<dt>FTSwish(x) = x * sigmoid(x) + threshold</dt><dd><p>where FTSwish(x) &lt; 0 = threshold</p>
</dd>
</dl>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1812.06247">https://arxiv.org/abs/1812.06247</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> – Threshold value for FTSwish activation formulation. (threshold &lt; 0)</p></li>
<li><p><strong>mean_shift</strong> – Mean shifting value for FTSwish activation formulation.
(applied only if != 0, disabled by default)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.FTSwish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#FTSwish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.FTSwish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.activation.Mish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">Mish</code><span class="sig-paren">(</span><em class="sig-param">softplus_beta: float = 1.0</em>, <em class="sig-param">softplus_threshold: int = 20</em>, <em class="sig-param">use_builtin: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Mish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Mish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Mish activation definition.</p>
<p>Mish(x) = x * tanh(softplus(x))</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/abs/1908.08681">https://arxiv.org/abs/1908.08681</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>softplus_beta</strong> – Beta value for softplus activation formulation.
(Usually 0 &gt; softplus_beta &gt;= 2)</p></li>
<li><p><strong>softplus_threshold</strong> – Values above this revert to a linear function.
(Usually 10 &gt; softplus_threshold &gt;= 20)</p></li>
<li><p><strong>use_builtin</strong> – Whether to use PyTorch activation function if available.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.Mish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Mish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Mish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.activation.Smish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">Smish</code><span class="sig-paren">(</span><em class="sig-param">alpha: float = 1.0</em>, <em class="sig-param">beta: float = 1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Smish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Smish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Smish activation definition.</p>
<dl class="simple">
<dt>Smish(x) = (alpha * x) * tanh(log(1 + sigmoid(beta * x)))</dt><dd><p>where alpha &gt; 0 and beta &gt; 0</p>
</dd>
</dl>
<p>Reference: <a class="reference external" href="https://www.mdpi.com/2079-9292/11/4/540/htm">https://www.mdpi.com/2079-9292/11/4/540/htm</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> – Alpha value for Smish activation fomulation.
(Usually, alpha = 1. If alpha &lt;= 0, set value to 1).</p></li>
<li><p><strong>beta</strong> – Beta value for Smish activation formulation.
(Usually, beta = 1. If beta &lt;= 0, set value to 1).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.Smish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Smish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Smish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.activation.Swish">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">Swish</code><span class="sig-paren">(</span><em class="sig-param">beta: float = 1.0</em>, <em class="sig-param">use_builtin: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Swish"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Swish" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Swish activation definition.</p>
<dl class="simple">
<dt>Swish(x) = (beta * x) * sigmoid(x)</dt><dd><p>where beta = 1 defines standard Swish activation.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2108.12943">https://arxiv.org/abs/2108.12943</a> / <a class="reference external" href="https://arxiv.org/abs/1710.05941v1">https://arxiv.org/abs/1710.05941v1</a>.
E-swish variant: <a class="reference external" href="https://arxiv.org/abs/1801.07145">https://arxiv.org/abs/1801.07145</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beta</strong> – Beta parameter for E-Swish.
(beta &gt;= 1. If beta &lt; 1, use standard Swish).</p></li>
<li><p><strong>use_builtin</strong> – Whether to use PyTorch function if available.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr_transducer.activation.Swish.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#Swish.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.Swish.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.activation.get_activation">
<code class="sig-prename descclassname">espnet2.asr_transducer.activation.</code><code class="sig-name descname">get_activation</code><span class="sig-paren">(</span><em class="sig-param">activation_type: str</em>, <em class="sig-param">ftswish_threshold: float = -0.2</em>, <em class="sig-param">ftswish_mean_shift: float = 0.0</em>, <em class="sig-param">hardtanh_min_val: int = -1.0</em>, <em class="sig-param">hardtanh_max_val: int = 1.0</em>, <em class="sig-param">leakyrelu_neg_slope: float = 0.01</em>, <em class="sig-param">smish_alpha: float = 1.0</em>, <em class="sig-param">smish_beta: float = 1.0</em>, <em class="sig-param">softplus_beta: float = 1.0</em>, <em class="sig-param">softplus_threshold: int = 20</em>, <em class="sig-param">swish_beta: float = 1.0</em><span class="sig-paren">)</span> &#x2192; torch.nn.modules.module.Module<a class="reference internal" href="../_modules/espnet2/asr_transducer/activation.html#get_activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.activation.get_activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Return activation function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>activation_type</strong> – Activation function type.</p></li>
<li><p><strong>ftswish_threshold</strong> – Threshold value for FTSwish activation formulation.</p></li>
<li><p><strong>ftswish_mean_shift</strong> – Mean shifting value for FTSwish activation formulation.</p></li>
<li><p><strong>hardtanh_min_val</strong> – Minimum value of the linear region range for HardTanh.</p></li>
<li><p><strong>hardtanh_max_val</strong> – Maximum value of the linear region range for HardTanh.</p></li>
<li><p><strong>leakyrelu_neg_slope</strong> – Negative slope value for LeakyReLU activation formulation.</p></li>
<li><p><strong>smish_alpha</strong> – Alpha value for Smish activation fomulation.</p></li>
<li><p><strong>smish_beta</strong> – Beta value for Smish activation formulation.</p></li>
<li><p><strong>softplus_beta</strong> – Beta value for softplus activation formulation in Mish.</p></li>
<li><p><strong>softplus_threshold</strong> – Values above this revert to a linear function in Mish.</p></li>
<li><p><strong>swish_beta</strong> – Beta value for Swish variant formulation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Activation function.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-error-calculator-1">
<span id="espnet2-asr-transducer-error-calculator"></span><h2>espnet2.asr_transducer.error_calculator<a class="headerlink" href="#espnet2-asr-transducer-error-calculator-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.error_calculator"></span><p>Error Calculator module for Transducer.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.error_calculator.</code><code class="sig-name descname">ErrorCalculator</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder, joint_network: espnet2.asr_transducer.joint_network.JointNetwork, token_list: List[int], sym_space: str, sym_blank: str, nstep: int = 2, report_cer: bool = False, report_wer: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Calculate CER and WER for transducer models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint Network module.</p></li>
<li><p><strong>token_list</strong> – List of token units.</p></li>
<li><p><strong>sym_space</strong> – Space symbol.</p></li>
<li><p><strong>sym_blank</strong> – Blank symbol.</p></li>
<li><p><strong>nstep</strong> – Maximum number of symbol expansions at each time step w/ mAES.</p></li>
<li><p><strong>report_cer</strong> – Whether to compute CER.</p></li>
<li><p><strong>report_wer</strong> – Whether to compute WER.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ErrorCalculatorTransducer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_cer">
<code class="sig-name descname">calculate_cer</code><span class="sig-paren">(</span><em class="sig-param">char_pred: torch.Tensor</em>, <em class="sig-param">char_target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator.calculate_cer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_cer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level CER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>char_pred</strong> – Prediction character sequences. (B, ?)</p></li>
<li><p><strong>char_target</strong> – Target character sequences. (B, ?)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Average sentence-level CER score.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_wer">
<code class="sig-name descname">calculate_wer</code><span class="sig-paren">(</span><em class="sig-param">char_pred: torch.Tensor</em>, <em class="sig-param">char_target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator.calculate_wer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator.calculate_wer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level WER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>char_pred</strong> – Prediction character sequences. (B, ?)</p></li>
<li><p><strong>char_target</strong> – Target character sequences. (B, ?)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Average sentence-level WER score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.error_calculator.ErrorCalculator.convert_to_char">
<code class="sig-name descname">convert_to_char</code><span class="sig-paren">(</span><em class="sig-param">pred: torch.Tensor</em>, <em class="sig-param">target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[List, List]<a class="reference internal" href="../_modules/espnet2/asr_transducer/error_calculator.html#ErrorCalculator.convert_to_char"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.error_calculator.ErrorCalculator.convert_to_char" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert label ID sequences to character sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pred</strong> – Prediction label ID sequences. (B, U)</p></li>
<li><p><strong>target</strong> – Target label ID sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Prediction character sequences. (B, ?)
char_target: Target character sequences. (B, ?)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>char_pred</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-normalization-1">
<span id="espnet2-asr-transducer-normalization"></span><h2>espnet2.asr_transducer.normalization<a class="headerlink" href="#espnet2-asr-transducer-normalization-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.normalization"></span><p>Normalization modules for Transducer.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.normalization.BasicNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.normalization.</code><code class="sig-name descname">BasicNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape: int</em>, <em class="sig-param">eps: float = 0.25</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#BasicNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.BasicNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>BasicNorm module definition.</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/288">https://github.com/k2-fsa/icefall/pull/288</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> – Expected size.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator for numerical stability.</p></li>
</ul>
</dd>
</dl>
<p>Construct a BasicNorm object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.normalization.BasicNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#BasicNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.BasicNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute basic normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output sequences. (B, T, D_hidden)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.normalization.RMSNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.normalization.</code><code class="sig-name descname">RMSNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape: int</em>, <em class="sig-param">eps: float = 1e-05</em>, <em class="sig-param">partial: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#RMSNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.RMSNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RMSNorm module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/1910.07467.pdf">https://arxiv.org/pdf/1910.07467.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> – Expected size.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator for numerical stability.</p></li>
<li><p><strong>partial</strong> – Value defining the part of the input used for RMS stats.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RMSNorm object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.normalization.RMSNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#RMSNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.RMSNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute RMS normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.normalization.ScaleNorm">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.normalization.</code><code class="sig-name descname">ScaleNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape: int</em>, <em class="sig-param">eps: float = 1e-05</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#ScaleNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.ScaleNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ScaleNorm module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/1910.05895.pdf">https://arxiv.org/pdf/1910.05895.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> – Expected size.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator for numerical stability.</p></li>
</ul>
</dd>
</dl>
<p>Construct a ScaleNorm object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.normalization.ScaleNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#ScaleNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.ScaleNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute scale normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequences. (B, T, D_hidden)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output sequences. (B, T, D_hidden)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.normalization.get_normalization">
<code class="sig-prename descclassname">espnet2.asr_transducer.normalization.</code><code class="sig-name descname">get_normalization</code><span class="sig-paren">(</span><em class="sig-param">normalization_type: str</em>, <em class="sig-param">eps: Optional[float] = None</em>, <em class="sig-param">partial: Optional[float] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.nn.modules.module.Module, Dict]<a class="reference internal" href="../_modules/espnet2/asr_transducer/normalization.html#get_normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.normalization.get_normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Get normalization module and arguments given parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalization_type</strong> – Normalization module type.</p></li>
<li><p><strong>eps</strong> – Value added to the denominator.</p></li>
<li><p><strong>partial</strong> – Value defining the part of the input used for RMS stats (RMSNorm).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalization module class
: Normalization module arguments</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-joint-network-1">
<span id="espnet2-asr-transducer-joint-network"></span><h2>espnet2.asr_transducer.joint_network<a class="headerlink" href="#espnet2-asr-transducer-joint-network-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.joint_network"></span><p>Transducer joint network implementation.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.joint_network.JointNetwork">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.joint_network.</code><code class="sig-name descname">JointNetwork</code><span class="sig-paren">(</span><em class="sig-param">output_size: int</em>, <em class="sig-param">encoder_size: int</em>, <em class="sig-param">decoder_size: int</em>, <em class="sig-param">joint_space_size: int = 256</em>, <em class="sig-param">joint_activation_type: str = 'tanh'</em>, <em class="sig-param">lin_dec_bias: bool = True</em>, <em class="sig-param">**activation_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/joint_network.html#JointNetwork"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.joint_network.JointNetwork" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transducer joint network module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> – Output size.</p></li>
<li><p><strong>encoder_size</strong> – Encoder output size.</p></li>
<li><p><strong>decoder_size</strong> – Decoder output size.</p></li>
<li><p><strong>joint_space_size</strong> – Joint space size.</p></li>
<li><p><strong>joint_act_type</strong> – Type of activation for joint network.</p></li>
<li><p><strong>**activation_parameters</strong> – Parameters for the activation function.</p></li>
</ul>
</dd>
</dl>
<p>Construct a JointNetwork object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.joint_network.JointNetwork.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em>, <em class="sig-param">dec_out: torch.Tensor</em>, <em class="sig-param">no_projection: bool = False</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/joint_network.html#JointNetwork.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.joint_network.JointNetwork.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Joint computation of encoder and decoder hidden state sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>enc_out</strong> – Expanded encoder output state sequences.
(B, T, s_range, D_enc) or (B, T, 1, D_enc)</p></li>
<li><p><strong>dec_out</strong> – Expanded decoder output state sequences.
(B, T, s_range, D_dec) or (B, 1, U, D_dec)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Joint output state sequences.</dt><dd><p>(B, T, U, D_out) or (B, T, s_range, D_out)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>joint_out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-utils-1">
<span id="espnet2-asr-transducer-utils"></span><h2>espnet2.asr_transducer.utils<a class="headerlink" href="#espnet2-asr-transducer-utils-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.utils"></span><p>Utility functions for Transducer models.</p>
<dl class="exception">
<dt id="espnet2.asr_transducer.utils.TooShortUttError">
<em class="property">exception </em><code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">TooShortUttError</code><span class="sig-paren">(</span><em class="sig-param">message: str</em>, <em class="sig-param">actual_size: int</em>, <em class="sig-param">limit: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#TooShortUttError"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.TooShortUttError" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>Raised when the utt is too short for subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>message</strong> – Error message to display.</p></li>
<li><p><strong>actual_size</strong> – The size that cannot pass the subsampling.</p></li>
<li><p><strong>limit</strong> – The size limit for subsampling.</p></li>
</ul>
</dd>
</dl>
<p>Construct a TooShortUttError module.</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.check_short_utt">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">check_short_utt</code><span class="sig-paren">(</span><em class="sig-param">sub_factor: int</em>, <em class="sig-param">size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[bool, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#check_short_utt"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.check_short_utt" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if the input is too short for subsampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sub_factor</strong> – Subsampling factor for Conv2DSubsampling.</p></li>
<li><p><strong>size</strong> – Input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Whether an error should be sent.
: Size limit for specified subsampling factor.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.get_convinput_module_parameters">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">get_convinput_module_parameters</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">last_conv_size</em>, <em class="sig-param">subsampling_factor: int</em>, <em class="sig-param">is_vgg: bool = True</em><span class="sig-paren">)</span> &#x2192; Tuple[Union[Tuple[int, int], int], int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#get_convinput_module_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.get_convinput_module_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the convolution module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Module input size.</p></li>
<li><p><strong>last_conv_size</strong> – Last convolution size for module output size computation.</p></li>
<li><p><strong>subsampling_factor</strong> – Total subsampling factor.</p></li>
<li><p><strong>is_vgg</strong> – Whether the module type is VGG-like.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>First MaxPool2D kernel size or second Conv2d kernel size and stride.
output_size: Convolution module output size.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.get_transducer_task_io">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">get_transducer_task_io</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">encoder_out_lens: torch.Tensor</em>, <em class="sig-param">ignore_id: int = -1</em>, <em class="sig-param">blank_id: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#get_transducer_task_io"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.get_transducer_task_io" title="Permalink to this definition">¶</a></dt>
<dd><p>Get Transducer loss I/O.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>encoder_out_lens</strong> – Encoder output lengths. (B,)</p></li>
<li><p><strong>ignore_id</strong> – Padding symbol ID.</p></li>
<li><p><strong>blank_id</strong> – Blank symbol ID.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder inputs. (B, U)
target: Target label ID sequences. (B, U)
t_len: Time lengths. (B,)
u_len: Label lengths. (B,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>decoder_in</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.make_chunk_mask">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">make_chunk_mask</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">chunk_size: int</em>, <em class="sig-param">num_left_chunks: int = 0</em>, <em class="sig-param">device: torch.device = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#make_chunk_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.make_chunk_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create chunk mask for the subsequent steps (size, size).</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py">https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Size of the source mask.</p></li>
<li><p><strong>chunk_size</strong> – Number of frames in chunk.</p></li>
<li><p><strong>num_left_chunks</strong> – Number of left chunks the attention module can see.
(null or negative value means full context)</p></li>
<li><p><strong>device</strong> – Device for the mask tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Chunk mask. (size, size)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>mask</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.utils.make_source_mask">
<code class="sig-prename descclassname">espnet2.asr_transducer.utils.</code><code class="sig-name descname">make_source_mask</code><span class="sig-paren">(</span><em class="sig-param">lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/utils.html#make_source_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.utils.make_source_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create source mask for given lengths.</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py">https://github.com/k2-fsa/icefall/blob/master/icefall/utils.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>lengths</strong> – Sequence lengths. (B,)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mask for the sequence lengths. (B, max_len)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-init-1">
<span id="espnet2-asr-transducer-init"></span><h2>espnet2.asr_transducer.__init__<a class="headerlink" href="#espnet2-asr-transducer-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.__init__"></span></section>
<section id="espnet2-asr-transducer-decoder-abs-decoder-1">
<span id="espnet2-asr-transducer-decoder-abs-decoder"></span><h2>espnet2.asr_transducer.decoder.abs_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-abs-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.abs_decoder"></span><p>Abstract decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.abs_decoder.</code><code class="sig-name descname">AbsDecoder</code><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Abstract decoder module.</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.batch_score">
<em class="property">abstract </em><code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[Any]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch.Tensor]]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences.
states: Decoder hidden states.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.create_batch_states">
<em class="property">abstract </em><code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">new_states: List[Union[List[Dict[str, Optional[torch.Tensor]]], List[List[torch.Tensor]], Tuple[torch.Tensor, Optional[torch.Tensor]]]]</em><span class="sig-paren">)</span> &#x2192; Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create batch of decoder hidden states given a list of new states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_states</strong> – Decoder hidden states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>labels</strong> – Label ID sequences.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.init_state">
<em class="property">abstract </em><code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch._VariableFunctionsClass.tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.score">
<em class="property">abstract </em><code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label_sequence: List[int], states: Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch.Tensor]]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>state</strong> – Decoder hidden states.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequence.
state: Decoder hidden states.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.select_state">
<em class="property">abstract </em><code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch.Tensor]]], idx: int = 0</em><span class="sig-paren">)</span> &#x2192; Union[List[Dict[str, torch.Tensor]], List[torch.Tensor], Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from batch of states, if provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states.</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden state for given ID.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.set_device">
<em class="property">abstract </em><code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/abs_decoder.html#AbsDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-stateless-decoder-1">
<span id="espnet2-asr-transducer-decoder-stateless-decoder"></span><h2>espnet2.asr_transducer.decoder.stateless_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-stateless-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.stateless_decoder"></span><p>Stateless decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.stateless_decoder.</code><code class="sig-name descname">StatelessDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">embed_size: int = 256</em>, <em class="sig-param">embed_dropout_rate: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>Stateless Transducer decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Output size.</p></li>
<li><p><strong>embed_size</strong> – Embedding size.</p></li>
<li><p><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>embed_pad</strong> – Embed/Blank symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a StatelessDecoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, None]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
states: Decoder hidden states. None</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">new_states: List[Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_states</strong> – Decoder hidden states. [N x None]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. None</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">states: Optional[Any] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Label ID sequences. (B, L)</p></li>
<li><p><strong>states</strong> – Decoder hidden states. None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_emb)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>embed</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Initial decoder hidden states. None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label_sequence: List[int], states: Optional[Any] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, None]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>states</strong> – Decoder hidden states. None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequence. (1, D_emb)
state: Decoder hidden states. None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Optional[torch.Tensor], idx: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. None</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden state for given ID. None</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/stateless_decoder.html#StatelessDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.stateless_decoder.StatelessDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-rwkv-decoder-1">
<span id="espnet2-asr-transducer-decoder-rwkv-decoder"></span><h2>espnet2.asr_transducer.decoder.rwkv_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-rwkv-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.rwkv_decoder"></span><p>RWKV decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.rwkv_decoder.</code><code class="sig-name descname">RWKVDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">block_size: int = 512</em>, <em class="sig-param">context_size: int = 1024</em>, <em class="sig-param">linear_size: Optional[int] = None</em>, <em class="sig-param">attention_size: Optional[int] = None</em>, <em class="sig-param">normalization_type: str = 'layer_norm'</em>, <em class="sig-param">normalization_args: Dict = {}</em>, <em class="sig-param">num_blocks: int = 4</em>, <em class="sig-param">rescale_every: int = 0</em>, <em class="sig-param">embed_dropout_rate: float = 0.0</em>, <em class="sig-param">att_dropout_rate: float = 0.0</em>, <em class="sig-param">ffn_dropout_rate: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>RWKV decoder module.</p>
<p>Based on <a class="reference external" href="https://arxiv.org/pdf/2305.13048.pdf">https://arxiv.org/pdf/2305.13048.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Vocabulary size.</p></li>
<li><p><strong>block_size</strong> – Input/Output size.</p></li>
<li><p><strong>context_size</strong> – Context size for WKV computation.</p></li>
<li><p><strong>linear_size</strong> – FeedForward hidden size.</p></li>
<li><p><strong>attention_size</strong> – SelfAttention hidden size.</p></li>
<li><p><strong>normalization_type</strong> – Normalization layer type.</p></li>
<li><p><strong>normalization_args</strong> – Normalization layer arguments.</p></li>
<li><p><strong>num_blocks</strong> – Number of RWKV blocks.</p></li>
<li><p><strong>rescale_every</strong> – Whether to rescale input every N blocks (inference only).</p></li>
<li><p><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</p></li>
<li><p><strong>ffn_dropout_rate</strong> – Dropout rate for the feed-forward module.</p></li>
<li><p><strong>embed_pad</strong> – Embedding padding symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RWKVDecoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequence. (B, D_dec)
states: Decoder hidden states. [5 x (B, 1, D_att/D_dec, N)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">new_states: List[List[Dict[str, torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create batch of decoder hidden states given a list of new states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_states</strong> – Decoder hidden states. [B x [5 x (1, 1, D_att/D_dec, N)]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. [5 x (B, 1, D_att/D_dec, N)]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>labels</strong> – Decoder input sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">states: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Decoder input sequences. (B, L)</p></li>
<li><p><strong>states</strong> – Decoder hidden states. [5 x (B, D_att/D_dec, N)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)
states: Decoder hidden states. [5 x (B, D_att/D_dec, N)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int = 1</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize RWKVDecoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. [5 x (B, 1, D_att/D_dec, N)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label_sequence: List[int], states: List[torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>states</strong> – Decoder hidden states. [5 x (1, 1, D_att/D_dec, N)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequence. (D_dec)
states: Decoder hidden states. [5 x (1, 1, D_att/D_dec, N)]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: List[torch.Tensor], idx: int</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Select ID state from batch of decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>states</strong> – Decoder hidden states. [5 x (B, 1, D_att/D_dec, N)]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states for given ID. [5 x (1, 1, D_att/D_dec, N)]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rwkv_decoder.html#RWKVDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rwkv_decoder.RWKVDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-rnn-decoder-1">
<span id="espnet2-asr-transducer-decoder-rnn-decoder"></span><h2>espnet2.asr_transducer.decoder.rnn_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-rnn-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.rnn_decoder"></span><p>RNN decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.rnn_decoder.</code><code class="sig-name descname">RNNDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">embed_size: int = 256</em>, <em class="sig-param">hidden_size: int = 256</em>, <em class="sig-param">rnn_type: str = 'lstm'</em>, <em class="sig-param">num_layers: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">embed_dropout_rate: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>RNN decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Vocabulary size.</p></li>
<li><p><strong>embed_size</strong> – Embedding size.</p></li>
<li><p><strong>hidden_size</strong> – Hidden size..</p></li>
<li><p><strong>rnn_type</strong> – Decoder layers type.</p></li>
<li><p><strong>num_layers</strong> – Number of decoder layers.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for decoder layers.</p></li>
<li><p><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>embed_pad</strong> – Embedding padding symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RNNDecoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
states: Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">new_states: List[Tuple[torch.Tensor, Optional[torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_states</strong> – Decoder hidden states.
[B x ((N, 1, D_dec), (N, 1, D_dec) or None)]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>labels</strong> – Label ID sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch._VariableFunctionsClass.tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Initial decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor, state: Tuple[torch.Tensor, Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – RNN input sequences. (B, D_emb)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>RNN output sequences. (B, D_dec)
(h_next, c_next): Decoder hidden states.</p>
<blockquote>
<div><p>(N, B, D_dec), (N, B, D_dec) or None)</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label_sequence: List[int], states: Tuple[torch.Tensor, Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>states</strong> – Decoder hidden states.
((N, 1, D_dec), (N, 1, D_dec) or None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Decoder output sequence. (1, D_dec)
states: Decoder hidden states.</p>
<blockquote>
<div><p>((N, 1, D_dec), (N, 1, D_dec) or None)</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Tuple[torch.Tensor, Optional[torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec) or None)</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden state for given ID. ((N, 1, D_dec), (N, 1, D_dec) or None)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/rnn_decoder.html#RNNDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.rnn_decoder.RNNDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-mega-decoder-1">
<span id="espnet2-asr-transducer-decoder-mega-decoder"></span><h2>espnet2.asr_transducer.decoder.mega_decoder<a class="headerlink" href="#espnet2-asr-transducer-decoder-mega-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.mega_decoder"></span><p>MEGA decoder definition for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.mega_decoder.</code><code class="sig-name descname">MEGADecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">block_size: int = 512</em>, <em class="sig-param">linear_size: int = 1024</em>, <em class="sig-param">qk_size: int = 128</em>, <em class="sig-param">v_size: int = 1024</em>, <em class="sig-param">num_heads: int = 4</em>, <em class="sig-param">rel_pos_bias_type: str = 'simple'</em>, <em class="sig-param">max_positions: int = 2048</em>, <em class="sig-param">truncation_length: Optional[int] = None</em>, <em class="sig-param">normalization_type: str = 'layer_norm'</em>, <em class="sig-param">normalization_args: Dict = {}</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">activation_args: Dict = {}</em>, <em class="sig-param">chunk_size: int = -1</em>, <em class="sig-param">num_blocks: int = 4</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">embed_dropout_rate: float = 0.0</em>, <em class="sig-param">att_dropout_rate: float = 0.0</em>, <em class="sig-param">ema_dropout_rate: float = 0.0</em>, <em class="sig-param">ffn_dropout_rate: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder" title="espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr_transducer.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>MEGA decoder module.</p>
<p>Based on <a class="reference external" href="https://arxiv.org/pdf/2209.10655.pdf">https://arxiv.org/pdf/2209.10655.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Vocabulary size.</p></li>
<li><p><strong>block_size</strong> – Input/Output size.</p></li>
<li><p><strong>linear_size</strong> – NormalizedPositionwiseFeedForward hidden size.</p></li>
<li><p><strong>qk_size</strong> – Shared query and key size for attention module.</p></li>
<li><p><strong>v_size</strong> – Value size for attention module.</p></li>
<li><p><strong>num_heads</strong> – Number of EMA heads.</p></li>
<li><p><strong>rel_pos_bias</strong> – Type of relative position bias in attention module.</p></li>
<li><p><strong>max_positions</strong> – Maximum number of position for RelativePositionBias.</p></li>
<li><p><strong>truncation_length</strong> – Maximum length for truncation in EMA module.</p></li>
<li><p><strong>normalization_type</strong> – Normalization layer type.</p></li>
<li><p><strong>normalization_args</strong> – Normalization layer arguments.</p></li>
<li><p><strong>activation_type</strong> – Activation function type.</p></li>
<li><p><strong>activation_args</strong> – Activation function arguments.</p></li>
<li><p><strong>chunk_size</strong> – Chunk size for attention computation (-1 = full context).</p></li>
<li><p><strong>num_blocks</strong> – Number of MEGA blocks.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for MEGA internal modules.</p></li>
<li><p><strong>embed_dropout_rate</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</p></li>
<li><p><strong>ema_dropout_rate</strong> – Dropout rate for the EMA module.</p></li>
<li><p><strong>ffn_dropout_rate</strong> – Dropout rate for the feed-forward module.</p></li>
<li><p><strong>embed_pad</strong> – Embedding padding symbol ID.</p></li>
</ul>
</dd>
</dl>
<p>Construct a MEGADecoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr_transducer.beam_search_transducer.Hypothesis]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Dict[str, torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypotheses.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>states:</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">new_states: List[List[Dict[str, torch.Tensor]]]</em><span class="sig-paren">)</span> &#x2192; List[Dict[str, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create batch of decoder hidden states given a list of new states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_states</strong> – Decoder hidden states. [B x [N x Dict]]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. [N x Dict]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>labels</strong> – Decoder input sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.inference">
<code class="sig-name descname">inference</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor, states: List[Dict[str, torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Dict[str, torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – Decoder input sequences. (B, L)</p></li>
<li><p><strong>states</strong> – Decoder hidden states. [B x Dict]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, U, D_dec)
new_states: Decoder hidden states. [B x Dict]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int = 0</em><span class="sig-paren">)</span> &#x2192; List[Dict[str, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize MEGADecoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. [N x Dict]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">label_sequence: List[int], states: List[Dict[str, torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Dict[str, torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label_sequence</strong> – Current label sequence.</p></li>
<li><p><strong>states</strong> – Decoder hidden states. (??)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequence. (D_dec)
states: Decoder hidden states. (??)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: List[Dict[str, torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; List[Dict[str, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Select ID state from batch of decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>states</strong> – Decoder hidden states. [N x Dict]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states for given ID. [N x Dict]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.stack_qk_states">
<code class="sig-name descname">stack_qk_states</code><span class="sig-paren">(</span><em class="sig-param">state_list: List[torch.Tensor], dim: int</em><span class="sig-paren">)</span> &#x2192; List[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/mega_decoder.html#MEGADecoder.stack_qk_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.mega_decoder.MEGADecoder.stack_qk_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Stack query or key states with different lengths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state_list</strong> – List of query or key states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Query/Key state.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>new_state</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-init-1">
<span id="espnet2-asr-transducer-decoder-init"></span><h2>espnet2.asr_transducer.decoder.__init__<a class="headerlink" href="#espnet2-asr-transducer-decoder-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.__init__"></span></section>
<section id="espnet2-asr-transducer-decoder-blocks-mega-1">
<span id="espnet2-asr-transducer-decoder-blocks-mega"></span><h2>espnet2.asr_transducer.decoder.blocks.mega<a class="headerlink" href="#espnet2-asr-transducer-decoder-blocks-mega-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.blocks.mega"></span><p>Moving Average Equipped Gated Attention (MEGA) block definition.</p>
<p>Based/modified from <a class="reference external" href="https://github.com/facebookresearch/mega/blob/main/fairseq/modules/moving_average_gated_attention.py">https://github.com/facebookresearch/mega/blob/main/fairseq/modules/moving_average_gated_attention.py</a></p>
<p>Most variables are renamed according to <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/mega/modeling_mega.py">https://github.com/huggingface/transformers/blob/main/src/transformers/models/mega/modeling_mega.py</a>.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.blocks.mega.MEGA">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.blocks.mega.</code><code class="sig-name descname">MEGA</code><span class="sig-paren">(</span><em class="sig-param">size: int = 512</em>, <em class="sig-param">num_heads: int = 4</em>, <em class="sig-param">qk_size: int = 128</em>, <em class="sig-param">v_size: int = 1024</em>, <em class="sig-param">activation: torch.nn.modules.module.Module = ReLU()</em>, <em class="sig-param">normalization: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">rel_pos_bias_type: str = 'simple'</em>, <em class="sig-param">max_positions: int = 2048</em>, <em class="sig-param">truncation_length: Optional[int] = None</em>, <em class="sig-param">chunk_size: int = -1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">att_dropout_rate: float = 0.0</em>, <em class="sig-param">ema_dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/blocks/mega.html#MEGA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.blocks.mega.MEGA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MEGA module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Input/Output size.</p></li>
<li><p><strong>num_heads</strong> – Number of EMA heads.</p></li>
<li><p><strong>qk_size</strong> – Shared query and key size for attention module.</p></li>
<li><p><strong>v_size</strong> – Value size for attention module.</p></li>
<li><p><strong>qk_v_size</strong> – (QK, V) sizes for attention module.</p></li>
<li><p><strong>activation</strong> – Activation function type.</p></li>
<li><p><strong>normalization</strong> – Normalization module.</p></li>
<li><p><strong>rel_pos_bias_type</strong> – Type of relative position bias in attention module.</p></li>
<li><p><strong>max_positions</strong> – Maximum number of position for RelativePositionBias.</p></li>
<li><p><strong>truncation_length</strong> – Maximum length for truncation in EMA module.</p></li>
<li><p><strong>chunk_size</strong> – Chunk size for attention computation (-1 = full context).</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate for inner modules.</p></li>
<li><p><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</p></li>
<li><p><strong>ema_dropout_rate</strong> – Dropout rate for the EMA module.</p></li>
</ul>
</dd>
</dl>
<p>Construct a MEGA object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.blocks.mega.MEGA.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">attn_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">state: Optional[Dict[str</em>, <em class="sig-param">Optional[torch.Tensor]]] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[Dict[str, Optional[torch.Tensor]]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/blocks/mega.html#MEGA.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.blocks.mega.MEGA.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute moving average equiped gated attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MEGA input sequences. (L, B, size)</p></li>
<li><p><strong>mask</strong> – MEGA input sequence masks. (B, 1, L)</p></li>
<li><p><strong>attn_mask</strong> – MEGA attention mask. (1, L, L)</p></li>
<li><p><strong>state</strong> – Decoder hidden states.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>MEGA output sequences. (B, L, size)
state: Decoder hidden states.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.blocks.mega.MEGA.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">val: int = 0.0</em>, <em class="sig-param">std: int = 0.02</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/blocks/mega.html#MEGA.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.blocks.mega.MEGA.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>val</strong> – Initialization value.</p></li>
<li><p><strong>std</strong> – Standard deviation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.blocks.mega.MEGA.softmax_attention">
<code class="sig-name descname">softmax_attention</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">attn_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/blocks/mega.html#MEGA.softmax_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.blocks.mega.MEGA.softmax_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute attention weights with softmax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Query tensor. (B, 1, L, D)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, 1, L, D)</p></li>
<li><p><strong>mask</strong> – Sequence mask. (B, 1, L)</p></li>
<li><p><strong>attn_mask</strong> – Attention mask. (1, L, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attention weights. (B, 1, L, L)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>attn_weights</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-blocks-rwkv-1">
<span id="espnet2-asr-transducer-decoder-blocks-rwkv"></span><h2>espnet2.asr_transducer.decoder.blocks.rwkv<a class="headerlink" href="#espnet2-asr-transducer-decoder-blocks-rwkv-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.blocks.rwkv"></span><p>Receptance Weighted Key Value (RWKV) block definition.</p>
<p>Based/modified from <a class="reference external" href="https://github.com/BlinkDL/RWKV-LM/blob/main/RWKV-v4/src/model.py">https://github.com/BlinkDL/RWKV-LM/blob/main/RWKV-v4/src/model.py</a></p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.blocks.rwkv.RWKV">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.blocks.rwkv.</code><code class="sig-name descname">RWKV</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">linear_size: int</em>, <em class="sig-param">attention_size: int</em>, <em class="sig-param">context_size: int</em>, <em class="sig-param">block_id: int</em>, <em class="sig-param">num_blocks: int</em>, <em class="sig-param">normalization_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">normalization_args: Dict = {}</em>, <em class="sig-param">att_dropout_rate: float = 0.0</em>, <em class="sig-param">ffn_dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/blocks/rwkv.html#RWKV"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.blocks.rwkv.RWKV" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RWKV module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Input/Output size.</p></li>
<li><p><strong>linear_size</strong> – Feed-forward hidden size.</p></li>
<li><p><strong>attention_size</strong> – SelfAttention hidden size.</p></li>
<li><p><strong>context_size</strong> – Context size for WKV computation.</p></li>
<li><p><strong>block_id</strong> – Block index.</p></li>
<li><p><strong>num_blocks</strong> – Number of blocks in the architecture.</p></li>
<li><p><strong>normalization_class</strong> – Normalization layer class.</p></li>
<li><p><strong>normalization_args</strong> – Normalization layer arguments.</p></li>
<li><p><strong>att_dropout_rate</strong> – Dropout rate for the attention module.</p></li>
<li><p><strong>ffn_dropout_rate</strong> – Dropout rate for the feed-forward module.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RWKV object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.blocks.rwkv.RWKV.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">state: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/blocks/rwkv.html#RWKV.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.blocks.rwkv.RWKV.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute receptance weighted key value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – RWKV input sequences. (B, L, size)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. [5 x (B, D_att/size, N)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>RWKV output sequences. (B, L, size)
x: Decoder hidden states. [5 x (B, D_att/size, N)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-blocks-init-1">
<span id="espnet2-asr-transducer-decoder-blocks-init"></span><h2>espnet2.asr_transducer.decoder.blocks.__init__<a class="headerlink" href="#espnet2-asr-transducer-decoder-blocks-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.blocks.__init__"></span></section>
<section id="espnet2-asr-transducer-decoder-modules-init-1">
<span id="espnet2-asr-transducer-decoder-modules-init"></span><h2>espnet2.asr_transducer.decoder.modules.__init__<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.__init__"></span></section>
<section id="espnet2-asr-transducer-decoder-modules-mega-feed-forward-1">
<span id="espnet2-asr-transducer-decoder-modules-mega-feed-forward"></span><h2>espnet2.asr_transducer.decoder.modules.mega.feed_forward<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-mega-feed-forward-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.mega.feed_forward"></span><p>Normalized position-wise feed-forward module for MEGA block.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.mega.feed_forward.</code><code class="sig-name descname">NormalizedPositionwiseFeedForward</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">hidden_size: int</em>, <em class="sig-param">normalization: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">activation: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.activation.ReLU'&gt;</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/feed_forward.html#NormalizedPositionwiseFeedForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>NormalizedPositionFeedForward module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Input/Output size.</p></li>
<li><p><strong>hidden_size</strong> – Hidden size.</p></li>
<li><p><strong>normalization</strong> – Normalization module.</p></li>
<li><p><strong>activation</strong> – Activation function.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an NormalizedPositionwiseFeedForward object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/feed_forward.html#NormalizedPositionwiseFeedForward.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute feed-forward module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – NormalizedPositionwiseFeedForward input sequences. (B, L, size)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>NormalizedPositionwiseFeedForward output sequences. (B, L, size)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">val: float = 0.0</em>, <em class="sig-param">std: float = 0.02</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/feed_forward.html#NormalizedPositionwiseFeedForward.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.feed_forward.NormalizedPositionwiseFeedForward.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>val</strong> – Initialization value.</p></li>
<li><p><strong>std</strong> – Standard deviation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-modules-mega-positional-bias-1">
<span id="espnet2-asr-transducer-decoder-modules-mega-positional-bias"></span><h2>espnet2.asr_transducer.decoder.modules.mega.positional_bias<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-mega-positional-bias-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.mega.positional_bias"></span><p>Positional bias related modules.</p>
<p>Based/modified from <a class="reference external" href="https://github.com/facebookresearch/mega/blob/main/fairseq/modules/relative_positional_bias.py">https://github.com/facebookresearch/mega/blob/main/fairseq/modules/relative_positional_bias.py</a></p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.mega.positional_bias.</code><code class="sig-name descname">RelativePositionBias</code><span class="sig-paren">(</span><em class="sig-param">max_positions: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RelativePositionBias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RelativePositionBias module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>max_positions</strong> – Maximum number of relative positions.</p>
</dd>
</dl>
<p>Construct a RelativePositionBias object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">length: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RelativePositionBias.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute relative position bias.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>length</strong> – Sequence length.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Relative position bias. (L, L)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tile</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">val: float = 0.0</em>, <em class="sig-param">std: float = 0.02</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RelativePositionBias.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RelativePositionBias.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>val</strong> – Initialization value.</p></li>
<li><p><strong>std</strong> – Standard deviation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.mega.positional_bias.</code><code class="sig-name descname">RotaryRelativePositionBias</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">max_positions: int = 2048</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RotaryRelativePositionBias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RotaryRelativePositionBias module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Module embedding size.</p></li>
<li><p><strong>max_positions</strong> – Maximum number of relative positions.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RotaryRelativePositionBias object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">length: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RotaryRelativePositionBias.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute rotary relative position bias.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>length</strong> – Sequence length.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Rotary relative position bias. (L, L)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bias</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.get_sinusoid_embeddings">
<em class="property">static </em><code class="sig-name descname">get_sinusoid_embeddings</code><span class="sig-paren">(</span><em class="sig-param">max_positions: int</em>, <em class="sig-param">size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RotaryRelativePositionBias.get_sinusoid_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.get_sinusoid_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute sinusoidal positional embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_positions</strong> – Maximum number of positions.</p></li>
<li><p><strong>size</strong> – Input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sine elements. (max_positions, size // 2)
: Cos elements. (max_positions, size // 2)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">val: float = 0.0</em>, <em class="sig-param">std: float = 0.02</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RotaryRelativePositionBias.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>val</strong> – Initialization value.</p></li>
<li><p><strong>std</strong> – Standard deviation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.rotary">
<code class="sig-name descname">rotary</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/positional_bias.html#RotaryRelativePositionBias.rotary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.positional_bias.RotaryRelativePositionBias.rotary" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute rotary positional embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Input sequence. (L, size)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Rotary positional embeddings.  (L, size)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-modules-mega-multi-head-damped-ema-1">
<span id="espnet2-asr-transducer-decoder-modules-mega-multi-head-damped-ema"></span><h2>espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-mega-multi-head-damped-ema-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema"></span><p>Multi-head Damped Exponential Moving Average (EMA) module for MEGA block.</p>
<p>Based/modified from <a class="reference external" href="https://github.com/facebookresearch/mega/blob/main/fairseq/modules/moving_average_gated_attention.py">https://github.com/facebookresearch/mega/blob/main/fairseq/modules/moving_average_gated_attention.py</a></p>
<p>Most variables are renamed according to <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/mega/modeling_mega.py">https://github.com/huggingface/transformers/blob/main/src/transformers/models/mega/modeling_mega.py</a>.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.</code><code class="sig-name descname">MultiHeadDampedEMA</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">num_heads: int = 4</em>, <em class="sig-param">activation: torch.nn.modules.module.Module = ReLU()</em>, <em class="sig-param">truncation_length: Optional[int] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MultiHeadDampedEMA module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Module size.</p></li>
<li><p><strong>num_heads</strong> – Number of attention heads.</p></li>
<li><p><strong>activation</strong> – Activation function type.</p></li>
<li><p><strong>truncation_length</strong> – Maximum length for truncation.</p></li>
</ul>
</dd>
</dl>
<p>Construct an MultiHeadDampedEMA object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.compute_ema_coefficients">
<code class="sig-name descname">compute_ema_coefficients</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA.compute_ema_coefficients"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.compute_ema_coefficients" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute EMA coefficients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>None</strong> – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Damping factor / P-th order coefficient.</dt><dd><p>(size, num_heads, 1)</p>
</dd>
<dt>prev_timestep_weight: Previous timestep weight / Q-th order coefficient.</dt><dd><p>(size, num_heads, 1)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>damping_factor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.compute_ema_kernel">
<code class="sig-name descname">compute_ema_kernel</code><span class="sig-paren">(</span><em class="sig-param">length: int</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA.compute_ema_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.compute_ema_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute EMA kernel / vandermonde product.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>length</strong> – Sequence length.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>EMA kernel / Vandermonde product. (size, L)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.ema_one_step">
<code class="sig-name descname">ema_one_step</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">state: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA.ema_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.ema_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform exponential moving average for a single step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MultiHeadDampedEMA input sequences. (B, D, 1)</p></li>
<li><p><strong>state</strong> – MultiHeadDampedEMA state. (B, D, num_heads)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>MultiHeadDamped output sequences. (B, 1, D)
new_state: MultiHeadDampedEMA state. (B, D, num_heads)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">state: Optional[Dict[str</em>, <em class="sig-param">torch.Tensor]] = None</em><span class="sig-paren">)</span> &#x2192; Optional[torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute multi-dimensional damped EMA.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MultiHeadDampedEMA input sequence. (L, B, D)</p></li>
<li><p><strong>mask</strong> – Sequence mask. (B, 1, L)</p></li>
<li><p><strong>state</strong> – MultiHeadDampedEMA state. (B, D, num_heads)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>MultiHeadDampedEMA output sequence. (B, L, D)
new_state: MultiHeadDampedEMA state. (B, D, num_heads)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.get_ema_coefficients">
<code class="sig-name descname">get_ema_coefficients</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA.get_ema_coefficients"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.get_ema_coefficients" title="Permalink to this definition">¶</a></dt>
<dd><p>Get EMA coefficients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>None</strong> – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Damping factor / P-th order coefficient. (size, num_heads, 1)
: Previous timestep weight / Q-th order coefficient. (size, num_heads, 1)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">val: float = 0.0</em>, <em class="sig-param">std1: float = 0.2</em>, <em class="sig-param">std2: float = 1.0</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/mega/multi_head_damped_ema.html#MultiHeadDampedEMA.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.mega.multi_head_damped_ema.MultiHeadDampedEMA.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>val</strong> – Initialization value.</p></li>
<li><p><strong>std1</strong> – Main standard deviation.</p></li>
<li><p><strong>std2</strong> – Secondary standard deviation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-modules-mega-init-1">
<span id="espnet2-asr-transducer-decoder-modules-mega-init"></span><h2>espnet2.asr_transducer.decoder.modules.mega.__init__<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-mega-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.mega.__init__"></span></section>
<section id="espnet2-asr-transducer-decoder-modules-rwkv-feed-forward-1">
<span id="espnet2-asr-transducer-decoder-modules-rwkv-feed-forward"></span><h2>espnet2.asr_transducer.decoder.modules.rwkv.feed_forward<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-rwkv-feed-forward-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.rwkv.feed_forward"></span><p>Feed-forward (channel mixing) module for RWKV block.</p>
<p>Based/Modified from <a class="reference external" href="https://github.com/BlinkDL/RWKV-LM/blob/main/RWKV-v4/src/model.py">https://github.com/BlinkDL/RWKV-LM/blob/main/RWKV-v4/src/model.py</a></p>
<p>Some variables are renamed according to <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/rwkv/modeling_rwkv.py">https://github.com/huggingface/transformers/blob/main/src/transformers/models/rwkv/modeling_rwkv.py</a>.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.</code><code class="sig-name descname">FeedForward</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">hidden_size: int</em>, <em class="sig-param">block_id: int</em>, <em class="sig-param">num_blocks: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/feed_forward.html#FeedForward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>FeedForward module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Input/Output size.</p></li>
<li><p><strong>hidden_size</strong> – Hidden size.</p></li>
<li><p><strong>block_id</strong> – Block index.</p></li>
<li><p><strong>num_blocks</strong> – Number of blocks in the architecture.</p></li>
</ul>
</dd>
</dl>
<p>Construct a FeedForward object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">state: Optional[List[torch.Tensor]] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[List[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/feed_forward.html#FeedForward.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute channel mixing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – FeedForward input sequences. (B, U, size)</p></li>
<li><p><strong>state</strong> – Decoder hidden state. [5 x (B, 1, size, N)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>FeedForward output sequences. (B, U, size)
state: Decoder hidden state. [5 x (B, 1, size, N)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">block_id: int</em>, <em class="sig-param">num_blocks: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/feed_forward.html#FeedForward.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.feed_forward.FeedForward.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Block size.</p></li>
<li><p><strong>block_id</strong> – Block index.</p></li>
<li><p><strong>num_blocks</strong> – Number of blocks in the architecture.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-modules-rwkv-attention-1">
<span id="espnet2-asr-transducer-decoder-modules-rwkv-attention"></span><h2>espnet2.asr_transducer.decoder.modules.rwkv.attention<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-rwkv-attention-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.rwkv.attention"></span><p>Attention (time mixing) modules for RWKV block.</p>
<p>Based/Modified from <a class="reference external" href="https://github.com/BlinkDL/RWKV-LM/blob/main/RWKV-v4/src/model.py">https://github.com/BlinkDL/RWKV-LM/blob/main/RWKV-v4/src/model.py</a>.</p>
<p>Some variables are renamed according to <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/rwkv/modeling_rwkv.py">https://github.com/huggingface/transformers/blob/main/src/transformers/models/rwkv/modeling_rwkv.py</a>.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.rwkv.attention.</code><code class="sig-name descname">SelfAttention</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">attention_size: int</em>, <em class="sig-param">context_size: int</em>, <em class="sig-param">block_id: int</em>, <em class="sig-param">num_blocks: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#SelfAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>SelfAttention module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Input/Output size.</p></li>
<li><p><strong>attention_size</strong> – Attention hidden size.</p></li>
<li><p><strong>context_size</strong> – Context size for WKV kernel.</p></li>
<li><p><strong>block_id</strong> – Block index.</p></li>
<li><p><strong>num_blocks</strong> – Number of blocks in the architecture.</p></li>
</ul>
</dd>
</dl>
<p>Construct a SelfAttention object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">state: Optional[List[torch.Tensor]] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[List[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#SelfAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute time mixing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – SelfAttention input sequences. (B, U, size)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. [5 x (B, 1, D_att, N)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>SelfAttention output sequences. (B, U, size)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">attention_size: int</em>, <em class="sig-param">block_id: int</em>, <em class="sig-param">num_blocks: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#SelfAttention.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset module parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Block size.</p></li>
<li><p><strong>attention_size</strong> – Attention hidden size.</p></li>
<li><p><strong>block_id</strong> – Block index.</p></li>
<li><p><strong>num_blocks</strong> – Number of blocks in the architecture.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention.wkv_linear_attention">
<code class="sig-name descname">wkv_linear_attention</code><span class="sig-paren">(</span><em class="sig-param">time_decay: torch.Tensor, time_first: torch.Tensor, key: torch.Tensor, value: torch.Tensor, state: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor, torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#SelfAttention.wkv_linear_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.SelfAttention.wkv_linear_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute WKV with state (i.e.: for inference).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>time_decay</strong> – Channel-wise time decay vector. (D_att)</p></li>
<li><p><strong>time_first</strong> – Channel-wise time first vector. (D_att)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, 1, D_att)</p></li>
<li><p><strong>value</strong> – Value tensor. (B, 1, D_att)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. [3 x (B, D_att)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Weighted Key-Value. (B, 1, D_att)
state: Decoder hidden states. [3 x (B, 1, D_att)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>output</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.rwkv.attention.</code><code class="sig-name descname">WKVLinearAttention</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#WKVLinearAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>WKVLinearAttention function definition.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_output: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#WKVLinearAttention.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>WKVLinearAttention function backward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>grad_output</strong> – Output gradient. (B, U, D_att)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Gradient for channel-wise time decay vector. (D_att)
grad_time_first: Gradient for channel-wise time first vector. (D_att)
grad_key: Gradient for key tensor. (B, U, D_att)
grad_value: Gradient for value tensor. (B, U, D_att)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>grad_time_decay</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">time_decay: torch.Tensor</em>, <em class="sig-param">time_first: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">value: torch._VariableFunctionsClass.tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#WKVLinearAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.WKVLinearAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>WKVLinearAttention function forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>time_decay</strong> – Channel-wise time decay vector. (D_att)</p></li>
<li><p><strong>time_first</strong> – Channel-wise time first vector. (D_att)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, U, D_att)</p></li>
<li><p><strong>value</strong> – Value tensor. (B, U, D_att)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Weighted Key-Value tensor. (B, U, D_att)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.decoder.modules.rwkv.attention.load_wkv_kernel">
<code class="sig-prename descclassname">espnet2.asr_transducer.decoder.modules.rwkv.attention.</code><code class="sig-name descname">load_wkv_kernel</code><span class="sig-paren">(</span><em class="sig-param">context_size: int</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/decoder/modules/rwkv/attention.html#load_wkv_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.decoder.modules.rwkv.attention.load_wkv_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Load WKV CUDA kernel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>context_size</strong> – Context size.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-decoder-modules-rwkv-init-1">
<span id="espnet2-asr-transducer-decoder-modules-rwkv-init"></span><h2>espnet2.asr_transducer.decoder.modules.rwkv.__init__<a class="headerlink" href="#espnet2-asr-transducer-decoder-modules-rwkv-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.decoder.modules.rwkv.__init__"></span></section>
<section id="espnet2-asr-transducer-frontend-online-audio-processor-1">
<span id="espnet2-asr-transducer-frontend-online-audio-processor"></span><h2>espnet2.asr_transducer.frontend.online_audio_processor<a class="headerlink" href="#espnet2-asr-transducer-frontend-online-audio-processor-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.frontend.online_audio_processor"></span><p>Online processor for Transducer models chunk-by-chunk streaming decoding.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.frontend.online_audio_processor.</code><code class="sig-name descname">OnlineAudioProcessor</code><span class="sig-paren">(</span><em class="sig-param">feature_extractor: torch.nn.modules.module.Module</em>, <em class="sig-param">normalization_module: torch.nn.modules.module.Module</em>, <em class="sig-param">decoding_window: int</em>, <em class="sig-param">encoder_sub_factor: int</em>, <em class="sig-param">frontend_conf: Dict</em>, <em class="sig-param">device: torch.device</em>, <em class="sig-param">audio_sampling_rate: int = 16000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/frontend/online_audio_processor.html#OnlineAudioProcessor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>OnlineProcessor module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_extractor</strong> – Feature extractor module.</p></li>
<li><p><strong>normalization_module</strong> – Normalization module.</p></li>
<li><p><strong>decoding_window</strong> – Size of the decoding window (in ms).</p></li>
<li><p><strong>encoder_sub_factor</strong> – Encoder subsampling factor.</p></li>
<li><p><strong>frontend_conf</strong> – Frontend configuration.</p></li>
<li><p><strong>device</strong> – Device to pin module tensors on.</p></li>
<li><p><strong>audio_sampling_rate</strong> – Input sampling rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an OnlineAudioProcessor.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.compute_features">
<code class="sig-name descname">compute_features</code><span class="sig-paren">(</span><em class="sig-param">samples: torch.Tensor</em>, <em class="sig-param">is_final: bool</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/frontend/online_audio_processor.html#OnlineAudioProcessor.compute_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.compute_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute features from input samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – Speech data. (S)</p></li>
<li><p><strong>is_final</strong> – Whether speech corresponds to the final chunk of data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Features sequence. (1, chunk_sz_bs, D_feats)
feats_length: Features length sequence. (1,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>feats</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.get_current_feats">
<code class="sig-name descname">get_current_feats</code><span class="sig-paren">(</span><em class="sig-param">feats: torch.Tensor</em>, <em class="sig-param">feats_length: torch.Tensor</em>, <em class="sig-param">is_final: bool</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/frontend/online_audio_processor.html#OnlineAudioProcessor.get_current_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.get_current_feats" title="Permalink to this definition">¶</a></dt>
<dd><p>Get features for current decoding window.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feats</strong> – Computed features sequence. (1, F, D_feats)</p></li>
<li><p><strong>feats_length</strong> – Computed features sequence length. (1,)</p></li>
<li><p><strong>is_final</strong> – Whether feats corresponds to the final chunk of data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoding window features sequence. (1, chunk_sz_bs, D_feats)
feats_length: Decoding window features length sequence. (1,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>feats</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.get_current_samples">
<code class="sig-name descname">get_current_samples</code><span class="sig-paren">(</span><em class="sig-param">samples: torch.Tensor</em>, <em class="sig-param">is_final: bool</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/frontend/online_audio_processor.html#OnlineAudioProcessor.get_current_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.get_current_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Get samples for feature computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples</strong> – Speech data. (S)</p></li>
<li><p><strong>is_final</strong> – Whether speech corresponds to the final chunk of data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>New speech data. (1, decoding_samples)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>samples</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.reset_cache">
<code class="sig-name descname">reset_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/frontend/online_audio_processor.html#OnlineAudioProcessor.reset_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.frontend.online_audio_processor.OnlineAudioProcessor.reset_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset cache parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>None</strong> – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-frontend-init-1">
<span id="espnet2-asr-transducer-frontend-init"></span><h2>espnet2.asr_transducer.frontend.__init__<a class="headerlink" href="#espnet2-asr-transducer-frontend-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.frontend.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-encoder-1">
<span id="espnet2-asr-transducer-encoder-encoder"></span><h2>espnet2.asr_transducer.encoder.encoder<a class="headerlink" href="#espnet2-asr-transducer-encoder-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.encoder"></span><p>Encoder for Transducer model.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.encoder.</code><code class="sig-name descname">Encoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, body_conf: List[Dict[str, Any]], input_conf: Dict[str, Any] = {}, main_conf: Dict[str, Any] = {}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input size.</p></li>
<li><p><strong>body_conf</strong> – Encoder body configuration.</p></li>
<li><p><strong>input_conf</strong> – Encoder input configuration.</p></li>
<li><p><strong>main_conf</strong> – Encoder main configuration.</p></li>
</ul>
</dd>
</dl>
<p>Construct an Encoder object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_len: torch.Tensor</em>, <em class="sig-param">processed_frames: torch._VariableFunctionsClass.tensor</em>, <em class="sig-param">left_context: int = 32</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences as chunks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Encoder input features. (1, T_in, F)</p></li>
<li><p><strong>x_len</strong> – Encoder input features lengths. (1,)</p></li>
<li><p><strong>processed_frames</strong> – Number of frames already seen.</p></li>
<li><p><strong>left_context</strong> – Number of previous frames (AFTER subsampling) the attention
module can see in current chunk.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Encoder outputs. (B, T_out, D_enc)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_len: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Encoder input features. (B, T_in, F)</p></li>
<li><p><strong>x_len</strong> – Encoder input features lengths. (B,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Encoder outputs. (B, T_out, D_enc)
x_len: Encoder outputs lenghts. (B,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.encoder.Encoder.reset_cache">
<code class="sig-name descname">reset_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/encoder.html#Encoder.reset_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.encoder.Encoder.reset_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset encoder cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of previous frames (AFTER subsampling) the attention
module can see in current chunk.</p></li>
<li><p><strong>device</strong> – Device ID.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-validation-1">
<span id="espnet2-asr-transducer-encoder-validation"></span><h2>espnet2.asr_transducer.encoder.validation<a class="headerlink" href="#espnet2-asr-transducer-encoder-validation-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.validation"></span><p>Set of methods to validate encoder architecture.</p>
<dl class="function">
<dt id="espnet2.asr_transducer.encoder.validation.validate_architecture">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.validation.</code><code class="sig-name descname">validate_architecture</code><span class="sig-paren">(</span><em class="sig-param">input_conf: Dict[str, Any], body_conf: List[Dict[str, Any]], input_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/validation.html#validate_architecture"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.validation.validate_architecture" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate specified architecture is valid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_conf</strong> – Encoder input block configuration.</p></li>
<li><p><strong>body_conf</strong> – Encoder body blocks configuration.</p></li>
<li><p><strong>input_size</strong> – Encoder input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Encoder input block output size.
: Encoder body block output size.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>input_block_osize</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.validation.validate_block_arguments">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.validation.</code><code class="sig-name descname">validate_block_arguments</code><span class="sig-paren">(</span><em class="sig-param">configuration: Dict[str, Any], block_id: int, previous_block_output: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/validation.html#validate_block_arguments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.validation.validate_block_arguments" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate block arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Architecture configuration.</p></li>
<li><p><strong>block_id</strong> – Block ID.</p></li>
<li><p><strong>previous_block_output</strong> – Previous block output size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Block input size.
output_size: Block output size.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>input_size</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.validation.validate_input_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.validation.</code><code class="sig-name descname">validate_input_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: Dict[str, Any], body_first_conf: Dict[str, Any], input_size: int</em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/validation.html#validate_input_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.validation.validate_input_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Validate input block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Encoder input block configuration.</p></li>
<li><p><strong>body_first_conf</strong> – Encoder first body block configuration.</p></li>
<li><p><strong>input_size</strong> – Encoder input block input size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Encoder input block output size.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>output_size</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-building-1">
<span id="espnet2-asr-transducer-encoder-building"></span><h2>espnet2.asr_transducer.encoder.building<a class="headerlink" href="#espnet2-asr-transducer-encoder-building-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.building"></span><p>Set of methods to build Transducer encoder architecture.</p>
<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_body_blocks">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_body_blocks</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any], output_size: int</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_body_blocks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_body_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Build encoder body blocks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Body blocks configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
<li><p><strong>output_size</strong> – Architecture output size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>MultiBlocks function encapsulation all encoder blocks.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_branchformer_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_branchformer_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_branchformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_branchformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Branchformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Branchformer block configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Branchformer block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_conformer_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_conformer_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conformer.Conformer<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_conformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_conformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Conformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Conformer block configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Conformer block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_conv1d_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_conv1d_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], causal: bool</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_conv1d_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_conv1d_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build Conv1d block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>configuration</strong> – Conv1d block configuration.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Conv1d block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_ebranchformer_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_ebranchformer_block</code><span class="sig-paren">(</span><em class="sig-param">configuration: List[Dict[str, Any]], main_params: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_ebranchformer_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_ebranchformer_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build E-Branchformer block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – E-Branchformer block configuration.</p></li>
<li><p><strong>main_params</strong> – Encoder main parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>E-Branchformer block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_input_block">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_input_block</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, configuration: Dict[str, Union[str, int]]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_input_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_input_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Build encoder input block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input size.</p></li>
<li><p><strong>configuration</strong> – Input block configuration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ConvInput block function.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_main_parameters">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_main_parameters</code><span class="sig-paren">(</span><em class="sig-param">pos_wise_act_type: str = 'swish'</em>, <em class="sig-param">conv_mod_act_type: str = 'swish'</em>, <em class="sig-param">pos_enc_dropout_rate: float = 0.0</em>, <em class="sig-param">pos_enc_max_len: int = 5000</em>, <em class="sig-param">simplified_att_score: bool = False</em>, <em class="sig-param">norm_type: str = 'layer_norm'</em>, <em class="sig-param">conv_mod_norm_type: str = 'layer_norm'</em>, <em class="sig-param">after_norm_eps: Optional[float] = None</em>, <em class="sig-param">after_norm_partial: Optional[float] = None</em>, <em class="sig-param">blockdrop_rate: float = 0.0</em>, <em class="sig-param">dynamic_chunk_training: bool = False</em>, <em class="sig-param">short_chunk_threshold: float = 0.75</em>, <em class="sig-param">short_chunk_size: int = 25</em>, <em class="sig-param">num_left_chunks: int = 0</em>, <em class="sig-param">**activation_parameters</em><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_main_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_main_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Build encoder main parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pos_wise_act_type</strong> – X-former position-wise feed-forward activation type.</p></li>
<li><p><strong>conv_mod_act_type</strong> – X-former convolution module activation type.</p></li>
<li><p><strong>pos_enc_dropout_rate</strong> – Positional encoding dropout rate.</p></li>
<li><p><strong>pos_enc_max_len</strong> – Positional encoding maximum length.</p></li>
<li><p><strong>simplified_att_score</strong> – Whether to use simplified attention score computation.</p></li>
<li><p><strong>norm_type</strong> – X-former normalization module type.</p></li>
<li><p><strong>conv_mod_norm_type</strong> – Conformer convolution module normalization type.</p></li>
<li><p><strong>after_norm_eps</strong> – Epsilon value for the final normalization.</p></li>
<li><p><strong>after_norm_partial</strong> – Value for the final normalization with RMSNorm.</p></li>
<li><p><strong>blockdrop_rate</strong> – Probability threshold of dropping out each encoder block.</p></li>
<li><p><strong>dynamic_chunk_training</strong> – Whether to use dynamic chunk training.</p></li>
<li><p><strong>short_chunk_threshold</strong> – Threshold for dynamic chunk selection.</p></li>
<li><p><strong>short_chunk_size</strong> – Minimum number of frames during dynamic chunk training.</p></li>
<li><p><strong>num_left_chunks</strong> – Number of left chunks the attention module can see.
(null or negative value means full context)</p></li>
<li><p><strong>**activation_parameters</strong> – Parameters of the activation functions.
(See espnet2/asr_transducer/activation.py)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Main encoder parameters</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr_transducer.encoder.building.build_positional_encoding">
<code class="sig-prename descclassname">espnet2.asr_transducer.encoder.building.</code><code class="sig-name descname">build_positional_encoding</code><span class="sig-paren">(</span><em class="sig-param">block_size: int, configuration: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/building.html#build_positional_encoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.building.build_positional_encoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Build positional encoding block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>configuration</strong> – Positional encoding configuration.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Positional encoding module.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-init-1">
<span id="espnet2-asr-transducer-encoder-init"></span><h2>espnet2.asr_transducer.encoder.__init__<a class="headerlink" href="#espnet2-asr-transducer-encoder-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-blocks-conformer-1">
<span id="espnet2-asr-transducer-encoder-blocks-conformer"></span><h2>espnet2.asr_transducer.encoder.blocks.conformer<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-conformer-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.conformer"></span><p>Conformer block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.conformer.</code><code class="sig-name descname">Conformer</code><span class="sig-paren">(</span><em class="sig-param">block_size: int</em>, <em class="sig-param">self_att: torch.nn.modules.module.Module</em>, <em class="sig-param">feed_forward: torch.nn.modules.module.Module</em>, <em class="sig-param">feed_forward_macaron: torch.nn.modules.module.Module</em>, <em class="sig-param">conv_mod: torch.nn.modules.module.Module</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conformer module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>self_att</strong> – Self-attention module instance.</p></li>
<li><p><strong>feed_forward</strong> – Feed-forward module instance.</p></li>
<li><p><strong>feed_forward_macaron</strong> – Feed-forward module instance for macaron network.</p></li>
<li><p><strong>conv_mod</strong> – Convolution module instance.</p></li>
<li><p><strong>norm_class</strong> – Normalization module class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Conformer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Conformer output sequences. (B, T, D_block)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Conformer output sequences. (B, T, D_block)
mask: Source mask. (B, T)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conformer.Conformer.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conformer.html#Conformer.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conformer.Conformer.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset self-attention and convolution modules cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-conv1d-1">
<span id="espnet2-asr-transducer-encoder-blocks-conv1d"></span><h2>espnet2.asr_transducer.encoder.blocks.conv1d<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-conv1d-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.conv1d"></span><p>Conv1d block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.conv1d.</code><code class="sig-name descname">Conv1d</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, output_size: int, kernel_size: Union[int, Tuple], stride: Union[int, Tuple] = 1, dilation: Union[int, Tuple] = 1, groups: Union[int, Tuple] = 1, bias: bool = True, batch_norm: bool = False, relu: bool = True, causal: bool = False, dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Conv1d module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input dimension.</p></li>
<li><p><strong>output_size</strong> – Output dimension.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>stride</strong> – Stride of the convolution.</p></li>
<li><p><strong>dilation</strong> – Spacing between the kernel points.</p></li>
<li><p><strong>groups</strong> – Number of blocked connections from input channels to output channels.</p></li>
<li><p><strong>bias</strong> – Whether to add a learnable bias to the output.</p></li>
<li><p><strong>batch_norm</strong> – Whether to use batch normalization after convolution.</p></li>
<li><p><strong>relu</strong> – Whether to use a ReLU activation after convolution.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Conv1d object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conv1d input sequences. (B, T, D_in)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_in)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk (not used here).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Conv1d output sequences. (B, T, D_out)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_out)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_mask">
<code class="sig-name descname">create_new_mask</code><span class="sig-paren">(</span><em class="sig-param">mask: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.create_new_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create new mask for output sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mask</strong> – Mask of input sequences. (B, T)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mask of output sequences. (B, sub(T))</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_pos_enc">
<code class="sig-name descname">create_new_pos_enc</code><span class="sig-paren">(</span><em class="sig-param">pos_enc: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.create_new_pos_enc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.create_new_pos_enc" title="Permalink to this definition">¶</a></dt>
<dd><p>Create new positional embedding vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>pos_enc</strong> – Input sequences positional embedding.
(B, 2 * (T - 1), D_in)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output sequences positional embedding.</dt><dd><p>(B, 2 * (sub(T) - 1), D_in)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pos_enc</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Conv1d input sequences. (B, T, D_in)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_in)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>Conv1d output sequences. (B, sub(T), D_out)
mask: Source mask. (B, T) or (B, sub(T))
pos_enc: Positional embedding sequences.</p>
<blockquote>
<div><p>(B, 2 * (T - 1), D_att) or (B, 2 * (sub(T) - 1), D_out)</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv1d.html#Conv1d.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv1d.Conv1d.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset Conv1d cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk (not used here).</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-ebranchformer-1">
<span id="espnet2-asr-transducer-encoder-blocks-ebranchformer"></span><h2>espnet2.asr_transducer.encoder.blocks.ebranchformer<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-ebranchformer-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.ebranchformer"></span><p>E-Branchformer block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.ebranchformer.</code><code class="sig-name descname">EBranchformer</code><span class="sig-paren">(</span><em class="sig-param">block_size: int</em>, <em class="sig-param">linear_size: int</em>, <em class="sig-param">self_att: torch.nn.modules.module.Module</em>, <em class="sig-param">feed_forward: torch.nn.modules.module.Module</em>, <em class="sig-param">feed_forward_macaron: torch.nn.modules.module.Module</em>, <em class="sig-param">conv_mod: torch.nn.modules.module.Module</em>, <em class="sig-param">depthwise_conv_mod: torch.nn.modules.module.Module</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/ebranchformer.html#EBranchformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E-Branchformer module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/2210.00077.pdf">https://arxiv.org/pdf/2210.00077.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>linear_size</strong> – Linear layers’ hidden size.</p></li>
<li><p><strong>self_att</strong> – Self-attention module instance.</p></li>
<li><p><strong>feed_forward</strong> – Feed-forward module instance.</p></li>
<li><p><strong>feed_forward_macaron</strong> – Feed-forward module instance for macaron network.</p></li>
<li><p><strong>conv_mod</strong> – ConvolutionalSpatialGatingUnit module instance.</p></li>
<li><p><strong>depthwise_conv_mod</strong> – DepthwiseConvolution module instance.</p></li>
<li><p><strong>norm_class</strong> – Normalization class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a E-Branchformer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/ebranchformer.html#EBranchformer.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – E-Branchformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>E-Branchformer output sequences. (B, T, D_block)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/ebranchformer.html#EBranchformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – E-Branchformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>E-Branchformer output sequences. (B, T, D_block)
mask: Source mask. (B, T)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/ebranchformer.html#EBranchformer.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.ebranchformer.EBranchformer.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset self-attention and convolution modules cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-branchformer-1">
<span id="espnet2-asr-transducer-encoder-blocks-branchformer"></span><h2>espnet2.asr_transducer.encoder.blocks.branchformer<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-branchformer-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.branchformer"></span><p>Branchformer block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.branchformer.</code><code class="sig-name descname">Branchformer</code><span class="sig-paren">(</span><em class="sig-param">block_size: int</em>, <em class="sig-param">linear_size: int</em>, <em class="sig-param">self_att: torch.nn.modules.module.Module</em>, <em class="sig-param">conv_mod: torch.nn.modules.module.Module</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Branchformer module definition.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/2207.02971.pdf">https://arxiv.org/pdf/2207.02971.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_size</strong> – Input/output size.</p></li>
<li><p><strong>linear_size</strong> – Linear layers’ hidden size.</p></li>
<li><p><strong>self_att</strong> – Self-attention module instance.</p></li>
<li><p><strong>conv_mod</strong> – Convolution module instance.</p></li>
<li><p><strong>norm_class</strong> – Normalization class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a Branchformer object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode chunk of input sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Branchformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Branchformer output sequences. (B, T, D_block)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Branchformer input sequences. (B, T, D_block)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_block)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Branchformer output sequences. (B, T, D_block)
mask: Source mask. (B, T)
pos_enc: Positional embedding sequences. (B, 2 * (T - 1), D_block)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/branchformer.html#Branchformer.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.branchformer.Branchformer.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset self-attention and convolution modules cache for streaming.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-blocks-init-1">
<span id="espnet2-asr-transducer-encoder-blocks-init"></span><h2>espnet2.asr_transducer.encoder.blocks.__init__<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-blocks-conv-input-1">
<span id="espnet2-asr-transducer-encoder-blocks-conv-input"></span><h2>espnet2.asr_transducer.encoder.blocks.conv_input<a class="headerlink" href="#espnet2-asr-transducer-encoder-blocks-conv-input-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.blocks.conv_input"></span><p>ConvInput block for Transducer encoder.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.blocks.conv_input.</code><code class="sig-name descname">ConvInput</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, conv_size: Union[int, Tuple], subsampling_factor: int = 4, vgg_like: bool = True, output_size: Optional[int] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv_input.html#ConvInput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ConvInput module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – Input size.</p></li>
<li><p><strong>conv_size</strong> – Convolution size.</p></li>
<li><p><strong>subsampling_factor</strong> – Subsampling factor.</p></li>
<li><p><strong>vgg_like</strong> – Whether to use a VGG-like network.</p></li>
<li><p><strong>output_size</strong> – Block output dimension.</p></li>
</ul>
</dd>
</dl>
<p>Construct a ConvInput object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/blocks/conv_input.html#ConvInput.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.blocks.conv_input.ConvInput.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode input sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – ConvInput input sequences. (B, T, D_feats)</p></li>
<li><p><strong>mask</strong> – Mask of input sequences. (B, 1, T)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ConvInput output sequences. (B, sub(T), D_out)
mask: Mask of output sequences. (B, 1, sub(T))</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-multi-blocks-1">
<span id="espnet2-asr-transducer-encoder-modules-multi-blocks"></span><h2>espnet2.asr_transducer.encoder.modules.multi_blocks<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-multi-blocks-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.multi_blocks"></span><p>MultiBlocks for encoder architecture.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.multi_blocks.</code><code class="sig-name descname">MultiBlocks</code><span class="sig-paren">(</span><em class="sig-param">block_list: List[torch.nn.modules.module.Module], output_size: int, norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;, norm_args: Optional[Dict] = None, blockdrop_rate: int = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>MultiBlocks definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>block_list</strong> – Individual blocks of the encoder architecture.</p></li>
<li><p><strong>output_size</strong> – Architecture output size.</p></li>
<li><p><strong>norm_class</strong> – Normalization module class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>blockdrop_rate</strong> – Probability threshold of dropping out each block.</p></li>
</ul>
</dd>
</dl>
<p>Construct a MultiBlocks object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.chunk_forward">
<code class="sig-name descname">chunk_forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks.chunk_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.chunk_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward each block of the encoder architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MultiBlocks input sequences. (B, T, D_block_1)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences. (B, 2 * (T - 1), D_att)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk (used by Conformer and Branchformer block).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>MultiBlocks output sequences. (B, T, D_block_N)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward each block of the encoder architecture.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – MultiBlocks input sequences. (B, T, D_block_1)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding sequences.</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_2, T_2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output sequences. (B, T, D_block_N)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.reset_streaming_cache">
<code class="sig-name descname">reset_streaming_cache</code><span class="sig-paren">(</span><em class="sig-param">left_context: int</em>, <em class="sig-param">device: torch.device</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/multi_blocks.html#MultiBlocks.reset_streaming_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.multi_blocks.MultiBlocks.reset_streaming_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize/Reset encoder streaming cache.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk (used by Conformer and Branchformer block).</p></li>
<li><p><strong>device</strong> – Device to use for cache tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-positional-encoding-1">
<span id="espnet2-asr-transducer-encoder-modules-positional-encoding"></span><h2>espnet2.asr_transducer.encoder.modules.positional_encoding<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-positional-encoding-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.positional_encoding"></span><p>Positional encoding modules.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.positional_encoding.</code><code class="sig-name descname">RelPositionalEncoding</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">max_len: int = 5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/positional_encoding.html#RelPositionalEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Relative positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Module size.</p></li>
<li><p><strong>max_len</strong> – Maximum input length.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct a RelativePositionalEncoding object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.extend_pe">
<code class="sig-name descname">extend_pe</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/positional_encoding.html#RelPositionalEncoding.extend_pe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.extend_pe" title="Permalink to this definition">¶</a></dt>
<dd><p>Reset positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input sequences. (B, T, ?)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/positional_encoding.html#RelPositionalEncoding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.positional_encoding.RelPositionalEncoding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input sequences. (B, T, ?)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames the attention module can see
in current chunk.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Positional embedding sequences. (B, 2 * (T - 1), ?)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pos_enc</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-attention-1">
<span id="espnet2-asr-transducer-encoder-modules-attention"></span><h2>espnet2.asr_transducer.encoder.modules.attention<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-attention-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.attention"></span><p>Multi-Head attention layers with relative positional encoding.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.attention.</code><code class="sig-name descname">RelPositionMultiHeadedAttention</code><span class="sig-paren">(</span><em class="sig-param">num_heads: int</em>, <em class="sig-param">embed_size: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">simplified_attention_score: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>RelPositionMultiHeadedAttention definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_heads</strong> – Number of attention heads.</p></li>
<li><p><strong>embed_size</strong> – Embedding size.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an MultiHeadedAttention object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_attention_score">
<code class="sig-name descname">compute_attention_score</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.compute_attention_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_attention_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Attention score computation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Transformed query tensor. (B, H, T_1, d_k)</p></li>
<li><p><strong>key</strong> – Transformed key tensor. (B, H, T_2, d_k)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding tensor. (B, 2 * T_1 - 1, size)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames to use for current chunk
attention computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attention score. (B, H, T_1, T_2)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_simplified_attention_score">
<code class="sig-name descname">compute_simplified_attention_score</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.compute_simplified_attention_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.compute_simplified_attention_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Simplified attention score computation.</p>
<p>Reference: <a class="reference external" href="https://github.com/k2-fsa/icefall/pull/458">https://github.com/k2-fsa/icefall/pull/458</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Transformed query tensor. (B, H, T_1, d_k)</p></li>
<li><p><strong>key</strong> – Transformed key tensor. (B, H, T_2, d_k)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding tensor. (B, 2 * T_1 - 1, size)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames to use for current chunk
attention computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attention score. (B, H, T_1, T_2)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">value: torch.Tensor</em>, <em class="sig-param">pos_enc: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute scaled dot product attention with rel. positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Query tensor. (B, T_1, size)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, T_2, size)</p></li>
<li><p><strong>value</strong> – Value tensor. (B, T_2, size)</p></li>
<li><p><strong>pos_enc</strong> – Positional embedding tensor. (B, 2 * T_1 - 1, size)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_1, T_1)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames to use for current chunk
attention computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor. (B, T_1, H * d_k)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_attention">
<code class="sig-name descname">forward_attention</code><span class="sig-paren">(</span><em class="sig-param">value: torch.Tensor</em>, <em class="sig-param">scores: torch.Tensor</em>, <em class="sig-param">mask: torch.Tensor</em>, <em class="sig-param">chunk_mask: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.forward_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute attention context vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> – Transformed value. (B, H, T_2, d_k)</p></li>
<li><p><strong>scores</strong> – Attention score. (B, H, T_1, T_2)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>chunk_mask</strong> – Chunk mask. (T_1, T_1)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed value weighted by attention score. (B, T_1, H * d_k)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>attn_output</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_qkv">
<code class="sig-name descname">forward_qkv</code><span class="sig-paren">(</span><em class="sig-param">query: torch.Tensor</em>, <em class="sig-param">key: torch.Tensor</em>, <em class="sig-param">value: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.forward_qkv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.forward_qkv" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform query, key and value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> – Query tensor. (B, T_1, size)</p></li>
<li><p><strong>key</strong> – Key tensor. (B, T_2, size)</p></li>
<li><p><strong>v</strong> – Value tensor. (B, T_2, size)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed query tensor. (B, H, T_1, d_k)
k: Transformed key tensor. (B, H, T_2, d_k)
v: Transformed value tensor. (B, H, T_2, d_k)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>q</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.rel_shift">
<code class="sig-name descname">rel_shift</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">left_context: int = 0</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/attention.html#RelPositionMultiHeadedAttention.rel_shift"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.attention.RelPositionMultiHeadedAttention.rel_shift" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute relative positional encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – Input sequence. (B, H, T_1, 2 * T_1 - 1)</p></li>
<li><p><strong>left_context</strong> – Number of previous frames to use for current chunk
attention computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output sequence. (B, H, T_1, T_2)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-encoder-modules-init-1">
<span id="espnet2-asr-transducer-encoder-modules-init"></span><h2>espnet2.asr_transducer.encoder.modules.__init__<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.__init__"></span></section>
<section id="espnet2-asr-transducer-encoder-modules-convolution-1">
<span id="espnet2-asr-transducer-encoder-modules-convolution"></span><h2>espnet2.asr_transducer.encoder.modules.convolution<a class="headerlink" href="#espnet2-asr-transducer-encoder-modules-convolution-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr_transducer.encoder.modules.convolution"></span><p>Convolution modules for X-former blocks.</p>
<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.convolution.</code><code class="sig-name descname">ConformerConvolution</code><span class="sig-paren">(</span><em class="sig-param">channels: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">activation: torch.nn.modules.module.Module = ReLU()</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">causal: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConformerConvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ConformerConvolution module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> – The number of channels.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>activation</strong> – Activation function.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
</ul>
</dd>
</dl>
<p>Construct an ConformerConvolution object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConformerConvolution.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConformerConvolution.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute convolution module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – ConformerConvolution input sequences. (B, T, D_hidden)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>cache</strong> – ConformerConvolution input cache. (1, D_hidden, conv_kernel)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ConformerConvolution output sequences. (B, ?, D_hidden)
cache: ConformerConvolution output cache. (1, D_hidden, conv_kernel)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.convolution.</code><code class="sig-name descname">ConvolutionalSpatialGatingUnit</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">norm_class: torch.nn.modules.module.Module = &lt;class 'torch.nn.modules.normalization.LayerNorm'&gt;</em>, <em class="sig-param">norm_args: Dict = {}</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">causal: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConvolutionalSpatialGatingUnit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional Spatial Gating Unit module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Initial size to determine the number of channels.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>norm_class</strong> – Normalization module class.</p></li>
<li><p><strong>norm_args</strong> – Normalization module arguments.</p></li>
<li><p><strong>dropout_rate</strong> – Dropout rate.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
</ul>
</dd>
</dl>
<p>Construct a ConvolutionalSpatialGatingUnit object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#ConvolutionalSpatialGatingUnit.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.ConvolutionalSpatialGatingUnit.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute convolution module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – ConvolutionalSpatialGatingUnit input sequences. (B, T, D_hidden)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>cache</strong> – ConvolutionalSpationGatingUnit input cache.
(1, D_hidden, conv_kernel)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ConvolutionalSpatialGatingUnit output sequences. (B, ?, D_hidden)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.DepthwiseConvolution">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr_transducer.encoder.modules.convolution.</code><code class="sig-name descname">DepthwiseConvolution</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">causal: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#DepthwiseConvolution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.DepthwiseConvolution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Depth-wise Convolution module definition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – Initial size to determine the number of channels.</p></li>
<li><p><strong>kernel_size</strong> – Size of the convolving kernel.</p></li>
<li><p><strong>causal</strong> – Whether to use causal convolution (set to True if streaming).</p></li>
</ul>
</dd>
</dl>
<p>Construct a DepthwiseConvolution object.</p>
<dl class="method">
<dt id="espnet2.asr_transducer.encoder.modules.convolution.DepthwiseConvolution.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">mask: Optional[torch.Tensor] = None</em>, <em class="sig-param">cache: Optional[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr_transducer/encoder/modules/convolution.html#DepthwiseConvolution.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr_transducer.encoder.modules.convolution.DepthwiseConvolution.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute convolution module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – DepthwiseConvolution input sequences. (B, T, D_hidden)</p></li>
<li><p><strong>mask</strong> – Source mask. (B, T_2)</p></li>
<li><p><strong>cache</strong> – DepthwiseConvolution input cache. (1, conv_kernel, D_hidden)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>DepthwiseConvolution output sequences. (B, ?, D_hidden)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet2.asr.html" class="btn btn-neutral float-left" title="espnet2.asr package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet2.st.html" class="btn btn-neutral float-right" title="espnet2.st package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>