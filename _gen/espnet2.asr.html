<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>espnet2.asr package &mdash; ESPnet 202308 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet2.asr_transducer package" href="espnet2.asr_transducer.html" />
    <link rel="prev" title="espnet2.tts package" href="espnet2.tts.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ESPnet
          </a>
              <div class="version">
                202308
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Common usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet1_tutorial.html">Usage</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_format_wav_scp.html">Converting audio file formats using format_wav_scp.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html">CMU 11492/11692 Spring 2023: Data preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html#Data-preparation-in-ESPnet">Data preparation in ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html">CMU 11492/11692 Spring 2023: Speech Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html">CMU 11492/11692 Spring 2023: Spoken Language Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html">CMU 11492/11692 Spring 2023: Text to Speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet2.asr package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-maskctc-model-1">espnet2.asr.maskctc_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-espnet-model-1">espnet2.asr.espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-ctc-1">espnet2.asr.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-pit-espnet-model-1">espnet2.asr.pit_espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-discrete-asr-espnet-model-1">espnet2.asr.discrete_asr_espnet_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-init-1">espnet2.asr.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-abs-decoder-1">espnet2.asr.decoder.abs_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-mlm-decoder-1">espnet2.asr.decoder.mlm_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-whisper-decoder-1">espnet2.asr.decoder.whisper_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-hugging-face-transformers-decoder-1">espnet2.asr.decoder.hugging_face_transformers_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-s4-decoder-1">espnet2.asr.decoder.s4_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-transducer-decoder-1">espnet2.asr.decoder.transducer_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-transformer-decoder-1">espnet2.asr.decoder.transformer_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-rnn-decoder-1">espnet2.asr.decoder.rnn_decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-decoder-init-1">espnet2.asr.decoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-specaug-specaug-1">espnet2.asr.specaug.specaug</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-specaug-init-1">espnet2.asr.specaug.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-specaug-abs-specaug-1">espnet2.asr.specaug.abs_specaug</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-abs-frontend-1">espnet2.asr.frontend.abs_frontend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-windowing-1">espnet2.asr.frontend.windowing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-default-1">espnet2.asr.frontend.default</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-s3prl-1">espnet2.asr.frontend.s3prl</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-fused-1">espnet2.asr.frontend.fused</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-whisper-1">espnet2.asr.frontend.whisper</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-frontend-init-1">espnet2.asr.frontend.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-pool-1">espnet2.asr.state_spaces.pool</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-base-1">espnet2.asr.state_spaces.base</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-block-1">espnet2.asr.state_spaces.block</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-residual-1">espnet2.asr.state_spaces.residual</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-model-1">espnet2.asr.state_spaces.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-registry-1">espnet2.asr.state_spaces.registry</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-components-1">espnet2.asr.state_spaces.components</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-cauchy-1">espnet2.asr.state_spaces.cauchy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-s4-1">espnet2.asr.state_spaces.s4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-utils-1">espnet2.asr.state_spaces.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-attention-1">espnet2.asr.state_spaces.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-init-1">espnet2.asr.state_spaces.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-state-spaces-ff-1">espnet2.asr.state_spaces.ff</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-preencoder-linear-1">espnet2.asr.preencoder.linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-preencoder-abs-preencoder-1">espnet2.asr.preencoder.abs_preencoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-preencoder-sinc-1">espnet2.asr.preencoder.sinc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-preencoder-init-1">espnet2.asr.preencoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-beam-search-transducer-1">espnet2.asr.transducer.beam_search_transducer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-error-calculator-1">espnet2.asr.transducer.error_calculator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-beam-search-transducer-streaming-1">espnet2.asr.transducer.beam_search_transducer_streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-init-1">espnet2.asr.transducer.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-rnnt-1">espnet2.asr.transducer.rnnt_multi_blank.rnnt</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-rnnt-multi-blank-1">espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-init-1">espnet2.asr.transducer.rnnt_multi_blank.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-rnnt-helper-1">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-global-constants-1">espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-init-1">espnet2.asr.transducer.rnnt_multi_blank.utils.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-cpu-rnnt-1">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-init-1">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-1">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-kernel-1">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-reduce-1">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-init-1">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-layers-fastformer-1">espnet2.asr.layers.fastformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-layers-cgmlp-1">espnet2.asr.layers.cgmlp</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-layers-init-1">espnet2.asr.layers.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-postencoder-length-adaptor-postencoder-1">espnet2.asr.postencoder.length_adaptor_postencoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-postencoder-abs-postencoder-1">espnet2.asr.postencoder.abs_postencoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-postencoder-init-1">espnet2.asr.postencoder.__init__</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-postencoder-hugging-face-transformers-postencoder-1">espnet2.asr.postencoder.hugging_face_transformers_postencoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-abs-encoder-1">espnet2.asr.encoder.abs_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-e-branchformer-encoder-1">espnet2.asr.encoder.e_branchformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-transformer-encoder-1">espnet2.asr.encoder.transformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-vgg-rnn-encoder-1">espnet2.asr.encoder.vgg_rnn_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-hubert-encoder-1">espnet2.asr.encoder.hubert_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-conformer-encoder-1">espnet2.asr.encoder.conformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-transformer-encoder-multispkr-1">espnet2.asr.encoder.transformer_encoder_multispkr</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-branchformer-encoder-1">espnet2.asr.encoder.branchformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-whisper-encoder-1">espnet2.asr.encoder.whisper_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-wav2vec2-encoder-1">espnet2.asr.encoder.wav2vec2_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-contextual-block-transformer-encoder-1">espnet2.asr.encoder.contextual_block_transformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-contextual-block-conformer-encoder-1">espnet2.asr.encoder.contextual_block_conformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-hugging-face-transformers-encoder-1">espnet2.asr.encoder.hugging_face_transformers_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-longformer-encoder-1">espnet2.asr.encoder.longformer_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-rnn-encoder-1">espnet2.asr.encoder.rnn_encoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet2-asr-encoder-init-1">espnet2.asr.encoder.__init__</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asr_transducer.html">espnet2.asr_transducer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.asvspoof.html">espnet2.asvspoof package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_svs.html">espnet2.gan_svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.spk.html">espnet2.spk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2.diar.html">espnet2.diar package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">espnet2.asr package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/_gen/espnet2.asr.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="espnet2-asr-package">
<h1>espnet2.asr package<a class="headerlink" href="#espnet2-asr-package" title="Permalink to this headline">¶</a></h1>
<section id="espnet2-asr-maskctc-model-1">
<span id="espnet2-asr-maskctc-model"></span><h2>espnet2.asr.maskctc_model<a class="headerlink" href="#espnet2-asr-maskctc-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.maskctc_model"></span><dl class="class">
<dt id="espnet2.asr.maskctc_model.MaskCTCInference">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.maskctc_model.</code><code class="sig-name descname">MaskCTCInference</code><span class="sig-paren">(</span><em class="sig-param">asr_model: espnet2.asr.maskctc_model.MaskCTCModel</em>, <em class="sig-param">n_iterations: int</em>, <em class="sig-param">threshold_probability: float</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCInference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCInference" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Mask-CTC-based non-autoregressive inference</p>
<p>Initialize Mask-CTC inference</p>
<dl class="method">
<dt id="espnet2.asr.maskctc_model.MaskCTCInference.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet.nets.beam_search.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCInference.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCInference.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform Mask-CTC inference</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.maskctc_model.MaskCTCInference.ids2text">
<code class="sig-name descname">ids2text</code><span class="sig-paren">(</span><em class="sig-param">ids: List[int]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCInference.ids2text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCInference.ids2text" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.maskctc_model.MaskCTCModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.maskctc_model.</code><code class="sig-name descname">MaskCTCModel</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int, token_list: Union[Tuple[str, ...], List[str]], frontend: Optional[espnet2.asr.frontend.abs_frontend.AbsFrontend], specaug: Optional[espnet2.asr.specaug.abs_specaug.AbsSpecAug], normalize: Optional[espnet2.layers.abs_normalize.AbsNormalize], preencoder: Optional[espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder], encoder: espnet2.asr.encoder.abs_encoder.AbsEncoder, postencoder: Optional[espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder], decoder: espnet2.asr.decoder.mlm_decoder.MLMDecoder, ctc: espnet2.asr.ctc.CTC, joint_network: Optional[torch.nn.modules.module.Module] = None, ctc_weight: float = 0.5, interctc_weight: float = 0.0, ignore_id: int = -1, lsm_weight: float = 0.0, length_normalized_loss: bool = False, report_cer: bool = True, report_wer: bool = True, sym_space: str = '&lt;space&gt;', sym_blank: str = '&lt;blank&gt;', sym_mask: str = '&lt;mask&gt;', extract_feats_in_collect_stats: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.espnet_model.ESPnetASRModel" title="espnet2.asr.espnet_model.ESPnetASRModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.espnet_model.ESPnetASRModel</span></code></a></p>
<p>Hybrid CTC/Masked LM Encoder-Decoder model (Mask-CTC)</p>
<dl class="method">
<dt id="espnet2.asr.maskctc_model.MaskCTCModel.batchify_nll">
<code class="sig-name descname">batchify_nll</code><span class="sig-paren">(</span><em class="sig-param">encoder_out: torch.Tensor</em>, <em class="sig-param">encoder_out_lens: torch.Tensor</em>, <em class="sig-param">ys_pad: torch.Tensor</em>, <em class="sig-param">ys_pad_lens: torch.Tensor</em>, <em class="sig-param">batch_size: int = 100</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCModel.batchify_nll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCModel.batchify_nll" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute negative log likelihood(nll) from transformer-decoder</p>
<p>To avoid OOM, this fuction seperate the input into batches.
Then call nll for each batch and combine and return results.
:param encoder_out: (Batch, Length, Dim)
:param encoder_out_lens: (Batch,)
:param ys_pad: (Batch, Length)
:param ys_pad_lens: (Batch,)
:param batch_size: int, samples each batch contain when computing nll,</p>
<blockquote>
<div><p>you may change this to avoid OOM or increase
GPU memory usage</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.maskctc_model.MaskCTCModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder + Decoder + Calc loss</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – (Batch, Length, …)</p></li>
<li><p><strong>speech_lengths</strong> – (Batch, )</p></li>
<li><p><strong>text</strong> – (Batch, Length)</p></li>
<li><p><strong>text_lengths</strong> – (Batch,)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.maskctc_model.MaskCTCModel.nll">
<code class="sig-name descname">nll</code><span class="sig-paren">(</span><em class="sig-param">encoder_out: torch.Tensor</em>, <em class="sig-param">encoder_out_lens: torch.Tensor</em>, <em class="sig-param">ys_pad: torch.Tensor</em>, <em class="sig-param">ys_pad_lens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/maskctc_model.html#MaskCTCModel.nll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.maskctc_model.MaskCTCModel.nll" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute negative log likelihood(nll) from transformer-decoder</p>
<p>Normally, this function is called in batchify_nll.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_out</strong> – (Batch, Length, Dim)</p></li>
<li><p><strong>encoder_out_lens</strong> – (Batch,)</p></li>
<li><p><strong>ys_pad</strong> – (Batch, Length)</p></li>
<li><p><strong>ys_pad_lens</strong> – (Batch,)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-espnet-model-1">
<span id="espnet2-asr-espnet-model"></span><h2>espnet2.asr.espnet_model<a class="headerlink" href="#espnet2-asr-espnet-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.espnet_model"></span><dl class="class">
<dt id="espnet2.asr.espnet_model.ESPnetASRModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.espnet_model.</code><code class="sig-name descname">ESPnetASRModel</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int, token_list: Union[Tuple[str, ...], List[str]], frontend: Optional[espnet2.asr.frontend.abs_frontend.AbsFrontend], specaug: Optional[espnet2.asr.specaug.abs_specaug.AbsSpecAug], normalize: Optional[espnet2.layers.abs_normalize.AbsNormalize], preencoder: Optional[espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder], encoder: espnet2.asr.encoder.abs_encoder.AbsEncoder, postencoder: Optional[espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder], decoder: Optional[espnet2.asr.decoder.abs_decoder.AbsDecoder], ctc: espnet2.asr.ctc.CTC, joint_network: Optional[torch.nn.modules.module.Module], aux_ctc: dict = None, ctc_weight: float = 0.5, interctc_weight: float = 0.0, ignore_id: int = -1, lsm_weight: float = 0.0, length_normalized_loss: bool = False, report_cer: bool = True, report_wer: bool = True, sym_space: str = '&lt;space&gt;', sym_blank: str = '&lt;blank&gt;', transducer_multi_blank_durations: List = [], transducer_multi_blank_sigma: float = 0.05, sym_sos: str = '&lt;sos/eos&gt;', sym_eos: str = '&lt;sos/eos&gt;', extract_feats_in_collect_stats: bool = True, lang_token_id: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/espnet_model.html#ESPnetASRModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.espnet_model.ESPnetASRModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.train.html#espnet2.train.abs_espnet_model.AbsESPnetModel" title="espnet2.train.abs_espnet_model.AbsESPnetModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.train.abs_espnet_model.AbsESPnetModel</span></code></a></p>
<p>CTC-attention hybrid Encoder-Decoder model</p>
<dl class="method">
<dt id="espnet2.asr.espnet_model.ESPnetASRModel.batchify_nll">
<code class="sig-name descname">batchify_nll</code><span class="sig-paren">(</span><em class="sig-param">encoder_out: torch.Tensor</em>, <em class="sig-param">encoder_out_lens: torch.Tensor</em>, <em class="sig-param">ys_pad: torch.Tensor</em>, <em class="sig-param">ys_pad_lens: torch.Tensor</em>, <em class="sig-param">batch_size: int = 100</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/espnet_model.html#ESPnetASRModel.batchify_nll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.espnet_model.ESPnetASRModel.batchify_nll" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute negative log likelihood(nll) from transformer-decoder</p>
<p>To avoid OOM, this fuction seperate the input into batches.
Then call nll for each batch and combine and return results.
:param encoder_out: (Batch, Length, Dim)
:param encoder_out_lens: (Batch,)
:param ys_pad: (Batch, Length)
:param ys_pad_lens: (Batch,)
:param batch_size: int, samples each batch contain when computing nll,</p>
<blockquote>
<div><p>you may change this to avoid OOM or increase
GPU memory usage</p>
</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.espnet_model.ESPnetASRModel.collect_feats">
<code class="sig-name descname">collect_feats</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Dict[str, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/espnet_model.html#ESPnetASRModel.collect_feats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.espnet_model.ESPnetASRModel.collect_feats" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.espnet_model.ESPnetASRModel.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/espnet_model.html#ESPnetASRModel.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.espnet_model.ESPnetASRModel.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder. Note that this method is used by asr_inference.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – (Batch, Length, …)</p></li>
<li><p><strong>speech_lengths</strong> – (Batch, )</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.espnet_model.ESPnetASRModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/espnet_model.html#ESPnetASRModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.espnet_model.ESPnetASRModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder + Decoder + Calc loss</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – (Batch, Length, …)</p></li>
<li><p><strong>speech_lengths</strong> – (Batch, )</p></li>
<li><p><strong>text</strong> – (Batch, Length)</p></li>
<li><p><strong>text_lengths</strong> – (Batch,)</p></li>
<li><p><strong>kwargs</strong> – “utt_id” is among the input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.espnet_model.ESPnetASRModel.nll">
<code class="sig-name descname">nll</code><span class="sig-paren">(</span><em class="sig-param">encoder_out: torch.Tensor</em>, <em class="sig-param">encoder_out_lens: torch.Tensor</em>, <em class="sig-param">ys_pad: torch.Tensor</em>, <em class="sig-param">ys_pad_lens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/espnet_model.html#ESPnetASRModel.nll"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.espnet_model.ESPnetASRModel.nll" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute negative log likelihood(nll) from transformer-decoder</p>
<p>Normally, this function is called in batchify_nll.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_out</strong> – (Batch, Length, Dim)</p></li>
<li><p><strong>encoder_out_lens</strong> – (Batch,)</p></li>
<li><p><strong>ys_pad</strong> – (Batch, Length)</p></li>
<li><p><strong>ys_pad_lens</strong> – (Batch,)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-ctc-1">
<span id="espnet2-asr-ctc"></span><h2>espnet2.asr.ctc<a class="headerlink" href="#espnet2-asr-ctc-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.ctc"></span><dl class="class">
<dt id="espnet2.asr.ctc.CTC">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.ctc.</code><code class="sig-name descname">CTC</code><span class="sig-paren">(</span><em class="sig-param">odim: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">ctc_type: str = 'builtin'</em>, <em class="sig-param">reduce: bool = True</em>, <em class="sig-param">ignore_nan_grad: bool = None</em>, <em class="sig-param">zero_infinity: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/ctc.html#CTC"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.ctc.CTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CTC module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>odim</strong> – dimension of outputs</p></li>
<li><p><strong>encoder_output_size</strong> – number of encoder projection units</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate (0.0 ~ 1.0)</p></li>
<li><p><strong>ctc_type</strong> – builtin or gtnctc</p></li>
<li><p><strong>reduce</strong> – reduce the CTC loss into a scalar</p></li>
<li><p><strong>ignore_nan_grad</strong> – Same as zero_infinity (keeping for backward compatiblity)</p></li>
<li><p><strong>zero_infinity</strong> – Whether to zero infinite losses and the associated gradients.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.ctc.CTC.argmax">
<code class="sig-name descname">argmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/ctc.html#CTC.argmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.ctc.CTC.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>argmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hs_pad</strong> (<em>torch.Tensor</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>argmax applied 2d tensor (B, Tmax)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.ctc.CTC.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys_pad</em>, <em class="sig-param">ys_lens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/ctc.html#CTC.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.ctc.CTC.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate CTC loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – batch of padded hidden state sequences (B, Tmax, D)</p></li>
<li><p><strong>hlens</strong> – batch of lengths of hidden state sequences (B)</p></li>
<li><p><strong>ys_pad</strong> – batch of padded character id sequence tensor (B, Lmax)</p></li>
<li><p><strong>ys_lens</strong> – batch of lengths of character sequence (B)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.ctc.CTC.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/ctc.html#CTC.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.ctc.CTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>log_softmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hs_pad</strong> (<em>Tensor</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>log softmax applied 3d tensor (B, Tmax, odim)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.ctc.CTC.loss_fn">
<code class="sig-name descname">loss_fn</code><span class="sig-paren">(</span><em class="sig-param">th_pred</em>, <em class="sig-param">th_target</em>, <em class="sig-param">th_ilen</em>, <em class="sig-param">th_olen</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/ctc.html#CTC.loss_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.ctc.CTC.loss_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.ctc.CTC.softmax">
<code class="sig-name descname">softmax</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/ctc.html#CTC.softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.ctc.CTC.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>softmax of frame activations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hs_pad</strong> (<em>Tensor</em>) – 3d tensor (B, Tmax, eprojs)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>softmax applied 3d tensor (B, Tmax, odim)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-pit-espnet-model-1">
<span id="espnet2-asr-pit-espnet-model"></span><h2>espnet2.asr.pit_espnet_model<a class="headerlink" href="#espnet2-asr-pit-espnet-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.pit_espnet_model"></span><dl class="class">
<dt id="espnet2.asr.pit_espnet_model.ESPnetASRModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.pit_espnet_model.</code><code class="sig-name descname">ESPnetASRModel</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int, token_list: Union[Tuple[str, ...], List[str]], frontend: Optional[espnet2.asr.frontend.abs_frontend.AbsFrontend], specaug: Optional[espnet2.asr.specaug.abs_specaug.AbsSpecAug], normalize: Optional[espnet2.layers.abs_normalize.AbsNormalize], preencoder: Optional[espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder], encoder: espnet2.asr.encoder.abs_encoder.AbsEncoder, postencoder: Optional[espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder], decoder: Optional[espnet2.asr.decoder.abs_decoder.AbsDecoder], ctc: espnet2.asr.ctc.CTC, joint_network: Optional[torch.nn.modules.module.Module], ctc_weight: float = 0.5, interctc_weight: float = 0.0, ignore_id: int = -1, lsm_weight: float = 0.0, length_normalized_loss: bool = False, report_cer: bool = True, report_wer: bool = True, sym_space: str = '&lt;space&gt;', sym_blank: str = '&lt;blank&gt;', sym_sos: str = '&lt;sos/eos&gt;', sym_eos: str = '&lt;sos/eos&gt;', extract_feats_in_collect_stats: bool = True, lang_token_id: int = -1, num_inf: int = 1, num_ref: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/pit_espnet_model.html#ESPnetASRModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.pit_espnet_model.ESPnetASRModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.espnet_model.ESPnetASRModel" title="espnet2.asr.espnet_model.ESPnetASRModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.espnet_model.ESPnetASRModel</span></code></a></p>
<p>CTC-attention hybrid Encoder-Decoder model</p>
<dl class="method">
<dt id="espnet2.asr.pit_espnet_model.ESPnetASRModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">speech: torch.Tensor</em>, <em class="sig-param">speech_lengths: torch.Tensor</em>, <em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/pit_espnet_model.html#ESPnetASRModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.pit_espnet_model.ESPnetASRModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder + Decoder + Calc loss</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>speech</strong> – (Batch, Length, …)</p></li>
<li><p><strong>speech_lengths</strong> – (Batch, )</p></li>
<li><p><strong>text</strong> – (Batch, Length)</p></li>
<li><p><strong>text_lengths</strong> – (Batch,)</p></li>
<li><p><strong>kwargs</strong> – “utt_id” is among the input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.pit_espnet_model.PITLossWrapper">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.pit_espnet_model.</code><code class="sig-name descname">PITLossWrapper</code><span class="sig-paren">(</span><em class="sig-param">criterion_fn: Callable</em>, <em class="sig-param">num_ref: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/pit_espnet_model.html#PITLossWrapper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.pit_espnet_model.PITLossWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.enh.html#espnet2.enh.loss.wrappers.abs_wrapper.AbsLossWrapper" title="espnet2.enh.loss.wrappers.abs_wrapper.AbsLossWrapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.enh.loss.wrappers.abs_wrapper.AbsLossWrapper</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.pit_espnet_model.PITLossWrapper.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inf: torch.Tensor</em>, <em class="sig-param">inf_lens: torch.Tensor</em>, <em class="sig-param">ref: torch.Tensor</em>, <em class="sig-param">ref_lens: torch.Tensor</em>, <em class="sig-param">others: Dict = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/pit_espnet_model.html#PITLossWrapper.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.pit_espnet_model.PITLossWrapper.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>PITLoss Wrapper function. Similar to espnet2/enh/loss/wrapper/pit_solver.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inf</strong> – Iterable[torch.Tensor], (batch, num_inf, …)</p></li>
<li><p><strong>inf_lens</strong> – Iterable[torch.Tensor], (batch, num_inf, …)</p></li>
<li><p><strong>ref</strong> – Iterable[torch.Tensor], (batch, num_ref, …)</p></li>
<li><p><strong>ref_lens</strong> – Iterable[torch.Tensor], (batch, num_ref, …)</p></li>
<li><p><strong>permute_inf</strong> – If true, permute the inference and inference_lens according to
the optimal permutation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.pit_espnet_model.PITLossWrapper.permutate">
<em class="property">classmethod </em><code class="sig-name descname">permutate</code><span class="sig-paren">(</span><em class="sig-param">perm</em>, <em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/pit_espnet_model.html#PITLossWrapper.permutate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.pit_espnet_model.PITLossWrapper.permutate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-discrete-asr-espnet-model-1">
<span id="espnet2-asr-discrete-asr-espnet-model"></span><h2>espnet2.asr.discrete_asr_espnet_model<a class="headerlink" href="#espnet2-asr-discrete-asr-espnet-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.discrete_asr_espnet_model"></span><dl class="class">
<dt id="espnet2.asr.discrete_asr_espnet_model.ESPnetDiscreteASRModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.discrete_asr_espnet_model.</code><code class="sig-name descname">ESPnetDiscreteASRModel</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int, token_list: Union[Tuple[str, ...], List[str]], frontend: Optional[espnet2.asr.frontend.abs_frontend.AbsFrontend], specaug: Optional[espnet2.asr.specaug.abs_specaug.AbsSpecAug], preencoder: Optional[espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder], encoder: espnet2.asr.encoder.abs_encoder.AbsEncoder, postencoder: Optional[espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder], decoder: espnet2.asr.decoder.abs_decoder.AbsDecoder, ctc: Optional[espnet2.asr.ctc.CTC], ctc_weight: float = 0.5, interctc_weight: float = 0.0, src_vocab_size: int = 0, src_token_list: Union[Tuple[str, ...], List[str]] = [], ignore_id: int = -1, lsm_weight: float = 0.0, length_normalized_loss: bool = False, report_bleu: bool = True, sym_space: str = '&lt;space&gt;', sym_blank: str = '&lt;blank&gt;', extract_feats_in_collect_stats: bool = True, share_decoder_input_output_embed: bool = False, share_encoder_decoder_input_embed: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/discrete_asr_espnet_model.html#ESPnetDiscreteASRModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.discrete_asr_espnet_model.ESPnetDiscreteASRModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet2.mt.html#espnet2.mt.espnet_model.ESPnetMTModel" title="espnet2.mt.espnet_model.ESPnetMTModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.mt.espnet_model.ESPnetMTModel</span></code></a></p>
<p>Encoder-Decoder model</p>
<dl class="method">
<dt id="espnet2.asr.discrete_asr_espnet_model.ESPnetDiscreteASRModel.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">src_text: torch.Tensor</em>, <em class="sig-param">src_text_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/discrete_asr_espnet_model.html#ESPnetDiscreteASRModel.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.discrete_asr_espnet_model.ESPnetDiscreteASRModel.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder. Note that this method is used by mt_inference.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src_text</strong> – (Batch, Length, …)</p></li>
<li><p><strong>src_text_lengths</strong> – (Batch, )</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.discrete_asr_espnet_model.ESPnetDiscreteASRModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">text: torch.Tensor</em>, <em class="sig-param">text_lengths: torch.Tensor</em>, <em class="sig-param">src_text: torch.Tensor</em>, <em class="sig-param">src_text_lengths: torch.Tensor</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Dict[str, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/discrete_asr_espnet_model.html#ESPnetDiscreteASRModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.discrete_asr_espnet_model.ESPnetDiscreteASRModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Frontend + Encoder + Decoder + Calc loss</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>text</strong> – (Batch, Length)</p></li>
<li><p><strong>text_lengths</strong> – (Batch,)</p></li>
<li><p><strong>src_text</strong> – (Batch, length)</p></li>
<li><p><strong>src_text_lengths</strong> – (Batch,)</p></li>
<li><p><strong>kwargs</strong> – “utt_id” is among the input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-init-1">
<span id="espnet2-asr-init"></span><h2>espnet2.asr.__init__<a class="headerlink" href="#espnet2-asr-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.__init__"></span></section>
<section id="espnet2-asr-decoder-abs-decoder-1">
<span id="espnet2-asr-decoder-abs-decoder"></span><h2>espnet2.asr.decoder.abs_decoder<a class="headerlink" href="#espnet2-asr-decoder-abs-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.abs_decoder"></span><dl class="class">
<dt id="espnet2.asr.decoder.abs_decoder.AbsDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.abs_decoder.</code><code class="sig-name descname">AbsDecoder</code><a class="reference internal" href="../_modules/espnet2/asr/decoder/abs_decoder.html#AbsDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <a class="reference internal" href="espnet.nets.html#espnet.nets.scorer_interface.ScorerInterface" title="espnet.nets.scorer_interface.ScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.ScorerInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.decoder.abs_decoder.AbsDecoder.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/abs_decoder.html#AbsDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-decoder-mlm-decoder-1">
<span id="espnet2-asr-decoder-mlm-decoder"></span><h2>espnet2.asr.decoder.mlm_decoder<a class="headerlink" href="#espnet2-asr-decoder-mlm-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.mlm_decoder"></span><p>Masked LM Decoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.decoder.mlm_decoder.MLMDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.mlm_decoder.</code><code class="sig-name descname">MLMDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/mlm_decoder.html#MLMDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.mlm_decoder.MLMDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.decoder.mlm_decoder.MLMDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/mlm_decoder.html#MLMDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.mlm_decoder.MLMDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>hlens</strong> – (batch)</p></li>
<li><p><strong>ys_in_pad</strong> – input token ids, int64 (batch, maxlen_out)
if input_layer == “embed”
input tensor (batch, maxlen_out, #mels) in the other cases</p></li>
<li><p><strong>ys_in_lens</strong> – (batch)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>tuple containing:
x: decoded token score before softmax (batch, maxlen_out, token)</p>
<blockquote>
<div><p>if use_output_layer is True,</p>
</div></blockquote>
<p>olens: (batch, )</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-decoder-whisper-decoder-1">
<span id="espnet2-asr-decoder-whisper-decoder"></span><h2>espnet2.asr.decoder.whisper_decoder<a class="headerlink" href="#espnet2-asr-decoder-whisper-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.whisper_decoder"></span><dl class="class">
<dt id="espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.whisper_decoder.</code><code class="sig-name descname">OpenAIWhisperDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">whisper_model: str = 'small'</em>, <em class="sig-param">download_dir: str = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/whisper_decoder.html#OpenAIWhisperDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a>, <a class="reference internal" href="espnet.nets.html#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>Transformer-based Speech-to-Text Decoder from OpenAI’s Whisper Model:</p>
<p>URL: <a class="reference external" href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></p>
<dl class="method">
<dt id="espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/whisper_decoder.html#OpenAIWhisperDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/whisper_decoder.html#OpenAIWhisperDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>hlens</strong> – (batch)</p></li>
<li><p><strong>ys_in_pad</strong> – input token ids, int64 (batch, maxlen_out)
if input_layer == “embed”
input tensor (batch, maxlen_out, #mels) in the other cases</p></li>
<li><p><strong>ys_in_lens</strong> – (batch)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>tuple containing:</p>
<dl class="simple">
<dt>x: decoded token score before softmax (batch, maxlen_out, token)</dt><dd><p>if use_output_layer is True,</p>
</dd>
</dl>
<p>olens: (batch, )</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.forward_one_step">
<code class="sig-name descname">forward_one_step</code><span class="sig-paren">(</span><em class="sig-param">tgt: torch.Tensor</em>, <em class="sig-param">tgt_mask: torch.Tensor</em>, <em class="sig-param">memory: torch.Tensor</em>, <em class="sig-param">cache: List[torch.Tensor] = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/whisper_decoder.html#OpenAIWhisperDecoder.forward_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.forward_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward one step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> – input token ids, int64 (batch, maxlen_out)</p></li>
<li><p><strong>tgt_mask</strong> – input token mask,  (batch, maxlen_out)
dtype=torch.uint8 in PyTorch 1.2-
dtype=torch.bool in PyTorch 1.2+ (include 1.2)</p></li>
<li><p><strong>memory</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>cache</strong> – cached output list of (batch, max_time_out-1, size)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>NN output value and cache per <cite>self.decoders</cite>.
y.shape` is (batch, maxlen_out, token)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>y, cache</p>
</dd>
</dl>
<dl class="simple">
<dt>NOTE (Shih-Lun):</dt><dd><p>cache implementation is ignored for now
for simplicity &amp; correctness</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/whisper_decoder.html#OpenAIWhisperDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.whisper_decoder.OpenAIWhisperDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-decoder-hugging-face-transformers-decoder-1">
<span id="espnet2-asr-decoder-hugging-face-transformers-decoder"></span><h2>espnet2.asr.decoder.hugging_face_transformers_decoder<a class="headerlink" href="#espnet2-asr-decoder-hugging-face-transformers-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.hugging_face_transformers_decoder"></span><p>Hugging Face Transformers Decoder.</p>
<dl class="class">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.hugging_face_transformers_decoder.</code><code class="sig-name descname">HuggingFaceTransformersDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">model_name_or_path: str</em>, <em class="sig-param">causal_lm: bool = False</em>, <em class="sig-param">prefix: str = ''</em>, <em class="sig-param">postfix: str = ''</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#HuggingFaceTransformersDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a>, <a class="reference internal" href="espnet.nets.html#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>Hugging Face Transformers Decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_output_size</strong> – dimension of encoder attention</p></li>
<li><p><strong>model_name_or_path</strong> – Hugging Face Transformers model name</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.add_prefix_postfix">
<code class="sig-name descname">add_prefix_postfix</code><span class="sig-paren">(</span><em class="sig-param">enc_out</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys_in_pad</em>, <em class="sig-param">ys_in_lens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#HuggingFaceTransformersDecoder.add_prefix_postfix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.add_prefix_postfix" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor, speech: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#HuggingFaceTransformersDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#HuggingFaceTransformersDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>hlens</strong> – (batch)</p></li>
<li><p><strong>ys_in_pad</strong> – input tensor (batch, maxlen_out, #mels)</p></li>
<li><p><strong>ys_in_lens</strong> – (batch)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>tuple containing:</p>
<dl class="simple">
<dt>x: decoded token score before softmax (batch, maxlen_out, token)</dt><dd><p>if use_output_layer is True,</p>
</dd>
</dl>
<p>olens: (batch, )</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#HuggingFaceTransformersDecoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em>, <em class="sig-param">speech=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#HuggingFaceTransformersDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.HuggingFaceTransformersDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>scores for next token that has a shape of <cite>(n_vocab)</cite>
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.get_hugging_face_model_lm_head">
<code class="sig-prename descclassname">espnet2.asr.decoder.hugging_face_transformers_decoder.</code><code class="sig-name descname">get_hugging_face_model_lm_head</code><span class="sig-paren">(</span><em class="sig-param">model</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#get_hugging_face_model_lm_head"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.get_hugging_face_model_lm_head" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.decoder.hugging_face_transformers_decoder.get_hugging_face_model_network">
<code class="sig-prename descclassname">espnet2.asr.decoder.hugging_face_transformers_decoder.</code><code class="sig-name descname">get_hugging_face_model_network</code><span class="sig-paren">(</span><em class="sig-param">model</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/hugging_face_transformers_decoder.html#get_hugging_face_model_network"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.hugging_face_transformers_decoder.get_hugging_face_model_network" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-decoder-s4-decoder-1">
<span id="espnet2-asr-decoder-s4-decoder"></span><h2>espnet2.asr.decoder.s4_decoder<a class="headerlink" href="#espnet2-asr-decoder-s4-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.s4_decoder"></span><p>Decoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.decoder.s4_decoder.S4Decoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.s4_decoder.</code><code class="sig-name descname">S4Decoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">dropinp: float = 0.0</em>, <em class="sig-param">dropout: float = 0.25</em>, <em class="sig-param">prenorm: bool = True</em>, <em class="sig-param">n_layers: int = 16</em>, <em class="sig-param">transposed: bool = False</em>, <em class="sig-param">tie_dropout: bool = False</em>, <em class="sig-param">n_repeat=1</em>, <em class="sig-param">layer=None</em>, <em class="sig-param">residual=None</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">pool=None</em>, <em class="sig-param">track_norms=True</em>, <em class="sig-param">drop_path: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/s4_decoder.html#S4Decoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.s4_decoder.S4Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a>, <a class="reference internal" href="espnet.nets.html#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>S4 decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – output dim</p></li>
<li><p><strong>encoder_output_size</strong> – dimension of hidden vector</p></li>
<li><p><strong>input_layer</strong> – input layer type</p></li>
<li><p><strong>dropinp</strong> – input dropout</p></li>
<li><p><strong>dropout</strong> – dropout parameter applied on every residual and every layer</p></li>
<li><p><strong>prenorm</strong> – pre-norm vs. post-norm</p></li>
<li><p><strong>n_layers</strong> – number of layers</p></li>
<li><p><strong>transposed</strong> – transpose inputs so each layer receives (batch, dim, length)</p></li>
<li><p><strong>tie_dropout</strong> – tie dropout mask across sequence like nn.Dropout1d/nn.Dropout2d</p></li>
<li><p><strong>n_repeat</strong> – each layer is repeated n times per stage before applying pooling</p></li>
<li><p><strong>layer</strong> – layer config, must be specified</p></li>
<li><p><strong>residual</strong> – residual config</p></li>
<li><p><strong>norm</strong> – normalization config (e.g. layer vs batch)</p></li>
<li><p><strong>pool</strong> – config for pooling layer per stage</p></li>
<li><p><strong>track_norms</strong> – log norms of each layer output</p></li>
<li><p><strong>drop_path</strong> – drop rate for stochastic depth</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.decoder.s4_decoder.S4Decoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/s4_decoder.html#S4Decoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.s4_decoder.S4Decoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.s4_decoder.S4Decoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/s4_decoder.html#S4Decoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.s4_decoder.S4Decoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>hlens</strong> – (batch)</p></li>
<li><p><strong>ys_in_pad</strong> – input token ids, int64 (batch, maxlen_out)
if input_layer == “embed”
input tensor (batch, maxlen_out, #mels) in the other cases</p></li>
<li><p><strong>ys_in_lens</strong> – (batch)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>tuple containing:</p>
<dl class="simple">
<dt>x: decoded token score before softmax (batch, maxlen_out, token)</dt><dd><p>if use_output_layer is True,</p>
</dd>
</dl>
<p>olens: (batch, )</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.s4_decoder.S4Decoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/s4_decoder.html#S4Decoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.s4_decoder.S4Decoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize state.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.s4_decoder.S4Decoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/s4_decoder.html#S4Decoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.s4_decoder.S4Decoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>scores for next token that has a shape of <cite>(n_vocab)</cite>
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-decoder-transducer-decoder-1">
<span id="espnet2-asr-decoder-transducer-decoder"></span><h2>espnet2.asr.decoder.transducer_decoder<a class="headerlink" href="#espnet2-asr-decoder-transducer-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.transducer_decoder"></span><p>(RNN-)Transducer decoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transducer_decoder.</code><code class="sig-name descname">TransducerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">rnn_type: str = 'lstm'</em>, <em class="sig-param">num_layers: int = 1</em>, <em class="sig-param">hidden_size: int = 320</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">dropout_embed: float = 0.0</em>, <em class="sig-param">embed_pad: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<p>(RNN-)Transducer decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – Output dimension.</p></li>
<li><p><strong>layers_type</strong> – (RNN-)Decoder layers type.</p></li>
<li><p><strong>num_layers</strong> – Number of decoder layers.</p></li>
<li><p><strong>hidden_size</strong> – Number of decoder units per layer.</p></li>
<li><p><strong>dropout</strong> – Dropout rate for decoder layers.</p></li>
<li><p><strong>dropout_embed</strong> – Dropout rate for embedding layer.</p></li>
<li><p><strong>embed_pad</strong> – Embed/Blank symbol ID.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet2.asr.transducer.beam_search_transducer.Hypothesis], List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis]], dec_states: Tuple[torch.Tensor, Optional[torch.Tensor]], cache: Dict[str, Any], use_lm: bool</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypotheses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyps</strong> – Hypotheses.</p></li>
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, dec_states) for each label sequences. (keys)</p></li>
<li><p><strong>use_lm</strong> – Whether to compute label ID sequences for LM.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, D_dec)
dec_states: Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))
lm_labels: Label ID sequences for LM. (B,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.create_batch_states">
<code class="sig-name descname">create_batch_states</code><span class="sig-paren">(</span><em class="sig-param">states: Tuple[torch.Tensor, Optional[torch.Tensor]], new_states: List[Tuple[torch.Tensor, Optional[torch.Tensor]]], check_list: Optional[List] = None</em><span class="sig-paren">)</span> &#x2192; List[Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.create_batch_states"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.create_batch_states" title="Permalink to this definition">¶</a></dt>
<dd><p>Create decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
<li><p><strong>new_states</strong> – Decoder hidden states. [N x ((1, D_dec), (1, D_dec))]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>states</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">labels: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>labels</strong> – Label ID sequences. (B, L)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequences. (B, T, U, D_dec)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch._VariableFunctionsClass.tensor]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize decoder states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> – Batch size.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Initial decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">sequence: torch.Tensor, state: Tuple[torch.Tensor, Optional[torch.Tensor]]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode source label sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> – RNN input sequences. (B, D_emb)</p></li>
<li><p><strong>state</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>RNN output sequences. (B, D_dec)
(h_next, c_next): Decoder hidden states. (N, B, D_dec), (N, B, D_dec))</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>sequence</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">hyp: espnet2.asr.transducer.beam_search_transducer.Hypothesis, cache: Dict[str, Any]</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Tuple[torch.Tensor, Optional[torch.Tensor]], torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>One-step forward hypothesis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hyp</strong> – Hypothesis.</p></li>
<li><p><strong>cache</strong> – Pairs of (dec_out, state) for each label sequence. (key)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Decoder output sequence. (1, D_dec)
new_state: Decoder hidden states. ((N, 1, D_dec), (N, 1, D_dec))
label: Label ID for LM. (1,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dec_out</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.select_state">
<code class="sig-name descname">select_state</code><span class="sig-paren">(</span><em class="sig-param">states: Tuple[torch.Tensor, Optional[torch.Tensor]], idx: int</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.select_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.select_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get specified ID state from decoder hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – Decoder hidden states. ((N, B, D_dec), (N, B, D_dec))</p></li>
<li><p><strong>idx</strong> – State ID to extract.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Decoder hidden state for given ID.</dt><dd><p>((N, 1, D_dec), (N, 1, D_dec))</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transducer_decoder.TransducerDecoder.set_device">
<code class="sig-name descname">set_device</code><span class="sig-paren">(</span><em class="sig-param">device: torch.device</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transducer_decoder.html#TransducerDecoder.set_device"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transducer_decoder.TransducerDecoder.set_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set GPU device to use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> – Device ID.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-decoder-transformer-decoder-1">
<span id="espnet2-asr-decoder-transformer-decoder"></span><h2>espnet2.asr.decoder.transformer_decoder<a class="headerlink" href="#espnet2-asr-decoder-transformer-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.transformer_decoder"></span><p>Decoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">BaseTransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#BaseTransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a>, <a class="reference internal" href="espnet.nets.html#espnet.nets.scorer_interface.BatchScorerInterface" title="espnet.nets.scorer_interface.BatchScorerInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.scorer_interface.BatchScorerInterface</span></code></a></p>
<p>Base class of Transfomer decoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vocab_size</strong> – output dim</p></li>
<li><p><strong>encoder_output_size</strong> – dimension of attention</p></li>
<li><p><strong>attention_heads</strong> – the number of heads of multi head attention</p></li>
<li><p><strong>linear_units</strong> – the number of units of position-wise feed forward</p></li>
<li><p><strong>num_blocks</strong> – the number of decoder blocks</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>self_attention_dropout_rate</strong> – dropout rate for attention</p></li>
<li><p><strong>input_layer</strong> – input layer type</p></li>
<li><p><strong>use_output_layer</strong> – whether to use output layer</p></li>
<li><p><strong>pos_enc_class</strong> – PositionalEncoding or ScaledPositionalEncoding</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>concat_after</strong> – whether to concat attention layer’s input and output
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied.
i.e. x -&gt; x + att(x)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor, return_hs: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#BaseTransformerDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em>, <em class="sig-param">return_hs: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#BaseTransformerDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>hlens</strong> – (batch)</p></li>
<li><p><strong>ys_in_pad</strong> – input token ids, int64 (batch, maxlen_out)
if input_layer == “embed”
input tensor (batch, maxlen_out, #mels) in the other cases</p></li>
<li><p><strong>ys_in_lens</strong> – (batch)</p></li>
<li><p><strong>return_hs</strong> – dec hidden state corresponding to ys,
used for searchable hidden ints</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>tuple containing:</p>
<dl class="simple">
<dt>x: decoded token score before softmax (batch, maxlen_out, token)</dt><dd><p>if use_output_layer is True,</p>
</dd>
</dl>
<p>olens: (batch, )</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.forward_one_step">
<code class="sig-name descname">forward_one_step</code><span class="sig-paren">(</span><em class="sig-param">tgt: torch.Tensor</em>, <em class="sig-param">tgt_mask: torch.Tensor</em>, <em class="sig-param">memory: torch.Tensor</em>, <em class="sig-param">cache: List[torch.Tensor] = None</em>, <em class="sig-param">return_hs: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#BaseTransformerDecoder.forward_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.forward_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward one step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> – input token ids, int64 (batch, maxlen_out)</p></li>
<li><p><strong>tgt_mask</strong> – input token mask,  (batch, maxlen_out)
dtype=torch.uint8 in PyTorch 1.2-
dtype=torch.bool in PyTorch 1.2+ (include 1.2)</p></li>
<li><p><strong>memory</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>cache</strong> – cached output list of (batch, max_time_out-1, size)</p></li>
<li><p><strong>return_hs</strong> – dec hidden state corresponding to ys,
used for searchable hidden ints</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>NN output value and cache per <cite>self.decoders</cite>.
y.shape` is (batch, maxlen_out, token)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>y, cache</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em>, <em class="sig-param">return_hs=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#BaseTransformerDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.DynamicConvolution2DTransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">DynamicConvolution2DTransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">conv_wshare: int = 4</em>, <em class="sig-param">conv_kernel_length: Sequence[int] = (11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11)</em>, <em class="sig-param">conv_usebias: int = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#DynamicConvolution2DTransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.DynamicConvolution2DTransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.DynamicConvolutionTransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">DynamicConvolutionTransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">conv_wshare: int = 4</em>, <em class="sig-param">conv_kernel_length: Sequence[int] = (11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11)</em>, <em class="sig-param">conv_usebias: int = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#DynamicConvolutionTransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.DynamicConvolutionTransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.LightweightConvolution2DTransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">LightweightConvolution2DTransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">conv_wshare: int = 4</em>, <em class="sig-param">conv_kernel_length: Sequence[int] = (11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11)</em>, <em class="sig-param">conv_usebias: int = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#LightweightConvolution2DTransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.LightweightConvolution2DTransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.LightweightConvolutionTransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">LightweightConvolutionTransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">conv_wshare: int = 4</em>, <em class="sig-param">conv_kernel_length: Sequence[int] = (11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11</em>, <em class="sig-param">11)</em>, <em class="sig-param">conv_usebias: int = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#LightweightConvolutionTransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.LightweightConvolutionTransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.TransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">TransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">layer_drop_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#TransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.TransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.transformer_decoder.</code><code class="sig-name descname">TransformerMDDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">self_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">src_attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: str = 'embed'</em>, <em class="sig-param">use_output_layer: bool = True</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">use_speech_attn: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#TransformerMDDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder" title="espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.transformer_decoder.BaseTransformerDecoder</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.batch_score">
<code class="sig-name descname">batch_score</code><span class="sig-paren">(</span><em class="sig-param">ys: torch.Tensor, states: List[Any], xs: torch.Tensor, speech: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[Any]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#TransformerMDDecoder.batch_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.batch_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ys</strong> (<em>torch.Tensor</em>) – torch.int64 prefix tokens (n_batch, ylen).</p></li>
<li><p><strong>states</strong> (<em>List</em><em>[</em><em>Any</em><em>]</em>) – Scorer states for prefix tokens.</p></li>
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys (n_batch, xlen, n_feat).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>batchfied scores for next token with shape of <cite>(n_batch, n_vocab)</cite>
and next state list for ys.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, List[Any]]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad: torch.Tensor</em>, <em class="sig-param">hlens: torch.Tensor</em>, <em class="sig-param">ys_in_pad: torch.Tensor</em>, <em class="sig-param">ys_in_lens: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor = None</em>, <em class="sig-param">speech_lens: torch.Tensor = None</em>, <em class="sig-param">return_hs: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#TransformerMDDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward decoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hs_pad</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>hlens</strong> – (batch)</p></li>
<li><p><strong>ys_in_pad</strong> – input token ids, int64 (batch, maxlen_out)
if input_layer == “embed”
input tensor (batch, maxlen_out, #mels) in the other cases</p></li>
<li><p><strong>ys_in_lens</strong> – (batch)</p></li>
<li><p><strong>return_hs</strong> – dec hidden state corresponding to ys,
used for searchable hidden ints</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>tuple containing:</p>
<dl class="simple">
<dt>x: decoded token score before softmax (batch, maxlen_out, token)</dt><dd><p>if use_output_layer is True,</p>
</dd>
</dl>
<p>olens: (batch, )</p>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.forward_one_step">
<code class="sig-name descname">forward_one_step</code><span class="sig-paren">(</span><em class="sig-param">tgt: torch.Tensor</em>, <em class="sig-param">tgt_mask: torch.Tensor</em>, <em class="sig-param">memory: torch.Tensor</em>, <em class="sig-param">speech: torch.Tensor = None</em>, <em class="sig-param">cache: List[torch.Tensor] = None</em>, <em class="sig-param">return_hs: bool = False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, List[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#TransformerMDDecoder.forward_one_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.forward_one_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward one step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> – input token ids, int64 (batch, maxlen_out)</p></li>
<li><p><strong>tgt_mask</strong> – input token mask,  (batch, maxlen_out)
dtype=torch.uint8 in PyTorch 1.2-
dtype=torch.bool in PyTorch 1.2+ (include 1.2)</p></li>
<li><p><strong>memory</strong> – encoded memory, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>speech</strong> – encoded speech, float32  (batch, maxlen_in, feat)</p></li>
<li><p><strong>cache</strong> – cached output list of (batch, max_time_out-1, size)</p></li>
<li><p><strong>return_hs</strong> – dec hidden state corresponding to ys,
used for searchable hidden ints</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>NN output value and cache per <cite>self.decoders</cite>.
y.shape` is (batch, maxlen_out, token)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>y, cache</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">ys</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em>, <em class="sig-param">speech=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/transformer_decoder.html#TransformerMDDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.transformer_decoder.TransformerMDDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-decoder-rnn-decoder-1">
<span id="espnet2-asr-decoder-rnn-decoder"></span><h2>espnet2.asr.decoder.rnn_decoder<a class="headerlink" href="#espnet2-asr-decoder-rnn-decoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.rnn_decoder"></span><dl class="class">
<dt id="espnet2.asr.decoder.rnn_decoder.RNNDecoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.decoder.rnn_decoder.</code><code class="sig-name descname">RNNDecoder</code><span class="sig-paren">(</span><em class="sig-param">vocab_size: int</em>, <em class="sig-param">encoder_output_size: int</em>, <em class="sig-param">rnn_type: str = 'lstm'</em>, <em class="sig-param">num_layers: int = 1</em>, <em class="sig-param">hidden_size: int = 320</em>, <em class="sig-param">sampling_probability: float = 0.0</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">context_residual: bool = False</em>, <em class="sig-param">replace_sos: bool = False</em>, <em class="sig-param">num_encs: int = 1</em>, <em class="sig-param">att_conf: dict = {'aconv_chans': 10</em>, <em class="sig-param">'aconv_filts': 100</em>, <em class="sig-param">'adim': 320</em>, <em class="sig-param">'aheads': 4</em>, <em class="sig-param">'atype': 'location'</em>, <em class="sig-param">'awin': 5</em>, <em class="sig-param">'han_conv_chans': -1</em>, <em class="sig-param">'han_conv_filts': 100</em>, <em class="sig-param">'han_dim': 320</em>, <em class="sig-param">'han_heads': 4</em>, <em class="sig-param">'han_mode': False</em>, <em class="sig-param">'han_type': None</em>, <em class="sig-param">'han_win': 5</em>, <em class="sig-param">'num_att': 1</em>, <em class="sig-param">'num_encs': 1}</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#RNNDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.RNNDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.decoder.abs_decoder.AbsDecoder" title="espnet2.asr.decoder.abs_decoder.AbsDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.decoder.abs_decoder.AbsDecoder</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.decoder.rnn_decoder.RNNDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em>, <em class="sig-param">hlens</em>, <em class="sig-param">ys_in_pad</em>, <em class="sig-param">ys_in_lens</em>, <em class="sig-param">strm_idx=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#RNNDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.RNNDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.rnn_decoder.RNNDecoder.init_state">
<code class="sig-name descname">init_state</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#RNNDecoder.init_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.RNNDecoder.init_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an initial state for decoding (optional).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoded feature tensor</p>
</dd>
</dl>
<p>Returns: initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.rnn_decoder.RNNDecoder.rnn_forward">
<code class="sig-name descname">rnn_forward</code><span class="sig-paren">(</span><em class="sig-param">ey</em>, <em class="sig-param">z_list</em>, <em class="sig-param">c_list</em>, <em class="sig-param">z_prev</em>, <em class="sig-param">c_prev</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#RNNDecoder.rnn_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.RNNDecoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.rnn_decoder.RNNDecoder.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param">yseq</em>, <em class="sig-param">state</em>, <em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#RNNDecoder.score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.RNNDecoder.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Score new token (required).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y</strong> (<em>torch.Tensor</em>) – 1D torch.int64 prefix tokens.</p></li>
<li><p><strong>state</strong> – Scorer state for prefix tokens</p></li>
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – The encoder feature that generates ys.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tuple of</dt><dd><p>scores for next token that has a shape of <cite>(n_vocab)</cite>
and next state for ys</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple[torch.Tensor, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.decoder.rnn_decoder.RNNDecoder.zero_state">
<code class="sig-name descname">zero_state</code><span class="sig-paren">(</span><em class="sig-param">hs_pad</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#RNNDecoder.zero_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.RNNDecoder.zero_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.decoder.rnn_decoder.build_attention_list">
<code class="sig-prename descclassname">espnet2.asr.decoder.rnn_decoder.</code><code class="sig-name descname">build_attention_list</code><span class="sig-paren">(</span><em class="sig-param">eprojs: int</em>, <em class="sig-param">dunits: int</em>, <em class="sig-param">atype: str = 'location'</em>, <em class="sig-param">num_att: int = 1</em>, <em class="sig-param">num_encs: int = 1</em>, <em class="sig-param">aheads: int = 4</em>, <em class="sig-param">adim: int = 320</em>, <em class="sig-param">awin: int = 5</em>, <em class="sig-param">aconv_chans: int = 10</em>, <em class="sig-param">aconv_filts: int = 100</em>, <em class="sig-param">han_mode: bool = False</em>, <em class="sig-param">han_type=None</em>, <em class="sig-param">han_heads: int = 4</em>, <em class="sig-param">han_dim: int = 320</em>, <em class="sig-param">han_conv_chans: int = -1</em>, <em class="sig-param">han_conv_filts: int = 100</em>, <em class="sig-param">han_win: int = 5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/decoder/rnn_decoder.html#build_attention_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.decoder.rnn_decoder.build_attention_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-decoder-init-1">
<span id="espnet2-asr-decoder-init"></span><h2>espnet2.asr.decoder.__init__<a class="headerlink" href="#espnet2-asr-decoder-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.decoder.__init__"></span></section>
<section id="espnet2-asr-specaug-specaug-1">
<span id="espnet2-asr-specaug-specaug"></span><h2>espnet2.asr.specaug.specaug<a class="headerlink" href="#espnet2-asr-specaug-specaug-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.specaug.specaug"></span><p>SpecAugment module.</p>
<dl class="class">
<dt id="espnet2.asr.specaug.specaug.SpecAug">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.specaug.specaug.</code><code class="sig-name descname">SpecAug</code><span class="sig-paren">(</span><em class="sig-param">apply_time_warp: bool = True, time_warp_window: int = 5, time_warp_mode: str = 'bicubic', apply_freq_mask: bool = True, freq_mask_width_range: Union[int, Sequence[int]] = (0, 20), num_freq_mask: int = 2, apply_time_mask: bool = True, time_mask_width_range: Union[int, Sequence[int], None] = None, time_mask_width_ratio_range: Union[float, Sequence[float], None] = None, num_time_mask: int = 2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/specaug/specaug.html#SpecAug"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.specaug.specaug.SpecAug" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.specaug.abs_specaug.AbsSpecAug" title="espnet2.asr.specaug.abs_specaug.AbsSpecAug"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.specaug.abs_specaug.AbsSpecAug</span></code></a></p>
<p>Implementation of SpecAug.</p>
<dl>
<dt>Reference:</dt><dd><p>Daniel S. Park et al.
“SpecAugment: A Simple Data</p>
<blockquote>
<div><p>Augmentation Method for Automatic Speech Recognition”</p>
</div></blockquote>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using cuda mode, time_warp doesn’t have reproducibility
due to <cite>torch.nn.functional.interpolate</cite>.</p>
</aside>
<dl class="method">
<dt id="espnet2.asr.specaug.specaug.SpecAug.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">x_lengths=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/specaug/specaug.html#SpecAug.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.specaug.specaug.SpecAug.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-specaug-init-1">
<span id="espnet2-asr-specaug-init"></span><h2>espnet2.asr.specaug.__init__<a class="headerlink" href="#espnet2-asr-specaug-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.specaug.__init__"></span></section>
<section id="espnet2-asr-specaug-abs-specaug-1">
<span id="espnet2-asr-specaug-abs-specaug"></span><h2>espnet2.asr.specaug.abs_specaug<a class="headerlink" href="#espnet2-asr-specaug-abs-specaug-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.specaug.abs_specaug"></span><dl class="class">
<dt id="espnet2.asr.specaug.abs_specaug.AbsSpecAug">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.specaug.abs_specaug.</code><code class="sig-name descname">AbsSpecAug</code><a class="reference internal" href="../_modules/espnet2/asr/specaug/abs_specaug.html#AbsSpecAug"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.specaug.abs_specaug.AbsSpecAug" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Abstract class for the augmentation of spectrogram</p>
<p>The process-flow:</p>
<p>Frontend  -&gt; SpecAug -&gt; Normalization -&gt; Encoder -&gt; Decoder</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.specaug.abs_specaug.AbsSpecAug.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em>, <em class="sig-param">x_lengths: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/specaug/abs_specaug.html#AbsSpecAug.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.specaug.abs_specaug.AbsSpecAug.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-abs-frontend-1">
<span id="espnet2-asr-frontend-abs-frontend"></span><h2>espnet2.asr.frontend.abs_frontend<a class="headerlink" href="#espnet2-asr-frontend-abs-frontend-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.abs_frontend"></span><dl class="class">
<dt id="espnet2.asr.frontend.abs_frontend.AbsFrontend">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.frontend.abs_frontend.</code><code class="sig-name descname">AbsFrontend</code><a class="reference internal" href="../_modules/espnet2/asr/frontend/abs_frontend.html#AbsFrontend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.frontend.abs_frontend.AbsFrontend.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/frontend/abs_frontend.html#AbsFrontend.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.abs_frontend.AbsFrontend.output_size">
<em class="property">abstract </em><code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/frontend/abs_frontend.html#AbsFrontend.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-windowing-1">
<span id="espnet2-asr-frontend-windowing"></span><h2>espnet2.asr.frontend.windowing<a class="headerlink" href="#espnet2-asr-frontend-windowing-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.windowing"></span><p>Sliding Window for raw audio input data.</p>
<dl class="class">
<dt id="espnet2.asr.frontend.windowing.SlidingWindow">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.frontend.windowing.</code><code class="sig-name descname">SlidingWindow</code><span class="sig-paren">(</span><em class="sig-param">win_length: int = 400</em>, <em class="sig-param">hop_length: int = 160</em>, <em class="sig-param">channels: int = 1</em>, <em class="sig-param">padding: int = None</em>, <em class="sig-param">fs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/frontend/windowing.html#SlidingWindow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.windowing.SlidingWindow" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend" title="espnet2.asr.frontend.abs_frontend.AbsFrontend"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.frontend.abs_frontend.AbsFrontend</span></code></a></p>
<p>Sliding Window.</p>
<p>Provides a sliding window over a batched continuous raw audio tensor.
Optionally, provides padding (Currently not implemented).
Combine this module with a pre-encoder compatible with raw audio data,
for example Sinc convolutions.</p>
<p>Known issues:
Output length is calculated incorrectly if audio shorter than win_length.
WARNING: trailing values are discarded - padding not implemented yet.
There is currently no additional window function applied to input values.</p>
<p>Initialize.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>win_length</strong> – Length of frame.</p></li>
<li><p><strong>hop_length</strong> – Relative starting point of next frame.</p></li>
<li><p><strong>channels</strong> – Number of input channels.</p></li>
<li><p><strong>padding</strong> – Padding (placeholder, currently not implemented).</p></li>
<li><p><strong>fs</strong> – Sampling rate (placeholder for compatibility, not used).</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.frontend.windowing.SlidingWindow.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/frontend/windowing.html#SlidingWindow.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.windowing.SlidingWindow.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply a sliding window on the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> – Input (B, T, C*D) or (B, T*C*D), with D=C=1.</p></li>
<li><p><strong>input_lengths</strong> – Input lengths within batch.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output with dimensions (B, T, C, D), with D=win_length.
Tensor: Output lengths within batch.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.windowing.SlidingWindow.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/frontend/windowing.html#SlidingWindow.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.windowing.SlidingWindow.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Return output length of feature dimension D, i.e. the window length.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-default-1">
<span id="espnet2-asr-frontend-default"></span><h2>espnet2.asr.frontend.default<a class="headerlink" href="#espnet2-asr-frontend-default-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.default"></span><dl class="class">
<dt id="espnet2.asr.frontend.default.DefaultFrontend">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.frontend.default.</code><code class="sig-name descname">DefaultFrontend</code><span class="sig-paren">(</span><em class="sig-param">fs: Union[int</em>, <em class="sig-param">str] = 16000</em>, <em class="sig-param">n_fft: int = 512</em>, <em class="sig-param">win_length: int = None</em>, <em class="sig-param">hop_length: int = 128</em>, <em class="sig-param">window: Optional[str] = 'hann'</em>, <em class="sig-param">center: bool = True</em>, <em class="sig-param">normalized: bool = False</em>, <em class="sig-param">onesided: bool = True</em>, <em class="sig-param">n_mels: int = 80</em>, <em class="sig-param">fmin: int = None</em>, <em class="sig-param">fmax: int = None</em>, <em class="sig-param">htk: bool = False</em>, <em class="sig-param">frontend_conf: Optional[dict] = {'badim': 320</em>, <em class="sig-param">'bdropout_rate': 0.0</em>, <em class="sig-param">'blayers': 3</em>, <em class="sig-param">'bnmask': 2</em>, <em class="sig-param">'bprojs': 320</em>, <em class="sig-param">'btype': 'blstmp'</em>, <em class="sig-param">'bunits': 300</em>, <em class="sig-param">'delay': 3</em>, <em class="sig-param">'ref_channel': -1</em>, <em class="sig-param">'taps': 5</em>, <em class="sig-param">'use_beamformer': False</em>, <em class="sig-param">'use_dnn_mask_for_wpe': True</em>, <em class="sig-param">'use_wpe': False</em>, <em class="sig-param">'wdropout_rate': 0.0</em>, <em class="sig-param">'wlayers': 3</em>, <em class="sig-param">'wprojs': 320</em>, <em class="sig-param">'wtype': 'blstmp'</em>, <em class="sig-param">'wunits': 300}</em>, <em class="sig-param">apply_stft: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/frontend/default.html#DefaultFrontend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.default.DefaultFrontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend" title="espnet2.asr.frontend.abs_frontend.AbsFrontend"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.frontend.abs_frontend.AbsFrontend</span></code></a></p>
<p>Conventional frontend structure for ASR.</p>
<p>Stft -&gt; WPE -&gt; MVDR-Beamformer -&gt; Power-spec -&gt; Mel-Fbank -&gt; CMVN</p>
<dl class="method">
<dt id="espnet2.asr.frontend.default.DefaultFrontend.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/frontend/default.html#DefaultFrontend.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.default.DefaultFrontend.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.default.DefaultFrontend.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/frontend/default.html#DefaultFrontend.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.default.DefaultFrontend.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-s3prl-1">
<span id="espnet2-asr-frontend-s3prl"></span><h2>espnet2.asr.frontend.s3prl<a class="headerlink" href="#espnet2-asr-frontend-s3prl-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.s3prl"></span><dl class="class">
<dt id="espnet2.asr.frontend.s3prl.S3prlFrontend">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.frontend.s3prl.</code><code class="sig-name descname">S3prlFrontend</code><span class="sig-paren">(</span><em class="sig-param">fs: Union[int</em>, <em class="sig-param">str] = 16000</em>, <em class="sig-param">frontend_conf: Optional[dict] = {'badim': 320</em>, <em class="sig-param">'bdropout_rate': 0.0</em>, <em class="sig-param">'blayers': 3</em>, <em class="sig-param">'bnmask': 2</em>, <em class="sig-param">'bprojs': 320</em>, <em class="sig-param">'btype': 'blstmp'</em>, <em class="sig-param">'bunits': 300</em>, <em class="sig-param">'delay': 3</em>, <em class="sig-param">'ref_channel': -1</em>, <em class="sig-param">'taps': 5</em>, <em class="sig-param">'use_beamformer': False</em>, <em class="sig-param">'use_dnn_mask_for_wpe': True</em>, <em class="sig-param">'use_wpe': False</em>, <em class="sig-param">'wdropout_rate': 0.0</em>, <em class="sig-param">'wlayers': 3</em>, <em class="sig-param">'wprojs': 320</em>, <em class="sig-param">'wtype': 'blstmp'</em>, <em class="sig-param">'wunits': 300}</em>, <em class="sig-param">download_dir: str = None</em>, <em class="sig-param">multilayer_feature: bool = False</em>, <em class="sig-param">layer: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/frontend/s3prl.html#S3prlFrontend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.s3prl.S3prlFrontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend" title="espnet2.asr.frontend.abs_frontend.AbsFrontend"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.frontend.abs_frontend.AbsFrontend</span></code></a></p>
<p>Speech Pretrained Representation frontend structure for ASR.</p>
<dl class="method">
<dt id="espnet2.asr.frontend.s3prl.S3prlFrontend.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/frontend/s3prl.html#S3prlFrontend.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.s3prl.S3prlFrontend.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.s3prl.S3prlFrontend.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/frontend/s3prl.html#S3prlFrontend.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.s3prl.S3prlFrontend.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.s3prl.S3prlFrontend.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/frontend/s3prl.html#S3prlFrontend.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.s3prl.S3prlFrontend.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-fused-1">
<span id="espnet2-asr-frontend-fused"></span><h2>espnet2.asr.frontend.fused<a class="headerlink" href="#espnet2-asr-frontend-fused-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.fused"></span><dl class="class">
<dt id="espnet2.asr.frontend.fused.FusedFrontends">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.frontend.fused.</code><code class="sig-name descname">FusedFrontends</code><span class="sig-paren">(</span><em class="sig-param">frontends=None</em>, <em class="sig-param">align_method='linear_projection'</em>, <em class="sig-param">proj_dim=100</em>, <em class="sig-param">fs=16000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/frontend/fused.html#FusedFrontends"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.fused.FusedFrontends" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend" title="espnet2.asr.frontend.abs_frontend.AbsFrontend"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.frontend.abs_frontend.AbsFrontend</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.frontend.fused.FusedFrontends.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/frontend/fused.html#FusedFrontends.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.fused.FusedFrontends.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.fused.FusedFrontends.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/frontend/fused.html#FusedFrontends.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.fused.FusedFrontends.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-whisper-1">
<span id="espnet2-asr-frontend-whisper"></span><h2>espnet2.asr.frontend.whisper<a class="headerlink" href="#espnet2-asr-frontend-whisper-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.whisper"></span><dl class="class">
<dt id="espnet2.asr.frontend.whisper.WhisperFrontend">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.frontend.whisper.</code><code class="sig-name descname">WhisperFrontend</code><span class="sig-paren">(</span><em class="sig-param">whisper_model: str = 'small'</em>, <em class="sig-param">freeze_weights: bool = True</em>, <em class="sig-param">download_dir: str = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/frontend/whisper.html#WhisperFrontend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.whisper.WhisperFrontend" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.frontend.abs_frontend.AbsFrontend" title="espnet2.asr.frontend.abs_frontend.AbsFrontend"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.frontend.abs_frontend.AbsFrontend</span></code></a></p>
<p>Speech Representation Using Encoder Outputs from OpenAI’s Whisper Model:</p>
<p>URL: <a class="reference external" href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></p>
<dl class="method">
<dt id="espnet2.asr.frontend.whisper.WhisperFrontend.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/frontend/whisper.html#WhisperFrontend.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.whisper.WhisperFrontend.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.whisper.WhisperFrontend.log_mel_spectrogram">
<code class="sig-name descname">log_mel_spectrogram</code><span class="sig-paren">(</span><em class="sig-param">audio: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/frontend/whisper.html#WhisperFrontend.log_mel_spectrogram"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.whisper.WhisperFrontend.log_mel_spectrogram" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.whisper.WhisperFrontend.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/frontend/whisper.html#WhisperFrontend.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.whisper.WhisperFrontend.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.frontend.whisper.WhisperFrontend.whisper_encode">
<code class="sig-name descname">whisper_encode</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/frontend/whisper.html#WhisperFrontend.whisper_encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.frontend.whisper.WhisperFrontend.whisper_encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-frontend-init-1">
<span id="espnet2-asr-frontend-init"></span><h2>espnet2.asr.frontend.__init__<a class="headerlink" href="#espnet2-asr-frontend-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.frontend.__init__"></span></section>
<section id="espnet2-asr-state-spaces-pool-1">
<span id="espnet2-asr-state-spaces-pool"></span><h2>espnet2.asr.state_spaces.pool<a class="headerlink" href="#espnet2-asr-state-spaces-pool-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.pool"></span><p>Implements downsampling and upsampling on sequences.</p>
<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.DownAvgPool">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">DownAvgPool</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownAvgPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownAvgPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownAvgPool.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownAvgPool.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownAvgPool.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownAvgPool.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownAvgPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownAvgPool.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownAvgPool.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownAvgPool.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.DownLinearPool">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">DownLinearPool</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownLinearPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownLinearPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownLinearPool.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownLinearPool.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownLinearPool.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownLinearPool.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownLinearPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownLinearPool.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownLinearPool.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownLinearPool.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.DownPool">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">DownPool</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">d_output=None</em>, <em class="sig-param">expand=None</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">transposed=True</em>, <em class="sig-param">weight_norm=True</em>, <em class="sig-param">initializer=None</em>, <em class="sig-param">activation=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownPool.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em>, <em class="sig-param">device=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownPool.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownPool.default_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Create initial state for a batch of inputs.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownPool.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownPool.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownPool.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownPool.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownPool.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step one time step as a recurrent model.</p>
<p>x: (…, H)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.DownPool2d">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">DownPool2d</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">d_output</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">transposed=True</em>, <em class="sig-param">weight_norm=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownPool2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownPool2d.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownPool2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.DownSample">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">DownSample</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownSample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSample" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownSample.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSample.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownSample.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownSample.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSample.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownSample.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownSample.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSample.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.DownSpectralPool">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">DownSpectralPool</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownSpectralPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSpectralPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownSpectralPool.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSpectralPool.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownSpectralPool.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownSpectralPool.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSpectralPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>x: (B, L…, D)</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.DownSpectralPool.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#DownSpectralPool.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.DownSpectralPool.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.UpPool">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">UpPool</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">d_output</em>, <em class="sig-param">stride</em>, <em class="sig-param">transposed=True</em>, <em class="sig-param">weight_norm=True</em>, <em class="sig-param">initializer=None</em>, <em class="sig-param">activation=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpPool.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpPool.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpPool.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em>, <em class="sig-param">device=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpPool.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpPool.default_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Create initial state for a batch of inputs.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpPool.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">skip=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpPool.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpPool.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpPool.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpPool.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step one time step as a recurrent model.</p>
<p>x: (…, H)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.pool.UpSample">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">UpSample</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpSample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpSample" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpSample.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpSample.d_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpSample.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpSample.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpSample.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.pool.UpSample.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#UpSample.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.UpSample.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.pool.downsample">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">downsample</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#downsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.downsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.pool.upsample">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.pool.</code><code class="sig-name descname">upsample</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">expand=1</em>, <em class="sig-param">transposed=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/pool.html#upsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.pool.upsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-state-spaces-base-1">
<span id="espnet2-asr-state-spaces-base"></span><h2>espnet2.asr.state_spaces.base<a class="headerlink" href="#espnet2-asr-state-spaces-base-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.base"></span><dl class="class">
<dt id="espnet2.asr.state_spaces.base.SequenceIdentity">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.base.</code><code class="sig-name descname">SequenceIdentity</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#SequenceIdentity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceIdentity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceIdentity" title="espnet2.asr.state_spaces.base.SequenceIdentity"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceIdentity</span></code></a></p>
<p>Simple SequenceModule for testing purposes.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceIdentity.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#SequenceIdentity.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceIdentity.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.base.SequenceModule">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.base.</code><code class="sig-name descname">SequenceModule</code><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#SequenceModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Abstract sequence model class.</p>
<p>All models must adhere to this interface</p>
<p>A SequenceModule is generally a model that transforms an input of shape
(n_batch, l_sequence, d_model) to (n_batch, l_sequence, d_output)</p>
<p>REQUIRED methods and attributes
forward, d_model, d_output: controls standard forward pass,
a sequence-to-sequence transformation
__init__ should also satisfy the following interface;
see SequenceIdentity for an example</p>
<blockquote>
<div><p>def __init__(self, d_model, transposed=False, <a href="#system-message-1"><span class="problematic" id="problematic-1">**</span></a>kwargs)</p>
</div></blockquote>
<p>OPTIONAL methods
default_state, step: allows stepping the model recurrently with a hidden state
state_to_tensor, d_state: allows decoding from hidden state</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.d_model">
<em class="property">property </em><code class="sig-name descname">d_model</code><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.d_model" title="Permalink to this definition">¶</a></dt>
<dd><p>Model dimension (generally same as input dimension).</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, encoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.d_state">
<em class="property">property </em><code class="sig-name descname">d_state</code><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.d_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return dimension of output of self.state_to_tensor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em>, <em class="sig-param">device=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#SequenceModule.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.default_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Create initial state for a batch of inputs.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#SequenceModule.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.state_to_tensor">
<em class="property">property </em><code class="sig-name descname">state_to_tensor</code><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.state_to_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a function mapping a state to a single tensor.</p>
<p>This method should be implemented if one wants to use
the hidden state insteadof the output sequence for final prediction.
Currently only used with the StateDecoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.base.SequenceModule.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#SequenceModule.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.SequenceModule.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.base.TransposedModule">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.base.</code><code class="sig-name descname">TransposedModule</code><span class="sig-paren">(</span><em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/base.html#TransposedModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.base.TransposedModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Transpose module.</p>
<p>Wrap a SequenceModule class to accept transposed parameter,
handle state, absorb kwargs</p>
</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-block-1">
<span id="espnet2-asr-state-spaces-block"></span><h2>espnet2.asr.state_spaces.block<a class="headerlink" href="#espnet2-asr-state-spaces-block-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.block"></span><p>Implements a full residual block around a black box layer.</p>
<p>Configurable options include:
normalization position: prenorm or postnorm
normalization type: batchnorm, layernorm etc.
subsampling/pooling
residual options: feedforward, residual, affine scalars, depth-dependent scaling, etc.</p>
<dl class="class">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.block.</code><code class="sig-name descname">SequenceResidualBlock</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">i_layer=None</em>, <em class="sig-param">prenorm=True</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">tie_dropout=False</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">layer=None</em>, <em class="sig-param">residual=None</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">pool=None</em>, <em class="sig-param">drop_path=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/block.html#SequenceResidualBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<p>Residual block wrapper for black box layer.</p>
<p>The SequenceResidualBlock class implements a generic
(batch, length, d_input) -&gt; (batch, length, d_input) transformation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_input</strong> – Input feature dimension</p></li>
<li><p><strong>i_layer</strong> – Layer index, only needs to be passed into certain residuals like Decay</p></li>
<li><p><strong>dropout</strong> – Dropout for black box module</p></li>
<li><p><strong>tie_dropout</strong> – Tie dropout mask across sequence like nn.Dropout1d/nn.Dropout2d</p></li>
<li><p><strong>transposed</strong> – Transpose inputs so each layer receives (batch, dim, length)</p></li>
<li><p><strong>layer</strong> – Config for black box module</p></li>
<li><p><strong>residual</strong> – Config for residual function</p></li>
<li><p><strong>norm</strong> – Config for normalization layer</p></li>
<li><p><strong>pool</strong> – Config for pooling layer per stage</p></li>
<li><p><strong>drop_path</strong> – Drop ratio for stochastic depth</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock.d_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Output dimension of model.</p>
<p>This attribute is required for all SequenceModule instantiations.
It is used by the rest of the pipeline
(e.g. model backbone, decoder) to track the internal shapes of the full model.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock.d_state">
<em class="property">property </em><code class="sig-name descname">d_state</code><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock.d_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return dimension of output of self.state_to_tensor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/block.html#SequenceResidualBlock.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock.default_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Create initial state for a batch of inputs.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/block.html#SequenceResidualBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock.state_to_tensor">
<em class="property">property </em><code class="sig-name descname">state_to_tensor</code><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock.state_to_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a function mapping a state to a single tensor.</p>
<p>This method should be implemented if one wants to use
the hidden state insteadof the output sequence for final prediction.
Currently only used with the StateDecoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.block.SequenceResidualBlock.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/block.html#SequenceResidualBlock.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.block.SequenceResidualBlock.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-residual-1">
<span id="espnet2-asr-state-spaces-residual"></span><h2>espnet2.asr.state_spaces.residual<a class="headerlink" href="#espnet2-asr-state-spaces-residual-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.residual"></span><p>Implementations of different types of residual functions.</p>
<dl class="class">
<dt id="espnet2.asr.state_spaces.residual.Affine">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.residual.</code><code class="sig-name descname">Affine</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">scalar=True</em>, <em class="sig-param">gamma=0.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Affine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Affine" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.residual.Residual" title="espnet2.asr.state_spaces.residual.Residual"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.residual.Residual</span></code></a></p>
<p>Residual connection with learnable scalar multipliers on the main branch.</p>
<p>scalar: Single scalar multiplier, or one per dimension
scale, power: Initialize to scale * layer_num**(-power)</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.residual.Affine.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">transposed</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Affine.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Affine.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.residual.DecayResidual">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.residual.</code><code class="sig-name descname">DecayResidual</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">power=0.5</em>, <em class="sig-param">l2=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#DecayResidual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.DecayResidual" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.residual.Residual" title="espnet2.asr.state_spaces.residual.Residual"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.residual.Residual</span></code></a></p>
<p>Residual connection that can decay the linear combination depending on depth.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.residual.DecayResidual.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">transposed</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#DecayResidual.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.DecayResidual.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.residual.Feedforward">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.residual.</code><code class="sig-name descname">Feedforward</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Feedforward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Feedforward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.residual.Residual" title="espnet2.asr.state_spaces.residual.Residual"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.residual.Residual</span></code></a></p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.residual.Highway">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.residual.</code><code class="sig-name descname">Highway</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">scaling_correction=False</em>, <em class="sig-param">elemwise=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Highway"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Highway" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.residual.Residual" title="espnet2.asr.state_spaces.residual.Residual"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.residual.Residual</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.residual.Highway.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">transposed=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Highway.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Highway.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.residual.Residual">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.residual.</code><code class="sig-name descname">Residual</code><span class="sig-paren">(</span><em class="sig-param">i_layer</em>, <em class="sig-param">d_input</em>, <em class="sig-param">d_model</em>, <em class="sig-param">alpha=1.0</em>, <em class="sig-param">beta=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Residual"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Residual" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Residual connection with constant affine weights.</p>
<p>Can simulate standard residual, no residual, and “constant gates”.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.residual.Residual.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Residual.d_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.residual.Residual.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">transposed</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/residual.html#Residual.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.residual.Residual.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-model-1">
<span id="espnet2-asr-state-spaces-model"></span><h2>espnet2.asr.state_spaces.model<a class="headerlink" href="#espnet2-asr-state-spaces-model-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.model"></span><dl class="class">
<dt id="espnet2.asr.state_spaces.model.SequenceModel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.model.</code><code class="sig-name descname">SequenceModel</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">n_layers=1</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">tie_dropout=False</em>, <em class="sig-param">prenorm=True</em>, <em class="sig-param">n_repeat=1</em>, <em class="sig-param">layer=None</em>, <em class="sig-param">residual=None</em>, <em class="sig-param">norm=None</em>, <em class="sig-param">pool=None</em>, <em class="sig-param">track_norms=True</em>, <em class="sig-param">dropinp=0.0</em>, <em class="sig-param">drop_path=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/model.html#SequenceModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.model.SequenceModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<p>Isotropic deep sequence model backbone, in the style of ResNets / Transformers.</p>
<p>The SequenceModel class implements a generic
(batch, length, d_input) -&gt; (batch, length, d_output) transformation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> – Resize input (useful for deep models with residuals)</p></li>
<li><p><strong>n_layers</strong> – Number of layers</p></li>
<li><p><strong>transposed</strong> – Transpose inputs so each layer receives (batch, dim, length)</p></li>
<li><p><strong>dropout</strong> – Dropout parameter applied on every residual and every layer</p></li>
<li><p><strong>tie_dropout</strong> – Tie dropout mask across sequence like nn.Dropout1d/nn.Dropout2d</p></li>
<li><p><strong>prenorm</strong> – Pre-norm vs. post-norm</p></li>
<li><p><strong>n_repeat</strong> – Each layer is repeated n times per stage before applying pooling</p></li>
<li><p><strong>layer</strong> – Layer config, must be specified</p></li>
<li><p><strong>residual</strong> – Residual config</p></li>
<li><p><strong>norm</strong> – Normalization config (e.g. layer vs batch)</p></li>
<li><p><strong>pool</strong> – Config for pooling layer per stage</p></li>
<li><p><strong>track_norms</strong> – Log norms of each layer output</p></li>
<li><p><strong>dropinp</strong> – Input dropout</p></li>
<li><p><strong>drop_path</strong> – Stochastic depth for each residual path</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.state_spaces.model.SequenceModel.d_state">
<em class="property">property </em><code class="sig-name descname">d_state</code><a class="headerlink" href="#espnet2.asr.state_spaces.model.SequenceModel.d_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return dimension of output of self.state_to_tensor.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.model.SequenceModel.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em>, <em class="sig-param">device=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/model.html#SequenceModel.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.model.SequenceModel.default_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Create initial state for a batch of inputs.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.model.SequenceModel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">*args</em>, <em class="sig-param">state=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/model.html#SequenceModel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.model.SequenceModel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.model.SequenceModel.state_to_tensor">
<em class="property">property </em><code class="sig-name descname">state_to_tensor</code><a class="headerlink" href="#espnet2.asr.state_spaces.model.SequenceModel.state_to_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a function mapping a state to a single tensor.</p>
<p>This method should be implemented if one wants to use
the hidden state insteadof the output sequence for final prediction.
Currently only used with the StateDecoder.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.model.SequenceModel.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/model.html#SequenceModel.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.model.SequenceModel.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-registry-1">
<span id="espnet2-asr-state-spaces-registry"></span><h2>espnet2.asr.state_spaces.registry<a class="headerlink" href="#espnet2-asr-state-spaces-registry-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.registry"></span></section>
<section id="espnet2-asr-state-spaces-components-1">
<span id="espnet2-asr-state-spaces-components"></span><h2>espnet2.asr.state_spaces.components<a class="headerlink" href="#espnet2-asr-state-spaces-components-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.components"></span><dl class="function">
<dt id="espnet2.asr.state_spaces.components.Activation">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">Activation</code><span class="sig-paren">(</span><em class="sig-param">activation=None</em>, <em class="sig-param">size=None</em>, <em class="sig-param">dim=-1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#Activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.Activation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.DropoutNd">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">DropoutNd</code><span class="sig-paren">(</span><em class="sig-param">p: float = 0.5</em>, <em class="sig-param">tie=True</em>, <em class="sig-param">transposed=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#DropoutNd"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.DropoutNd" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize dropout module.</p>
<p>tie: tie dropout mask across sequence lengths (Dropout1d/2d/3d)</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.DropoutNd.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">X</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#DropoutNd.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.DropoutNd.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>X: (batch, dim, lengths…)</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.components.LinearActivation">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">LinearActivation</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">d_output</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">zero_bias_init=False</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">initializer=None</em>, <em class="sig-param">activation=None</em>, <em class="sig-param">activate=False</em>, <em class="sig-param">weight_norm=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#LinearActivation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.LinearActivation" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a linear module, initialization, and activation.</p>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.Normalization">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">Normalization</code><span class="sig-paren">(</span><em class="sig-param">d</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">_name_='layer'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#Normalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.Normalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.Normalization.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#Normalization.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.Normalization.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.components.Normalization.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#Normalization.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.Normalization.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dInput">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">ReversibleInstanceNorm1dInput</code><span class="sig-paren">(</span><em class="sig-param">d</em>, <em class="sig-param">transposed=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#ReversibleInstanceNorm1dInput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dInput" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dInput.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#ReversibleInstanceNorm1dInput.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dInput.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dOutput">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">ReversibleInstanceNorm1dOutput</code><span class="sig-paren">(</span><em class="sig-param">norm_input</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#ReversibleInstanceNorm1dOutput"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dOutput" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dOutput.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#ReversibleInstanceNorm1dOutput.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.ReversibleInstanceNorm1dOutput.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.SquaredReLU">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">SquaredReLU</code><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#SquaredReLU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.SquaredReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.SquaredReLU.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#SquaredReLU.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.SquaredReLU.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.StochasticDepth">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">StochasticDepth</code><span class="sig-paren">(</span><em class="sig-param">p: float</em>, <em class="sig-param">mode: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#StochasticDepth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.StochasticDepth" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Stochastic depth module.</p>
<p>See <a class="reference internal" href="#espnet2.asr.state_spaces.components.stochastic_depth" title="espnet2.asr.state_spaces.components.stochastic_depth"><code class="xref py py-func docutils literal notranslate"><span class="pre">stochastic_depth()</span></code></a>.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.StochasticDepth.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#StochasticDepth.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.StochasticDepth.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.TSInverseNormalization">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">TSInverseNormalization</code><span class="sig-paren">(</span><em class="sig-param">method</em>, <em class="sig-param">normalizer</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TSInverseNormalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TSInverseNormalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.TSInverseNormalization.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TSInverseNormalization.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TSInverseNormalization.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.TSNormalization">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">TSNormalization</code><span class="sig-paren">(</span><em class="sig-param">method</em>, <em class="sig-param">horizon</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TSNormalization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TSNormalization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.TSNormalization.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TSNormalization.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TSNormalization.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.TransposedLN">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">TransposedLN</code><span class="sig-paren">(</span><em class="sig-param">d</em>, <em class="sig-param">scalar=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TransposedLN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TransposedLN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transposed LayerNorm module.</p>
<p>LayerNorm module over second dimension
Assumes shape (B, D, L), where L can be 1 or more axis</p>
<p>This is slow and a dedicated CUDA/Triton implementation
shuld provide substantial end-to-end speedup</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.TransposedLN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TransposedLN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TransposedLN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.components.TransposedLinear">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">TransposedLinear</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">d_output</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TransposedLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TransposedLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transposed linear module.</p>
<p>Linear module on the second-to-last dimension
Assumes shape (B, D, L), where L can be 1 or more axis</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.components.TransposedLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#TransposedLinear.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.TransposedLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.components.get_initializer">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">get_initializer</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">activation=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#get_initializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.get_initializer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.components.stochastic_depth">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.components.</code><code class="sig-name descname">stochastic_depth</code><span class="sig-paren">(</span><em class="sig-param">input: torch._VariableFunctionsClass.tensor</em>, <em class="sig-param">p: float</em>, <em class="sig-param">mode: str</em>, <em class="sig-param">training: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/components.html#stochastic_depth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.components.stochastic_depth" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply stochastic depth.</p>
<p>Implements the Stochastic Depth from <a class="reference external" href="https://arxiv.org/abs/1603.09382">“Deep Networks with Stochastic Depth”</a> used for randomly dropping residual
branches of residual architectures.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<em>Tensor</em><em>[</em><em>N</em><em>, </em><em>..</em><em>]</em>) – The input tensor or arbitrary dimensions with the first
one being its batch i.e. a batch with <code class="docutils literal notranslate"><span class="pre">N</span></code> rows.</p></li>
<li><p><strong>p</strong> (<em>float</em>) – probability of the input to be zeroed.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – <code class="docutils literal notranslate"><span class="pre">&quot;batch&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;row&quot;</span></code>.
<code class="docutils literal notranslate"><span class="pre">&quot;batch&quot;</span></code> randomly zeroes the entire input, <code class="docutils literal notranslate"><span class="pre">&quot;row&quot;</span></code> zeroes
randomly selected rows from the batch.</p></li>
<li><p><strong>training</strong> – apply stochastic depth if is <code class="docutils literal notranslate"><span class="pre">True</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The randomly zeroed tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor[N, ..]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-cauchy-1">
<span id="espnet2-asr-state-spaces-cauchy"></span><h2>espnet2.asr.state_spaces.cauchy<a class="headerlink" href="#espnet2-asr-state-spaces-cauchy-1" title="Permalink to this headline">¶</a></h2>
</section>
<section id="espnet2-asr-state-spaces-s4-1">
<span id="espnet2-asr-state-spaces-s4"></span><h2>espnet2.asr.state_spaces.s4<a class="headerlink" href="#espnet2-asr-state-spaces-s4-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.s4"></span><p>Standalone version of Structured (Sequence) State Space (S4) model.</p>
<dl class="class">
<dt id="espnet2.asr.state_spaces.s4.OptimModule">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">OptimModule</code><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#OptimModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.OptimModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Interface for Module that allows registering buffers/parameters with configurable optimizer hyperparameters. # noqa</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.OptimModule.register">
<code class="sig-name descname">register</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">tensor</em>, <em class="sig-param">lr=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#OptimModule.register"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.OptimModule.register" title="Permalink to this definition">¶</a></dt>
<dd><p>Register a tensor with a configurable learning rate and 0 weight decay.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.s4.S4">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">S4</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">d_state=64</em>, <em class="sig-param">l_max=None</em>, <em class="sig-param">channels=1</em>, <em class="sig-param">bidirectional=False</em>, <em class="sig-param">activation='gelu'</em>, <em class="sig-param">postact='glu'</em>, <em class="sig-param">hyper_act=None</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">tie_dropout=False</em>, <em class="sig-param">bottleneck=None</em>, <em class="sig-param">gate=None</em>, <em class="sig-param">transposed=True</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">**kernel_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#S4"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.S4" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initialize S4 module.</p>
<p>d_state: the dimension of the state, also denoted by N
l_max: the maximum kernel length, also denoted by L.</p>
<blockquote>
<div><p>Set l_max=None to always use a global kernel</p>
</div></blockquote>
<dl class="simple">
<dt>channels: can be interpreted as a number of “heads”;</dt><dd><p>the SSM is a map from a 1-dim to C-dim sequence.
It’s not recommended to change this unless desperate for things to tune;
instead, increase d_model for larger models</p>
</dd>
</dl>
<p>bidirectional: if True, convolution kernel will be two-sided</p>
<p>activation: activation in between SS and FF
postact: activation after FF
hyper_act: use a “hypernetwork” multiplication (experimental)
dropout: standard dropout argument. tie_dropout=True ties the dropout</p>
<blockquote>
<div><p>mask across the sequence length, emulating nn.Dropout1d</p>
</div></blockquote>
<dl class="simple">
<dt>transposed: choose backbone axis ordering of</dt><dd><p>(B, L, H) (if False) or (B, H, L) (if True)
[B=batch size, L=sequence length, H=hidden dimension]</p>
</dd>
</dl>
<p>gate: add gated activation (GSS)
bottleneck: reduce SSM dimension (GSS)</p>
<p>See the class SSKernel for the kernel constructor which accepts kernel_args.
Relevant options that are worth considering
and tuning include “mode” + “measure”, “dt_min”, “dt_max”, “lr”</p>
<p>Other options are all experimental and should not need to be configured</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.S4.d_output">
<em class="property">property </em><code class="sig-name descname">d_output</code><a class="headerlink" href="#espnet2.asr.state_spaces.s4.S4.d_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.S4.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em>, <em class="sig-param">device=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#S4.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.S4.default_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.S4.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state=None</em>, <em class="sig-param">rate=1.0</em>, <em class="sig-param">lengths=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#S4.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.S4.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>u: (B H L) if self.transposed else (B L H)
state: (H N) never needed unless you know what you’re doing</p>
<p>Returns: same shape as u</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.S4.setup_step">
<code class="sig-name descname">setup_step</code><span class="sig-paren">(</span><em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#S4.setup_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.S4.setup_step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.S4.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#S4.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.S4.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step one time step as a recurrent model.</p>
<p>Intended to be used during validation.</p>
<p>u: (B H)
state: (B H N)
Returns: output (B H), state (B H N)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.s4.SSKernel">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">SSKernel</code><span class="sig-paren">(</span><em class="sig-param">H</em>, <em class="sig-param">N=64</em>, <em class="sig-param">L=None</em>, <em class="sig-param">measure='legs'</em>, <em class="sig-param">rank=1</em>, <em class="sig-param">channels=1</em>, <em class="sig-param">dt_min=0.001</em>, <em class="sig-param">dt_max=0.1</em>, <em class="sig-param">deterministic=False</em>, <em class="sig-param">lr=None</em>, <em class="sig-param">mode='nplr'</em>, <em class="sig-param">n_ssm=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">measure_args={}</em>, <em class="sig-param">**kernel_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Wrapper around SSKernel parameterizations.</p>
<p>The SSKernel is expected to support the interface
forward()
default_state()
_setup_step()
step()</p>
<p>State Space Kernel which computes the convolution kernel $\bar{K}$.</p>
<dl class="simple">
<dt>H: Number of independent SSM copies;</dt><dd><p>controls the size of the model. Also called d_model in the config.</p>
</dd>
<dt>N: State size (dimensionality of parameters A, B, C).</dt><dd><p>Also called d_state in the config.
Generally shouldn’t need to be adjusted and doens’t affect speed much.</p>
</dd>
<dt>L: Maximum length of convolution kernel, if known.</dt><dd><p>Should work in the majority of cases even if not known.</p>
</dd>
<dt>measure: Options for initialization of (A, B).</dt><dd><p>For NPLR mode, recommendations are “legs”,
“fout”, “hippo” (combination of both).
For Diag mode, recommendations are “diag-inv”,
“diag-lin”, “diag-legs”, and “diag” (combination of diag-inv and diag-lin)</p>
</dd>
<dt>rank: Rank of low-rank correction for NPLR mode.</dt><dd><p>Needs to be increased for measure “legt”</p>
</dd>
<dt>channels: C channels turns the SSM from a 1-dim to C-dim map;</dt><dd><p>can think of it having C separate “heads” per SSM.
This was partly a feature to make it easier to implement bidirectionality;
it is recommended to set channels=1
and adjust H to control parameters instead</p>
</dd>
</dl>
<p>dt_min, dt_max: min and max values for the step size dt (Delta)
mode: Which kernel algorithm to use. ‘nplr’ is the full S4 model;</p>
<blockquote>
<div><p>‘diag’ is the simpler S4D; ‘slow’ is a dense version for testing</p>
</div></blockquote>
<dl class="simple">
<dt>n_ssm: Number of independent trainable (A, B) SSMs,</dt><dd><p>e.g. n_ssm=1 means all A/B parameters are tied across
the H different instantiations of C.
n_ssm=None means all H SSMs are completely independent.
Generally, changing this option can save parameters but doesn’t affect
performance or speed much. This parameter must divide H</p>
</dd>
<dt>lr: Passing in a number (e.g. 0.001) sets</dt><dd><p>attributes of SSM parameers (A, B, dt).
A custom optimizer hook is needed to configure the optimizer
to set the learning rates appropriately for these parameters.</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernel.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernel.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernel.default_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">state=None</em>, <em class="sig-param">L=None</em>, <em class="sig-param">rate=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernel.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernel.forward_state">
<code class="sig-name descname">forward_state</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernel.forward_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernel.forward_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward the state through a sequence.</p>
<p>i.e. computes the state after passing chunk through SSM</p>
<p>state: (B, H, N)
u: (B, H, L)</p>
<p>Returns: (B, H, N)</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernel.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernel.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernel.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.s4.SSKernelDiag">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">SSKernelDiag</code><span class="sig-paren">(</span><em class="sig-param">A</em>, <em class="sig-param">B</em>, <em class="sig-param">C</em>, <em class="sig-param">log_dt</em>, <em class="sig-param">L=None</em>, <em class="sig-param">disc='bilinear'</em>, <em class="sig-param">real_type='exp'</em>, <em class="sig-param">lr=None</em>, <em class="sig-param">bandlimit=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelDiag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelDiag" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.s4.OptimModule" title="espnet2.asr.state_spaces.s4.OptimModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.s4.OptimModule</span></code></a></p>
<p>Version using (complex) diagonal state matrix (S4D).</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelDiag.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelDiag.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelDiag.default_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelDiag.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">L</em>, <em class="sig-param">state=None</em>, <em class="sig-param">rate=1.0</em>, <em class="sig-param">u=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelDiag.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelDiag.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>state: (B, H, N) initial state
rate: sampling rate factor
L: target length</p>
<p>returns:
(C, H, L) convolution kernel (generally C=1)
(B, H, L) output from initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelDiag.forward_state">
<code class="sig-name descname">forward_state</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelDiag.forward_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelDiag.forward_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelDiag.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelDiag.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelDiag.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.state_spaces.s4.SSKernelNPLR">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">SSKernelNPLR</code><span class="sig-paren">(</span><em class="sig-param">w</em>, <em class="sig-param">P</em>, <em class="sig-param">B</em>, <em class="sig-param">C</em>, <em class="sig-param">log_dt</em>, <em class="sig-param">L=None</em>, <em class="sig-param">lr=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">keops=False</em>, <em class="sig-param">real_type='exp'</em>, <em class="sig-param">real_tolerance=0.001</em>, <em class="sig-param">bandlimit=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelNPLR"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelNPLR" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.s4.OptimModule" title="espnet2.asr.state_spaces.s4.OptimModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.s4.OptimModule</span></code></a></p>
<p>Stores a representation of and computes the SSKernel function.</p>
<p>K_L(A^dt, B^dt, C) corresponding to a discretized state space,
where A is Normal + Low Rank (NPLR)</p>
<p>Initialize kernel.</p>
<p>L: Maximum length; this module computes an SSM kernel of length L
A is represented by diag(w) - PP^*
w: (S, N) diagonal part
P: (R, S, N) low-rank part</p>
<p>B: (S, N)
C: (C, H, N)
dt: (H) timescale per feature
lr: [dict | float | None] hook to set lr of special parameters (A, B, dt)</p>
<p>Dimensions:
N (or d_state): state size
H (or d_model): total SSM copies
S (or n_ssm): number of trainable copies of (A, B, dt); must divide H
R (or rank): rank of low-rank part
C (or channels): system is 1-dim to C-dim</p>
<p>The forward pass of this Module returns a tensor of shape (C, H, L)</p>
<dl class="simple">
<dt>Note: tensor shape N here denotes half the true state size,</dt><dd><p>because of conjugate symmetry</p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelNPLR.default_state">
<code class="sig-name descname">default_state</code><span class="sig-paren">(</span><em class="sig-param">*batch_shape</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelNPLR.default_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelNPLR.default_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelNPLR.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">state=None</em>, <em class="sig-param">rate=1.0</em>, <em class="sig-param">L=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelNPLR.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelNPLR.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>state: (B, H, N) initial state
rate: sampling rate factor
L: target length</p>
<p>returns:
(C, H, L) convolution kernel (generally C=1)
(B, H, L) output from initial state</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.s4.SSKernelNPLR.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#SSKernelNPLR.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.SSKernelNPLR.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step one time step as a recurrent model.</p>
<p>Must have called self._setup_step()
and created state with self.default_state() before calling this</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.cauchy_naive">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">cauchy_naive</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">z</em>, <em class="sig-param">w</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#cauchy_naive"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.cauchy_naive" title="Permalink to this definition">¶</a></dt>
<dd><p>Naive version.</p>
<p>v, w: (…, N)
z: (…, L)
returns: (…, L)</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.combination">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">combination</code><span class="sig-paren">(</span><em class="sig-param">measures</em>, <em class="sig-param">N</em>, <em class="sig-param">R</em>, <em class="sig-param">S</em>, <em class="sig-param">**ssm_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#combination"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.combination" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.dplr">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">dplr</code><span class="sig-paren">(</span><em class="sig-param">scaling</em>, <em class="sig-param">N</em>, <em class="sig-param">rank=1</em>, <em class="sig-param">H=1</em>, <em class="sig-param">dtype=torch.float32</em>, <em class="sig-param">real_scale=1.0</em>, <em class="sig-param">imag_scale=1.0</em>, <em class="sig-param">random_real=False</em>, <em class="sig-param">random_imag=False</em>, <em class="sig-param">normalize=False</em>, <em class="sig-param">diagonal=True</em>, <em class="sig-param">random_B=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#dplr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.dplr" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.get_logger">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">get_logger</code><span class="sig-paren">(</span><em class="sig-param">name='espnet2.asr.state_spaces.s4'</em>, <em class="sig-param">level=20</em><span class="sig-paren">)</span> &#x2192; logging.Logger<a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#get_logger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.get_logger" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize multi-GPU-friendly python logger.</p>
</dd></dl>

<dl class="data">
<dt id="espnet2.asr.state_spaces.s4.log">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">log</code><em class="property"> = &lt;Logger espnet2.asr.state_spaces.s4 (INFO)&gt;</em><a class="reference internal" href="../_modules/logging.html#log"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Cauchy and Vandermonde kernels</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.log_vandermonde">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">log_vandermonde</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">x</em>, <em class="sig-param">L</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#log_vandermonde"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.log_vandermonde" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Vandermonde product.</p>
<p>v: (…, N)
x: (…, N)
returns: (…, L) sum v x^l</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.log_vandermonde_transpose">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">log_vandermonde_transpose</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">v</em>, <em class="sig-param">x</em>, <em class="sig-param">L</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#log_vandermonde_transpose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.log_vandermonde_transpose" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.nplr">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">nplr</code><span class="sig-paren">(</span><em class="sig-param">measure</em>, <em class="sig-param">N</em>, <em class="sig-param">rank=1</em>, <em class="sig-param">dtype=torch.float32</em>, <em class="sig-param">diagonalize_precision=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#nplr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.nplr" title="Permalink to this definition">¶</a></dt>
<dd><p>Decompose as Normal Plus Low-Rank (NPLR).</p>
<p>Return w, p, q, V, B such that
(w - p q^*, B) is unitarily equivalent to the original HiPPO A, B by the matrix V
i.e. A = V[w - p q^*]V^*, B = V B</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.power">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">power</code><span class="sig-paren">(</span><em class="sig-param">L</em>, <em class="sig-param">A</em>, <em class="sig-param">v=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#power"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.power" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute A^L and the scan sum_i A^i v_i.</p>
<p>A: (…, N, N)
v: (…, N, L)</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.rank_correction">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">rank_correction</code><span class="sig-paren">(</span><em class="sig-param">measure</em>, <em class="sig-param">N</em>, <em class="sig-param">rank=1</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#rank_correction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.rank_correction" title="Permalink to this definition">¶</a></dt>
<dd><p>Return low-rank matrix L such that A + L is normal.</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.rank_zero_only">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">rank_zero_only</code><span class="sig-paren">(</span><em class="sig-param">fn: Callable</em><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#rank_zero_only"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.rank_zero_only" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator function from PyTorch Lightning.</p>
<p>Function that can be used as a decorator
to enable a function/method being called only on global rank 0.</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.ssm">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">ssm</code><span class="sig-paren">(</span><em class="sig-param">measure</em>, <em class="sig-param">N</em>, <em class="sig-param">R</em>, <em class="sig-param">H</em>, <em class="sig-param">**ssm_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#ssm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.ssm" title="Permalink to this definition">¶</a></dt>
<dd><p>Dispatcher to create single SSM initialization.</p>
<p>N: state size
R: rank (for DPLR parameterization)
H: number of independent SSM copies</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.s4.transition">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.s4.</code><code class="sig-name descname">transition</code><span class="sig-paren">(</span><em class="sig-param">measure</em>, <em class="sig-param">N</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/s4.html#transition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.s4.transition" title="Permalink to this definition">¶</a></dt>
<dd><p>A, B transition matrices for different measures.</p>
</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-utils-1">
<span id="espnet2-asr-state-spaces-utils"></span><h2>espnet2.asr.state_spaces.utils<a class="headerlink" href="#espnet2-asr-state-spaces-utils-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.utils"></span><p>Utilities for dealing with collection objects (lists, dicts) and configs.</p>
<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.extract_attrs_from_obj">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">extract_attrs_from_obj</code><span class="sig-paren">(</span><em class="sig-param">obj</em>, <em class="sig-param">*attrs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#extract_attrs_from_obj"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.extract_attrs_from_obj" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.get_class">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">get_class</code><span class="sig-paren">(</span><em class="sig-param">registry</em>, <em class="sig-param">_name_</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#get_class"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.get_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.instantiate">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">instantiate</code><span class="sig-paren">(</span><em class="sig-param">registry</em>, <em class="sig-param">config</em>, <em class="sig-param">*args</em>, <em class="sig-param">partial=False</em>, <em class="sig-param">wrap=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#instantiate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.instantiate" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate registered module.</p>
<dl class="simple">
<dt>registry: Dictionary mapping names to functions or target paths</dt><dd><p>(e.g. {‘model’: ‘models.SequenceModel’})</p>
</dd>
<dt>config: Dictionary with a ‘_name_’ key indicating which element of the registry</dt><dd><p>to grab, and kwargs to be passed into the target constructor</p>
</dd>
</dl>
<p>wrap: wrap the target class (e.g. ema optimizer or tasks.wrap)
<a href="#system-message-2"><span class="problematic" id="problematic-2">*</span></a>args, <a href="#system-message-3"><span class="problematic" id="problematic-3">**</span></a>kwargs: additional arguments</p>
<blockquote>
<div><p>to override the config to pass into the target constructor</p>
</div></blockquote>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.is_dict">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">is_dict</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#is_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.is_dict" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.is_list">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">is_list</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#is_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.is_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.omegaconf_filter_keys">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">omegaconf_filter_keys</code><span class="sig-paren">(</span><em class="sig-param">d</em>, <em class="sig-param">fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#omegaconf_filter_keys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.omegaconf_filter_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Only keep keys where fn(key) is True. Support nested DictConfig.</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.to_dict">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">to_dict</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recursive=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#to_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.to_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert Sequence or Mapping object to dict.</p>
<p>lists get converted to {0: x[0], 1: x[1], …}</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.state_spaces.utils.to_list">
<code class="sig-prename descclassname">espnet2.asr.state_spaces.utils.</code><code class="sig-name descname">to_list</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">recursive=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/utils.html#to_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.utils.to_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert an object to list.</p>
<p>If Sequence (e.g. list, tuple, Listconfig): just return it</p>
<p>Special case: If non-recursive and not a list, wrap in list</p>
</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-attention-1">
<span id="espnet2-asr-state-spaces-attention"></span><h2>espnet2.asr.state_spaces.attention<a class="headerlink" href="#espnet2-asr-state-spaces-attention-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.attention"></span><p>Multi-Head Attention layer definition.</p>
<dl class="class">
<dt id="espnet2.asr.state_spaces.attention.MultiHeadedAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.attention.</code><code class="sig-name descname">MultiHeadedAttention</code><span class="sig-paren">(</span><em class="sig-param">n_feat</em>, <em class="sig-param">n_head</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/attention.html#MultiHeadedAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.attention.MultiHeadedAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<p>Multi-Head Attention layer inheriting SequenceModule.</p>
<p>Comparing default MHA module in ESPnet, this module returns additional dummy state
and has step function for autoregressive inference.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_head</strong> (<em>int</em>) – The number of heads.</p></li>
<li><p><strong>n_feat</strong> (<em>int</em>) – The number of features.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
</ul>
</dd>
</dl>
<p>Construct an MultiHeadedAttention object.</p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.attention.MultiHeadedAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">memory=None</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/attention.html#MultiHeadedAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.attention.MultiHeadedAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute scaled dot product attention.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – Query tensor (#batch, time1, size).</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – Key tensor (#batch, time2, size).</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Value tensor (#batch, time2, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor (#batch, 1, time2) or
(#batch, time1, time2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, time1, d_model).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.attention.MultiHeadedAttention.forward_attention">
<code class="sig-name descname">forward_attention</code><span class="sig-paren">(</span><em class="sig-param">value</em>, <em class="sig-param">scores</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/attention.html#MultiHeadedAttention.forward_attention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.attention.MultiHeadedAttention.forward_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute attention context vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Transformed value (#batch, n_head, time2, d_k).</p></li>
<li><p><strong>scores</strong> (<em>torch.Tensor</em>) – Attention score (#batch, n_head, time1, time2).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask (#batch, 1, time2) or (#batch, time1, time2).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed value (#batch, time1, d_model)</dt><dd><p>weighted by the attention score (#batch, time1, time2).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.attention.MultiHeadedAttention.forward_qkv">
<code class="sig-name descname">forward_qkv</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/attention.html#MultiHeadedAttention.forward_qkv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.attention.MultiHeadedAttention.forward_qkv" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform query, key and value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>query</strong> (<em>torch.Tensor</em>) – Query tensor (#batch, time1, size).</p></li>
<li><p><strong>key</strong> (<em>torch.Tensor</em>) – Key tensor (#batch, time2, size).</p></li>
<li><p><strong>value</strong> (<em>torch.Tensor</em>) – Value tensor (#batch, time2, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transformed query tensor (#batch, n_head, time1, d_k).
torch.Tensor: Transformed key tensor (#batch, n_head, time2, d_k).
torch.Tensor: Transformed value tensor (#batch, n_head, time2, d_k).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.attention.MultiHeadedAttention.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">state</em>, <em class="sig-param">memory=None</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/attention.html#MultiHeadedAttention.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.attention.MultiHeadedAttention.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-state-spaces-init-1">
<span id="espnet2-asr-state-spaces-init"></span><h2>espnet2.asr.state_spaces.__init__<a class="headerlink" href="#espnet2-asr-state-spaces-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.__init__"></span><p>Initialize sub package.</p>
</section>
<section id="espnet2-asr-state-spaces-ff-1">
<span id="espnet2-asr-state-spaces-ff"></span><h2>espnet2.asr.state_spaces.ff<a class="headerlink" href="#espnet2-asr-state-spaces-ff-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.state_spaces.ff"></span><p>Implementation of FFN block in the style of Transformers.</p>
<dl class="class">
<dt id="espnet2.asr.state_spaces.ff.FF">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.state_spaces.ff.</code><code class="sig-name descname">FF</code><span class="sig-paren">(</span><em class="sig-param">d_input</em>, <em class="sig-param">expand=2</em>, <em class="sig-param">d_output=None</em>, <em class="sig-param">transposed=False</em>, <em class="sig-param">activation='gelu'</em>, <em class="sig-param">initializer=None</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">tie_dropout=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/ff.html#FF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.ff.FF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.state_spaces.base.SequenceModule" title="espnet2.asr.state_spaces.base.SequenceModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.state_spaces.base.SequenceModule</span></code></a></p>
<dl class="method">
<dt id="espnet2.asr.state_spaces.ff.FF.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/ff.html#FF.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.ff.FF.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward pass.</p>
<p>A sequence-to-sequence transformation with an optional state.</p>
<p>Generally, this should map a tensor of shape
(batch, length, self.d_model) to (batch, length, self.d_output)</p>
<p>Additionally, it returns a “state” which can be any additional information
For example, RNN and SSM layers may return their hidden state,
while some types of transformer layers
(e.g. Transformer-XL) may want to pass a state as well</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.state_spaces.ff.FF.step">
<code class="sig-name descname">step</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/state_spaces/ff.html#FF.step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.state_spaces.ff.FF.step" title="Permalink to this definition">¶</a></dt>
<dd><p>Step the model recurrently for one step of the input sequence.</p>
<p>For example, this should correspond to unrolling an RNN for one step.
If the forward pass has signature (B, L, H1) -&gt; (B, L, H2),
this method should generally have signature
(B, H1) -&gt; (B, H2) with an optional recurrent state.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-preencoder-linear-1">
<span id="espnet2-asr-preencoder-linear"></span><h2>espnet2.asr.preencoder.linear<a class="headerlink" href="#espnet2-asr-preencoder-linear-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.preencoder.linear"></span><p>Linear Projection.</p>
<dl class="class">
<dt id="espnet2.asr.preencoder.linear.LinearProjection">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.preencoder.linear.</code><code class="sig-name descname">LinearProjection</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int</em>, <em class="sig-param">dropout: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/preencoder/linear.html#LinearProjection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.linear.LinearProjection" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder" title="espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder</span></code></a></p>
<p>Linear Projection Preencoder.</p>
<p>Initialize the module.</p>
<dl class="method">
<dt id="espnet2.asr.preencoder.linear.LinearProjection.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/preencoder/linear.html#LinearProjection.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.linear.LinearProjection.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.preencoder.linear.LinearProjection.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/preencoder/linear.html#LinearProjection.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.linear.LinearProjection.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the output size.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-preencoder-abs-preencoder-1">
<span id="espnet2-asr-preencoder-abs-preencoder"></span><h2>espnet2.asr.preencoder.abs_preencoder<a class="headerlink" href="#espnet2-asr-preencoder-abs-preencoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.preencoder.abs_preencoder"></span><dl class="class">
<dt id="espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.preencoder.abs_preencoder.</code><code class="sig-name descname">AbsPreEncoder</code><a class="reference internal" href="../_modules/espnet2/asr/preencoder/abs_preencoder.html#AbsPreEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/preencoder/abs_preencoder.html#AbsPreEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder.output_size">
<em class="property">abstract </em><code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/preencoder/abs_preencoder.html#AbsPreEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-preencoder-sinc-1">
<span id="espnet2-asr-preencoder-sinc"></span><h2>espnet2.asr.preencoder.sinc<a class="headerlink" href="#espnet2-asr-preencoder-sinc-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.preencoder.sinc"></span><p>Sinc convolutions for raw audio input.</p>
<dl class="class">
<dt id="espnet2.asr.preencoder.sinc.LightweightSincConvs">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.preencoder.sinc.</code><code class="sig-name descname">LightweightSincConvs</code><span class="sig-paren">(</span><em class="sig-param">fs: Union[int</em>, <em class="sig-param">str</em>, <em class="sig-param">float] = 16000</em>, <em class="sig-param">in_channels: int = 1</em>, <em class="sig-param">out_channels: int = 256</em>, <em class="sig-param">activation_type: str = 'leakyrelu'</em>, <em class="sig-param">dropout_type: str = 'dropout'</em>, <em class="sig-param">windowing_type: str = 'hamming'</em>, <em class="sig-param">scale_type: str = 'mel'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#LightweightSincConvs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.LightweightSincConvs" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder" title="espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.preencoder.abs_preencoder.AbsPreEncoder</span></code></a></p>
<p>Lightweight Sinc Convolutions.</p>
<p>Instead of using precomputed features, end-to-end speech recognition
can also be done directly from raw audio using sinc convolutions, as
described in “Lightweight End-to-End Speech Recognition from Raw Audio
Data Using Sinc-Convolutions” by Kürzinger et al.
<a class="reference external" href="https://arxiv.org/abs/2010.07597">https://arxiv.org/abs/2010.07597</a></p>
<p>To use Sinc convolutions in your model instead of the default f-bank
frontend, set this module as your pre-encoder with <cite>preencoder: sinc</cite>
and use the input of the sliding window frontend with
<cite>frontend: sliding_window</cite> in your yaml configuration file.
So that the process flow is:</p>
<p>Frontend (SlidingWindow) -&gt; SpecAug -&gt; Normalization -&gt;
Pre-encoder (LightweightSincConvs) -&gt; Encoder -&gt; Decoder</p>
<p>Note that this method also performs data augmentation in time domain
(vs. in spectral domain in the default frontend).
Use <cite>plot_sinc_filters.py</cite> to visualize the learned Sinc filters.</p>
<p>Initialize the module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fs</strong> – Sample rate.</p></li>
<li><p><strong>in_channels</strong> – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> – Number of output channels (for each input channel).</p></li>
<li><p><strong>activation_type</strong> – Choice of activation function.</p></li>
<li><p><strong>dropout_type</strong> – Choice of dropout function.</p></li>
<li><p><strong>windowing_type</strong> – Choice of windowing function.</p></li>
<li><p><strong>scale_type</strong> – Choice of filter-bank initialization scale.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.preencoder.sinc.LightweightSincConvs.espnet_initialization_fn">
<code class="sig-name descname">espnet_initialization_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#LightweightSincConvs.espnet_initialization_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.LightweightSincConvs.espnet_initialization_fn" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize sinc filters with filterbank values.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.preencoder.sinc.LightweightSincConvs.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#LightweightSincConvs.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.LightweightSincConvs.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply Lightweight Sinc Convolutions.</p>
<p>The input shall be formatted as (B, T, C_in, D_in)
with B as batch size, T as time dimension, C_in as channels,
and D_in as feature dimension.</p>
<p>The output will then be (B, T, C_out*D_out)
with C_out and D_out as output dimensions.</p>
<p>The current module structure only handles D_in=400, so that D_out=1.
Remark for the multichannel case: C_out is the number of out_channels
given at initialization multiplied with C_in.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.preencoder.sinc.LightweightSincConvs.gen_lsc_block">
<code class="sig-name descname">gen_lsc_block</code><span class="sig-paren">(</span><em class="sig-param">in_channels: int</em>, <em class="sig-param">out_channels: int</em>, <em class="sig-param">depthwise_kernel_size: int = 9</em>, <em class="sig-param">depthwise_stride: int = 1</em>, <em class="sig-param">depthwise_groups=None</em>, <em class="sig-param">pointwise_groups=0</em>, <em class="sig-param">dropout_probability: float = 0.15</em>, <em class="sig-param">avgpool=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#LightweightSincConvs.gen_lsc_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.LightweightSincConvs.gen_lsc_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a convolutional block for Lightweight Sinc convolutions.</p>
<p>Each block consists of either a depthwise or a depthwise-separable
convolutions together with dropout, (batch-)normalization layer, and
an optional average-pooling layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> – Number of input channels.</p></li>
<li><p><strong>out_channels</strong> – Number of output channels.</p></li>
<li><p><strong>depthwise_kernel_size</strong> – Kernel size of the depthwise convolution.</p></li>
<li><p><strong>depthwise_stride</strong> – Stride of the depthwise convolution.</p></li>
<li><p><strong>depthwise_groups</strong> – Number of groups of the depthwise convolution.</p></li>
<li><p><strong>pointwise_groups</strong> – Number of groups of the pointwise convolution.</p></li>
<li><p><strong>dropout_probability</strong> – Dropout probability in the block.</p></li>
<li><p><strong>avgpool</strong> – If True, an AvgPool layer is inserted.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Neural network building block.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.nn.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.preencoder.sinc.LightweightSincConvs.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#LightweightSincConvs.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.LightweightSincConvs.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the output size.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.preencoder.sinc.SpatialDropout">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.preencoder.sinc.</code><code class="sig-name descname">SpatialDropout</code><span class="sig-paren">(</span><em class="sig-param">dropout_probability: float = 0.15</em>, <em class="sig-param">shape: Union[tuple</em>, <em class="sig-param">list</em>, <em class="sig-param">None] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#SpatialDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.SpatialDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Spatial dropout module.</p>
<p>Apply dropout to full channels on tensors of input (B, C, D)</p>
<p>Initialize.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dropout_probability</strong> – Dropout probability.</p></li>
<li><p><strong>shape</strong> (<em>tuple</em><em>, </em><em>list</em>) – Shape of input tensors.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.preencoder.sinc.SpatialDropout.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/preencoder/sinc.html#SpatialDropout.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.preencoder.sinc.SpatialDropout.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward of spatial dropout module.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-preencoder-init-1">
<span id="espnet2-asr-preencoder-init"></span><h2>espnet2.asr.preencoder.__init__<a class="headerlink" href="#espnet2-asr-preencoder-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.preencoder.__init__"></span></section>
<section id="espnet2-asr-transducer-beam-search-transducer-1">
<span id="espnet2-asr-transducer-beam-search-transducer"></span><h2>espnet2.asr.transducer.beam_search_transducer<a class="headerlink" href="#espnet2-asr-transducer-beam-search-transducer-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.beam_search_transducer"></span><p>Search algorithms for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.beam_search_transducer.</code><code class="sig-name descname">BeamSearchTransducer</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr.decoder.abs_decoder.AbsDecoder</em>, <em class="sig-param">joint_network: espnet2.asr_transducer.joint_network.JointNetwork</em>, <em class="sig-param">beam_size: int</em>, <em class="sig-param">lm: torch.nn.modules.module.Module = None</em>, <em class="sig-param">lm_weight: float = 0.1</em>, <em class="sig-param">search_type: str = 'default'</em>, <em class="sig-param">max_sym_exp: int = 2</em>, <em class="sig-param">u_max: int = 50</em>, <em class="sig-param">nstep: int = 1</em>, <em class="sig-param">prefix_alpha: int = 1</em>, <em class="sig-param">expansion_gamma: int = 2.3</em>, <em class="sig-param">expansion_beta: int = 2</em>, <em class="sig-param">multi_blank_durations: List[int] = []</em>, <em class="sig-param">multi_blank_indices: List[int] = []</em>, <em class="sig-param">score_norm: bool = True</em>, <em class="sig-param">score_norm_during: bool = False</em>, <em class="sig-param">nbest: int = 1</em>, <em class="sig-param">token_list: Optional[List[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Beam search implementation for Transducer.</p>
<p>Initialize Transducer search module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint network module.</p></li>
<li><p><strong>beam_size</strong> – Beam size.</p></li>
<li><p><strong>lm</strong> – LM class.</p></li>
<li><p><strong>lm_weight</strong> – LM weight for soft fusion.</p></li>
<li><p><strong>search_type</strong> – Search algorithm to use during inference.</p></li>
<li><p><strong>max_sym_exp</strong> – Number of maximum symbol expansions at each time step. (TSD)</p></li>
<li><p><strong>u_max</strong> – Maximum output sequence length. (ALSD)</p></li>
<li><p><strong>nstep</strong> – Number of maximum expansion steps at each time step. (NSC/mAES)</p></li>
<li><p><strong>prefix_alpha</strong> – Maximum prefix length in prefix search. (NSC/mAES)</p></li>
<li><p><strong>expansion_beta</strong> – Number of additional candidates for expanded hypotheses selection. (mAES)</p></li>
<li><p><strong>expansion_gamma</strong> – Allowed logp difference for prune-by-value method. (mAES)</p></li>
<li><p><strong>multi_blank_durations</strong> – The duration of each blank token. (MBG)</p></li>
<li><p><strong>multi_blank_indices</strong> – The index of each blank token in token_list. (MBG)</p></li>
<li><p><strong>score_norm</strong> – Normalize final scores by length. (“default”)</p></li>
<li><p><strong>score_norm_during</strong> – Normalize scores by length during search. (default, TSD, ALSD)</p></li>
<li><p><strong>nbest</strong> – Number of final hypothesis.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding">
<code class="sig-name descname">align_length_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.align_length_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.align_length_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Alignment-length synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>h</strong> – Encoder output sequences. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.default_beam_search">
<code class="sig-name descname">default_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.default_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.default_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation.</p>
<p>Modified from <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.greedy_search">
<code class="sig-name descname">greedy_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.greedy_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.greedy_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Greedy search implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>1-best hypotheses.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hyp</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search">
<code class="sig-name descname">modified_adaptive_expansion_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.modified_adaptive_expansion_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.modified_adaptive_expansion_search" title="Permalink to this definition">¶</a></dt>
<dd><p>It’s the modified Adaptive Expansion Search (mAES) implementation.</p>
<p>Based on/modified from <a class="reference external" href="https://ieeexplore.ieee.org/document/9250505">https://ieeexplore.ieee.org/document/9250505</a> and NSC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.multi_blank_greedy_search">
<code class="sig-name descname">multi_blank_greedy_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.multi_blank_greedy_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.multi_blank_greedy_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Greedy Search for Multi-Blank Transducer (Multi-Blank Greedy, MBG).</p>
<p>In this implementation, we assume:
1. the index of standard blank is the last entry of self.multi_blank_indices</p>
<blockquote>
<div><p>rather than self.blank_id (to avoid too much change on original transducer)</p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>other entries in self.multi_blank_indices are big blanks that account for
multiple frames.</p></li>
</ol>
<p>Based on <a class="reference external" href="https://arxiv.org/abs/2211.03541">https://arxiv.org/abs/2211.03541</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>1-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hyp</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.nsc_beam_search">
<code class="sig-name descname">nsc_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.nsc_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.nsc_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>N-step constrained beam search implementation.</p>
<p>Based on/Modified from <a class="reference external" href="https://arxiv.org/pdf/2002.03577.pdf">https://arxiv.org/pdf/2002.03577.pdf</a>.
Please reference ESPnet (b-flo, PR #2444) for any usage outside ESPnet
until further modifications.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.prefix_search">
<code class="sig-name descname">prefix_search</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis], enc_out_t: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.prefix_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.prefix_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Prefix search for NSC and mAES strategies.</p>
<p>Based on <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.sort_nbest">
<code class="sig-name descname">sort_nbest</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet2.asr.transducer.beam_search_transducer.Hypothesis], List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis]]</em><span class="sig-paren">)</span> &#x2192; Union[List[espnet2.asr.transducer.beam_search_transducer.Hypothesis], List[espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis]]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.sort_nbest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.sort_nbest" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort hypotheses by score or score given sequence length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypothesis.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sorted hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.time_sync_decoding">
<code class="sig-name descname">time_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#BeamSearchTransducer.time_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.BeamSearchTransducer.time_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Time synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.beam_search_transducer.</code><code class="sig-name descname">ExtendedHypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]], torch.Tensor], lm_state: Union[Dict[str, Any], List[Any]] = None, dec_out: List[torch.Tensor] = None, lm_scores: torch.Tensor = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#ExtendedHypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.transducer.beam_search_transducer.Hypothesis" title="espnet2.asr.transducer.beam_search_transducer.Hypothesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.transducer.beam_search_transducer.Hypothesis</span></code></a></p>
<p>Extended hypothesis definition for NSC beam search and mAES.</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis.dec_out">
<code class="sig-name descname">dec_out</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis.dec_out" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis.lm_scores">
<code class="sig-name descname">lm_scores</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.ExtendedHypothesis.lm_scores" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.beam_search_transducer.Hypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.beam_search_transducer.</code><code class="sig-name descname">Hypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]], torch.Tensor], lm_state: Union[Dict[str, Any], List[Any]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer.html#Hypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.Hypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Default hypothesis definition for Transducer search algorithms.</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.beam_search_transducer.Hypothesis.lm_state">
<code class="sig-name descname">lm_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer.Hypothesis.lm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-error-calculator-1">
<span id="espnet2-asr-transducer-error-calculator"></span><h2>espnet2.asr.transducer.error_calculator<a class="headerlink" href="#espnet2-asr-transducer-error-calculator-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.error_calculator"></span><p>Error Calculator module for Transducer.</p>
<dl class="class">
<dt id="espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.error_calculator.</code><code class="sig-name descname">ErrorCalculatorTransducer</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr.decoder.abs_decoder.AbsDecoder, joint_network: torch.nn.modules.module.Module, token_list: List[int], sym_space: str, sym_blank: str, report_cer: bool = False, report_wer: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/error_calculator.html#ErrorCalculatorTransducer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Calculate CER and WER for transducer models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>token_list</strong> – List of tokens.</p></li>
<li><p><strong>sym_space</strong> – Space symbol.</p></li>
<li><p><strong>sym_blank</strong> – Blank symbol.</p></li>
<li><p><strong>report_cer</strong> – Whether to compute CER.</p></li>
<li><p><strong>report_wer</strong> – Whether to compute WER.</p></li>
</ul>
</dd>
</dl>
<p>Construct an ErrorCalculatorTransducer.</p>
<dl class="method">
<dt id="espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer.calculate_cer">
<code class="sig-name descname">calculate_cer</code><span class="sig-paren">(</span><em class="sig-param">char_pred: torch.Tensor</em>, <em class="sig-param">char_target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet2/asr/transducer/error_calculator.html#ErrorCalculatorTransducer.calculate_cer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer.calculate_cer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level CER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>char_pred</strong> – Prediction character sequences. (B, ?)</p></li>
<li><p><strong>char_target</strong> – Target character sequences. (B, ?)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Average sentence-level CER score.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer.calculate_wer">
<code class="sig-name descname">calculate_wer</code><span class="sig-paren">(</span><em class="sig-param">char_pred: torch.Tensor</em>, <em class="sig-param">char_target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; float<a class="reference internal" href="../_modules/espnet2/asr/transducer/error_calculator.html#ErrorCalculatorTransducer.calculate_wer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer.calculate_wer" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate sentence-level WER score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>char_pred</strong> – Prediction character sequences. (B, ?)</p></li>
<li><p><strong>char_target</strong> – Target character sequences. (B, ?)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Average sentence-level WER score</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer.convert_to_char">
<code class="sig-name descname">convert_to_char</code><span class="sig-paren">(</span><em class="sig-param">pred: torch.Tensor</em>, <em class="sig-param">target: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[List, List]<a class="reference internal" href="../_modules/espnet2/asr/transducer/error_calculator.html#ErrorCalculatorTransducer.convert_to_char"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.error_calculator.ErrorCalculatorTransducer.convert_to_char" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert label ID sequences to character sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pred</strong> – Prediction label ID sequences. (B, U)</p></li>
<li><p><strong>target</strong> – Target label ID sequences. (B, L)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Prediction character sequences. (B, ?)
char_target: Target character sequences. (B, ?)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>char_pred</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-beam-search-transducer-streaming-1">
<span id="espnet2-asr-transducer-beam-search-transducer-streaming"></span><h2>espnet2.asr.transducer.beam_search_transducer_streaming<a class="headerlink" href="#espnet2-asr-transducer-beam-search-transducer-streaming-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.beam_search_transducer_streaming"></span><p>Search algorithms for Transducer models.</p>
<dl class="class">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.beam_search_transducer_streaming.</code><code class="sig-name descname">BeamSearchTransducerStreaming</code><span class="sig-paren">(</span><em class="sig-param">decoder: espnet2.asr.decoder.abs_decoder.AbsDecoder</em>, <em class="sig-param">joint_network: espnet2.asr_transducer.joint_network.JointNetwork</em>, <em class="sig-param">beam_size: int</em>, <em class="sig-param">lm: torch.nn.modules.module.Module = None</em>, <em class="sig-param">lm_weight: float = 0.1</em>, <em class="sig-param">search_type: str = 'default'</em>, <em class="sig-param">max_sym_exp: int = 2</em>, <em class="sig-param">u_max: int = 50</em>, <em class="sig-param">nstep: int = 1</em>, <em class="sig-param">prefix_alpha: int = 1</em>, <em class="sig-param">expansion_gamma: int = 2.3</em>, <em class="sig-param">expansion_beta: int = 2</em>, <em class="sig-param">score_norm: bool = True</em>, <em class="sig-param">score_norm_during: bool = False</em>, <em class="sig-param">nbest: int = 1</em>, <em class="sig-param">penalty: float = 0.0</em>, <em class="sig-param">token_list: Optional[List[str]] = None</em>, <em class="sig-param">hold_n: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Beam search implementation for Transducer.</p>
<p>Initialize Transducer search module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder</strong> – Decoder module.</p></li>
<li><p><strong>joint_network</strong> – Joint network module.</p></li>
<li><p><strong>beam_size</strong> – Beam size.</p></li>
<li><p><strong>lm</strong> – LM class.</p></li>
<li><p><strong>lm_weight</strong> – LM weight for soft fusion.</p></li>
<li><p><strong>search_type</strong> – Search algorithm to use during inference.</p></li>
<li><p><strong>max_sym_exp</strong> – Number of maximum symbol expansions at each time step. (TSD)</p></li>
<li><p><strong>u_max</strong> – Maximum output sequence length. (ALSD)</p></li>
<li><p><strong>nstep</strong> – Number of maximum expansion steps at each time step. (NSC/mAES)</p></li>
<li><p><strong>prefix_alpha</strong> – Maximum prefix length in prefix search. (NSC/mAES)</p></li>
<li><p><strong>expansion_beta</strong> – Number of additional candidates for expanded hypotheses selection. (mAES)</p></li>
<li><p><strong>expansion_gamma</strong> – Allowed logp difference for prune-by-value method. (mAES)</p></li>
<li><p><strong>score_norm</strong> – Normalize final scores by length. (“default”)</p></li>
<li><p><strong>score_norm_during</strong> – Normalize scores by length during search. (default, TSD, ALSD)</p></li>
<li><p><strong>nbest</strong> – Number of final hypothesis.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.align_length_sync_decoding">
<code class="sig-name descname">align_length_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.align_length_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.align_length_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Alignment-length synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>h</strong> – Encoder output sequences. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.default_beam_search">
<code class="sig-name descname">default_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.default_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.default_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Beam search implementation.</p>
<p>Modified from <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.greedy_search">
<code class="sig-name descname">greedy_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.greedy_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.greedy_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Greedy search implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>1-best hypotheses.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hyp</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.modified_adaptive_expansion_search">
<code class="sig-name descname">modified_adaptive_expansion_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.modified_adaptive_expansion_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.modified_adaptive_expansion_search" title="Permalink to this definition">¶</a></dt>
<dd><p>It’s the modified Adaptive Expansion Search (mAES) implementation.</p>
<p>Based on/modified from <a class="reference external" href="https://ieeexplore.ieee.org/document/9250505">https://ieeexplore.ieee.org/document/9250505</a> and NSC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.nsc_beam_search">
<code class="sig-name descname">nsc_beam_search</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.nsc_beam_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.nsc_beam_search" title="Permalink to this definition">¶</a></dt>
<dd><p>N-step constrained beam search implementation.</p>
<p>Based on/Modified from <a class="reference external" href="https://arxiv.org/pdf/2002.03577.pdf">https://arxiv.org/pdf/2002.03577.pdf</a>.
Please reference ESPnet (b-flo, PR #2444) for any usage outside ESPnet
until further modifications.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D_enc)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.prefix_search">
<code class="sig-name descname">prefix_search</code><span class="sig-paren">(</span><em class="sig-param">hyps: List[espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis], enc_out_t: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.prefix_search"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.prefix_search" title="Permalink to this definition">¶</a></dt>
<dd><p>Prefix search for NSC and mAES strategies.</p>
<p>Based on <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">https://arxiv.org/pdf/1211.3711.pdf</a></p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.reset">
<code class="sig-name descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.reset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.reset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.sort_nbest">
<code class="sig-name descname">sort_nbest</code><span class="sig-paren">(</span><em class="sig-param">hyps: Union[List[espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis], List[espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis]]</em><span class="sig-paren">)</span> &#x2192; Union[List[espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis], List[espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis]]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.sort_nbest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.sort_nbest" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort hypotheses by score or score given sequence length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hyps</strong> – Hypothesis.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Sorted hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>hyps</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.time_sync_decoding">
<code class="sig-name descname">time_sync_decoding</code><span class="sig-paren">(</span><em class="sig-param">enc_out: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; List[espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis]<a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#BeamSearchTransducerStreaming.time_sync_decoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.BeamSearchTransducerStreaming.time_sync_decoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Time synchronous beam search implementation.</p>
<p>Based on <a class="reference external" href="https://ieeexplore.ieee.org/document/9053040">https://ieeexplore.ieee.org/document/9053040</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>enc_out</strong> – Encoder output sequence. (T, D)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>N-best hypothesis.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nbest_hyps</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.beam_search_transducer_streaming.</code><code class="sig-name descname">ExtendedHypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]], torch.Tensor], lm_state: Union[Dict[str, Any], List[Any]] = None, dec_out: List[torch.Tensor] = None, lm_scores: torch.Tensor = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#ExtendedHypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis" title="espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis</span></code></a></p>
<p>Extended hypothesis definition for NSC beam search and mAES.</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis.dec_out">
<code class="sig-name descname">dec_out</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis.dec_out" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis.lm_scores">
<code class="sig-name descname">lm_scores</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.ExtendedHypothesis.lm_scores" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.beam_search_transducer_streaming.</code><code class="sig-name descname">Hypothesis</code><span class="sig-paren">(</span><em class="sig-param">score: float, yseq: List[int], dec_state: Union[Tuple[torch.Tensor, Optional[torch.Tensor]], List[Optional[torch.Tensor]], torch.Tensor], lm_state: Union[Dict[str, Any], List[Any]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/beam_search_transducer_streaming.html#Hypothesis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Default hypothesis definition for Transducer search algorithms.</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis.lm_state">
<code class="sig-name descname">lm_state</code><em class="property"> = None</em><a class="headerlink" href="#espnet2.asr.transducer.beam_search_transducer_streaming.Hypothesis.lm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-init-1">
<span id="espnet2-asr-transducer-init"></span><h2>espnet2.asr.transducer.__init__<a class="headerlink" href="#espnet2-asr-transducer-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.__init__"></span></section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-rnnt-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-rnnt"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.rnnt<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-rnnt-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.rnnt"></span><dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt.multiblank_rnnt_loss_gpu">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.rnnt.</code><code class="sig-name descname">multiblank_rnnt_loss_gpu</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">grads: torch.Tensor</em>, <em class="sig-param">blank_label: int</em>, <em class="sig-param">big_blank_durations: list</em>, <em class="sig-param">fastemit_lambda: float</em>, <em class="sig-param">clamp: float</em>, <em class="sig-param">num_threads: int</em>, <em class="sig-param">sigma: float</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt.html#multiblank_rnnt_loss_gpu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt.multiblank_rnnt_loss_gpu" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Wrapper method for accessing GPU Multi-blank RNNT loss</dt><dd><p>(<a class="reference external" href="https://arxiv.org/pdf/2211.03541.pdf">https://arxiv.org/pdf/2211.03541.pdf</a>).</p>
</dd>
<dt>CUDA implementation ported from [HawkAaron/warp-transducer]</dt><dd><p>(<a class="reference external" href="https://github.com/HawkAaron/warp-transducer">https://github.com/HawkAaron/warp-transducer</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Activation tensor of shape [B, T, U, V + num_big_blanks + 1].</p></li>
<li><p><strong>labels</strong> – Ground truth labels of shape [B, U].</p></li>
<li><p><strong>input_lengths</strong> – Lengths of the acoustic sequence as a vector of ints [B].</p></li>
<li><p><strong>label_lengths</strong> – Lengths of the target sequence as a vector of ints [B].</p></li>
<li><p><strong>costs</strong> – Zero vector of length [B] in which costs will be set.</p></li>
<li><p><strong>grads</strong> – Zero tensor of shape [B, T, U, V + num_big_blanks + 1]
where the gradient will be set.</p></li>
<li><p><strong>blank_label</strong> – Index of the standard blank token in the vocabulary.</p></li>
<li><p><strong>big_blank_durations</strong> – A list of supported durations for big blank symbols
in the model, e.g. [2, 4, 8]. Note we only include durations for <a href="#system-message-4"><span class="problematic" id="problematic-4">``</span></a>big
blanks’’ here and it should not include 1 for the standard blank.
Those big blanks have vocabulary indices after the standard blank index.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
<li><p><strong>num_threads</strong> – Number of threads for OpenMP.</p></li>
<li><p><strong>sigma</strong> – logit-undernormalization weight used in the multi-blank model. Refer to
the multi-blank paper <a class="reference external" href="https://arxiv.org/pdf/2211.03541">https://arxiv.org/pdf/2211.03541</a>
for detailed explanations.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt.rnnt_loss_cpu">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.rnnt.</code><code class="sig-name descname">rnnt_loss_cpu</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">grads: torch.Tensor</em>, <em class="sig-param">blank_label: int</em>, <em class="sig-param">fastemit_lambda: float</em>, <em class="sig-param">clamp: float</em>, <em class="sig-param">num_threads: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt.html#rnnt_loss_cpu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt.rnnt_loss_cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper method for accessing CPU RNNT loss.</p>
<dl class="simple">
<dt>CPU implementation ported from [HawkAaron/warp-transducer]</dt><dd><p>(<a class="reference external" href="https://github.com/HawkAaron/warp-transducer">https://github.com/HawkAaron/warp-transducer</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Activation tensor of shape [B, T, U, V+1].</p></li>
<li><p><strong>labels</strong> – Ground truth labels of shape [B, U].</p></li>
<li><p><strong>input_lengths</strong> – Lengths of the acoustic sequence as a vector of ints [B].</p></li>
<li><p><strong>label_lengths</strong> – Lengths of the target sequence as a vector of ints [B].</p></li>
<li><p><strong>costs</strong> – Zero vector of length [B] in which costs will be set.</p></li>
<li><p><strong>grads</strong> – Zero tensor of shape [B, T, U, V+1] where the gradient will be set.</p></li>
<li><p><strong>blank_label</strong> – Index of the blank token in the vocabulary.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
<li><p><strong>num_threads</strong> – Number of threads for OpenMP.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt.rnnt_loss_gpu">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.rnnt.</code><code class="sig-name descname">rnnt_loss_gpu</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">grads: torch.Tensor</em>, <em class="sig-param">blank_label: int</em>, <em class="sig-param">fastemit_lambda: float</em>, <em class="sig-param">clamp: float</em>, <em class="sig-param">num_threads: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt.html#rnnt_loss_gpu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt.rnnt_loss_gpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper method for accessing GPU RNNT loss.</p>
<dl class="simple">
<dt>CUDA implementation ported from [HawkAaron/warp-transducer]</dt><dd><p>(<a class="reference external" href="https://github.com/HawkAaron/warp-transducer">https://github.com/HawkAaron/warp-transducer</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Activation tensor of shape [B, T, U, V+1].</p></li>
<li><p><strong>labels</strong> – Ground truth labels of shape [B, U].</p></li>
<li><p><strong>input_lengths</strong> – Lengths of the acoustic sequence as a vector of ints [B].</p></li>
<li><p><strong>label_lengths</strong> – Lengths of the target sequence as a vector of ints [B].</p></li>
<li><p><strong>costs</strong> – Zero vector of length [B] in which costs will be set.</p></li>
<li><p><strong>grads</strong> – Zero tensor of shape [B, T, U, V+1] where the gradient will be set.</p></li>
<li><p><strong>blank_label</strong> – Index of the blank token in the vocabulary.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
<li><p><strong>num_threads</strong> – Number of threads for OpenMP.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-rnnt-multi-blank-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-rnnt-multi-blank"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-rnnt-multi-blank-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank"></span><dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.rnnt_loss">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.</code><code class="sig-name descname">rnnt_loss</code><span class="sig-paren">(</span><em class="sig-param">acts</em>, <em class="sig-param">labels</em>, <em class="sig-param">act_lens</em>, <em class="sig-param">label_lens</em>, <em class="sig-param">blank=0</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">fastemit_lambda: float = 0.0</em>, <em class="sig-param">clamp: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt_multi_blank.html#rnnt_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.rnnt_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>RNN Transducer Loss (functional form)
:param acts: Tensor of (batch x seqLength x labelLength x outputDim)</p>
<blockquote>
<div><p>containing output from network</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – 2 dimensional Tensor containing all the targets of
the batch with zero padded</p></li>
<li><p><strong>act_lens</strong> – Tensor of size (batch) containing size of each
output sequence from the network</p></li>
<li><p><strong>label_lens</strong> – Tensor of (batch) containing label length of each example</p></li>
<li><p><strong>blank</strong> (<em>int</em><em>, </em><em>optional</em>) – blank label. Default: 0.</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied,
‘mean’: the output losses will be divided by the target lengths and
then the mean over the batch is taken. Default: ‘mean’</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.RNNTLossNumba">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.</code><code class="sig-name descname">RNNTLossNumba</code><span class="sig-paren">(</span><em class="sig-param">blank=0</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">fastemit_lambda: float = 0.0</em>, <em class="sig-param">clamp: float = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt_multi_blank.html#RNNTLossNumba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.RNNTLossNumba" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>blank</strong> (<em>int</em><em>, </em><em>optional</em>) – blank label. Default: 0.</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied,
‘mean’: the output losses will be divided by the target lengths and
then the mean over the batch is taken. Default: ‘mean’</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.RNNTLossNumba.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">acts</em>, <em class="sig-param">labels</em>, <em class="sig-param">act_lens</em>, <em class="sig-param">label_lens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt_multi_blank.html#RNNTLossNumba.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.RNNTLossNumba.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>log_probs: Tensor of (batch x seqLength x labelLength x outputDim)</dt><dd><p>containing output from network</p>
</dd>
<dt>labels: 2 dimensional Tensor containing all the targets of the</dt><dd><p>batch with zero padded</p>
</dd>
<dt>act_lens: Tensor of size (batch) containing size of each output</dt><dd><p>sequence from the network</p>
</dd>
</dl>
<p>label_lens: Tensor of (batch) containing label length of each example</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.MultiblankRNNTLossNumba">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.</code><code class="sig-name descname">MultiblankRNNTLossNumba</code><span class="sig-paren">(</span><em class="sig-param">blank</em>, <em class="sig-param">big_blank_durations</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">fastemit_lambda: float = 0.0</em>, <em class="sig-param">clamp: float = -1</em>, <em class="sig-param">sigma: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt_multi_blank.html#MultiblankRNNTLossNumba"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.MultiblankRNNTLossNumba" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>blank</strong> (<em>int</em>) – standard blank label.</p></li>
<li><p><strong>big_blank_durations</strong> – list of durations for multi-blank transducer, e.g.
[2, 4, 8].</p></li>
<li><p><strong>sigma</strong> – hyper-parameter for logit under-normalization method for training
multi-blank transducers. Recommended value 0.05.</p></li>
<li><p><strong>to https</strong> (<em>Refer</em>) – //arxiv.org/pdf/2211.03541 for detailed explanations for
the above parameters;</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied,
‘mean’: the output losses will be divided by the target lengths and
then the mean over the batch is taken. Default: ‘mean’</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.MultiblankRNNTLossNumba.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">acts</em>, <em class="sig-param">labels</em>, <em class="sig-param">act_lens</em>, <em class="sig-param">label_lens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/rnnt_multi_blank.html#MultiblankRNNTLossNumba.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.rnnt_multi_blank.MultiblankRNNTLossNumba.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>log_probs: Tensor of (batch x seqLength x labelLength x outputDim)</dt><dd><p>containing output from network</p>
</dd>
<dt>labels: 2 dimensional Tensor containing all the targets of</dt><dd><p>the batch with zero padded</p>
</dd>
<dt>act_lens: Tensor of size (batch) containing size of each output</dt><dd><p>sequence from the network</p>
</dd>
</dl>
<p>label_lens: Tensor of (batch) containing label length of each example</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-init-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-init"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.__init__<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.__init__"></span></section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-rnnt-helper-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-rnnt-helper"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-rnnt-helper-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper"></span><dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.add">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">add</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.add" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.compute_costs_data">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">compute_costs_data</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#compute_costs_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.compute_costs_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.copy_data_1d">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">copy_data_1d</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#copy_data_1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.copy_data_1d" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.div_up">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">div_up</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#div_up"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.div_up" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.exponential">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">exponential</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#exponential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.exponential" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.flatten_tensor">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">flatten_tensor</code><span class="sig-paren">(</span><em class="sig-param">x: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#flatten_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.flatten_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.get_workspace_size">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">get_workspace_size</code><span class="sig-paren">(</span><em class="sig-param">maxT: int</em>, <em class="sig-param">maxU: int</em>, <em class="sig-param">minibatch: int</em>, <em class="sig-param">gpu: bool</em><span class="sig-paren">)</span> &#x2192; Tuple[Optional[int], espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus]<a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#get_workspace_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.get_workspace_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.identity">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">identity</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#identity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.identity" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.log_plus">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">log_plus</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#log_plus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.log_plus" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.log_sum_exp">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">log_sum_exp</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#log_sum_exp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.log_sum_exp" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.maximum">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">maximum</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#maximum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.maximum" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.negate">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.</code><code class="sig-name descname">negate</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/rnnt_helper.html#negate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.rnnt_helper.negate" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-global-constants-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-global-constants"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-global-constants-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants"></span><dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.</code><code class="sig-name descname">RNNTStatus</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/global_constants.html#RNNTStatus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>An enumeration.</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus.RNNT_STATUS_INVALID_VALUE">
<code class="sig-name descname">RNNT_STATUS_INVALID_VALUE</code><em class="property"> = 1</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus.RNNT_STATUS_INVALID_VALUE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus.RNNT_STATUS_SUCCESS">
<code class="sig-name descname">RNNT_STATUS_SUCCESS</code><em class="property"> = 0</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus.RNNT_STATUS_SUCCESS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="data">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.THRESHOLD">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.</code><code class="sig-name descname">THRESHOLD</code><em class="property"> = 0.1</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.THRESHOLD" title="Permalink to this definition">¶</a></dt>
<dd><p>Getters</p>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.dtype">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.</code><code class="sig-name descname">dtype</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/global_constants.html#dtype"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.dtype" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.threads_per_block">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.</code><code class="sig-name descname">threads_per_block</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/global_constants.html#threads_per_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.threads_per_block" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.warp_size">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.</code><code class="sig-name descname">warp_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/global_constants.html#warp_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.warp_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-init-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-init"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.__init__<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.__init__"></span></section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-cpu-rnnt-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-cpu-rnnt"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-cpu-rnnt-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt"></span><dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.</code><code class="sig-name descname">CPURNNT</code><span class="sig-paren">(</span><em class="sig-param">minibatch: int</em>, <em class="sig-param">maxT: int</em>, <em class="sig-param">maxU: int</em>, <em class="sig-param">alphabet_size: int</em>, <em class="sig-param">workspace: torch.Tensor</em>, <em class="sig-param">blank: int</em>, <em class="sig-param">fastemit_lambda: float</em>, <em class="sig-param">clamp: float</em>, <em class="sig-param">num_threads: int</em>, <em class="sig-param">batch_first: bool</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CPURNNT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Helper class to compute the Transducer Loss on CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – Size of the minibatch b.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>workspace</strong> – An allocated chunk of memory that will be sliced off and
reshaped into required blocks used as working memory.</p></li>
<li><p><strong>blank</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
<li><p><strong>num_threads</strong> – Number of OMP threads to launch.</p></li>
<li><p><strong>batch_first</strong> – Bool that decides if batch dimension is first or third.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.compute_alphas">
<code class="sig-name descname">compute_alphas</code><span class="sig-paren">(</span><em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">T: int</em>, <em class="sig-param">U: int</em>, <em class="sig-param">alphas: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CPURNNT.compute_alphas"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.compute_alphas" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the probability of the forward variable alpha.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_probs</strong> – Flattened tensor [B, T, U, V+1]</p></li>
<li><p><strong>T</strong> – Length of the acoustic sequence T (not padded).</p></li>
<li><p><strong>U</strong> – Length of the target sequence U (not padded).</p></li>
<li><p><strong>alphas</strong> – Working space memory for alpha of shape [B, T, U].</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loglikelihood of the forward variable alpha.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.compute_betas_and_grads">
<code class="sig-name descname">compute_betas_and_grads</code><span class="sig-paren">(</span><em class="sig-param">grad: torch.Tensor</em>, <em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">T: int</em>, <em class="sig-param">U: int</em>, <em class="sig-param">alphas: torch.Tensor</em>, <em class="sig-param">betas: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">logll: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CPURNNT.compute_betas_and_grads"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.compute_betas_and_grads" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute backward variable beta as well as gradients of the activation
matrix wrt loglikelihood of forward variable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grad</strong> – Working space memory of flattened shape [B, T, U, V+1]</p></li>
<li><p><strong>log_probs</strong> – Activatio tensor of flattented shape [B, T, U, V+1]</p></li>
<li><p><strong>T</strong> – Length of the acoustic sequence T (not padded).</p></li>
<li><p><strong>U</strong> – Length of the target sequence U (not padded).</p></li>
<li><p><strong>alphas</strong> – Working space memory for alpha of shape [B, T, U].</p></li>
<li><p><strong>betas</strong> – Working space memory for alpha of shape [B, T, U].</p></li>
<li><p><strong>labels</strong> – Ground truth label of shape [B, U]</p></li>
<li><p><strong>logll</strong> – Loglikelihood of the forward variable.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Loglikelihood of the forward variable and inplace updates the grad tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.cost_and_grad">
<code class="sig-name descname">cost_and_grad</code><span class="sig-paren">(</span><em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">grads: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">flat_labels: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus<a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CPURNNT.cost_and_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.cost_and_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.cost_and_grad_kernel">
<code class="sig-name descname">cost_and_grad_kernel</code><span class="sig-paren">(</span><em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">grad: torch.Tensor</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">mb: int</em>, <em class="sig-param">T: int</em>, <em class="sig-param">U: int</em>, <em class="sig-param">bytes_used: int</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CPURNNT.cost_and_grad_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.cost_and_grad_kernel" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.score_forward">
<code class="sig-name descname">score_forward</code><span class="sig-paren">(</span><em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">flat_labels: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CPURNNT.score_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CPURNNT.score_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_index">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.</code><code class="sig-name descname">CpuRNNT_index</code><span class="sig-paren">(</span><em class="sig-param">U: int</em>, <em class="sig-param">maxU: int</em>, <em class="sig-param">minibatch: int</em>, <em class="sig-param">alphabet_size: int</em>, <em class="sig-param">batch_first: bool</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CpuRNNT_index"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_index" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A placeholder Index computation class that emits the resolved index in a
flattened tensor, mimicing pointer indexing in CUDA kernels on the CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>U</strong> – Length of the current target sample (without padding).</p></li>
<li><p><strong>maxU</strong> – Max Length of the padded target samples.</p></li>
<li><p><strong>minibatch</strong> – Minibatch index</p></li>
<li><p><strong>alphabet_size</strong> – Size of the vocabulary including RNNT blank - V+1.</p></li>
<li><p><strong>batch_first</strong> – Bool flag determining if batch index is first or third.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_metadata">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.</code><code class="sig-name descname">CpuRNNT_metadata</code><span class="sig-paren">(</span><em class="sig-param">T: int</em>, <em class="sig-param">U: int</em>, <em class="sig-param">workspace: torch.Tensor</em>, <em class="sig-param">bytes_used: int</em>, <em class="sig-param">blank: int</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">idx: espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CpuRNNT_metadata"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Metadata for CPU based RNNT loss calculation. Holds the working space memory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T</strong> – Length of the acoustic sequence (without padding).</p></li>
<li><p><strong>U</strong> – Length of the target sequence (without padding).</p></li>
<li><p><strong>workspace</strong> – Working space memory for the CPU.</p></li>
<li><p><strong>bytes_used</strong> – Number of bytes currently used for indexing the working
space memory. Generally 0.</p></li>
<li><p><strong>blank</strong> – Index of the blank token in the vocabulary.</p></li>
<li><p><strong>labels</strong> – Ground truth padded labels matrix of shape [B, U]</p></li>
<li><p><strong>log_probs</strong> – Log probs / activation matrix of flattented shape [B, T, U, V+1]</p></li>
<li><p><strong>idx</strong> – </p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_metadata.setup_probs">
<code class="sig-name descname">setup_probs</code><span class="sig-paren">(</span><em class="sig-param">T: int</em>, <em class="sig-param">U: int</em>, <em class="sig-param">labels: torch.Tensor</em>, <em class="sig-param">blank: int</em>, <em class="sig-param">log_probs: torch.Tensor</em>, <em class="sig-param">idx: espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#CpuRNNT_metadata.setup_probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.CpuRNNT_metadata.setup_probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.</code><code class="sig-name descname">LogSoftmaxGradModification</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#LogSoftmaxGradModification"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_output</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#LogSoftmaxGradModification.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation with backward mode
automatic differentiation (alias to the vjp function).</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward" title="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward" title="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.backward" title="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward" title="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">acts</em>, <em class="sig-param">clamp</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#LogSoftmaxGradModification.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.LogSoftmaxGradModification.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.log_sum_exp">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.</code><code class="sig-name descname">log_sum_exp</code><span class="sig-paren">(</span><em class="sig-param">a: torch.Tensor</em>, <em class="sig-param">b: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cpu_utils/cpu_rnnt.html#log_sum_exp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.cpu_rnnt.log_sum_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Logsumexp with safety checks for infs.</p>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-init-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-init"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.__init__<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cpu-utils-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.cpu_utils.__init__"></span></section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt"></span><dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.</code><code class="sig-name descname">GPURNNT</code><span class="sig-paren">(</span><em class="sig-param">minibatch: int</em>, <em class="sig-param">maxT: int</em>, <em class="sig-param">maxU: int</em>, <em class="sig-param">alphabet_size: int</em>, <em class="sig-param">workspace</em>, <em class="sig-param">blank: int</em>, <em class="sig-param">fastemit_lambda: float</em>, <em class="sig-param">clamp: float</em>, <em class="sig-param">num_threads: int</em>, <em class="sig-param">stream</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#GPURNNT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Helper class to launch the CUDA Kernels to compute the Transducer Loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>workspace</strong> – An allocated chunk of memory that will be sliced off and
reshaped into required blocks used as working memory.</p></li>
<li><p><strong>blank</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp
the gradient to [-clamp, clamp].</p></li>
<li><p><strong>num_threads</strong> – Number of OMP threads to launch.</p></li>
<li><p><strong>stream</strong> – Numba Cuda Stream.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.compute_cost_and_score">
<code class="sig-name descname">compute_cost_and_score</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor, grads: Optional[torch.Tensor], costs: torch.Tensor, labels: torch.Tensor, label_lengths: torch.Tensor, input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus<a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#GPURNNT.compute_cost_and_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.compute_cost_and_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute both the loss and the gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – A flattened tensor of shape [B, T, U, V+1] representing the
activation matrix.</p></li>
<li><p><strong>grad</strong> – A flattented zero tensor of same shape as acts.</p></li>
<li><p><strong>costs</strong> – A zero vector of length B which will be updated inplace
with the log probability costs.</p></li>
<li><p><strong>flat_labels</strong> – A flattened matrix of labels of shape [B, U]</p></li>
<li><p><strong>label_lengths</strong> – A vector of length B that contains the original
lengths of the acoustic sequence.</p></li>
<li><p><strong>input_lengths</strong> – A vector of length B that contains the original
lengths of the target sequence.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>This will launch kernels that will update inline the following variables:
-   grads: Gradients of the activation matrix wrt the costs vector.
-   costs: Negative log likelihood of the forward variable.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>An enum that either represents a successful RNNT operation or failure.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.cost_and_grad">
<code class="sig-name descname">cost_and_grad</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">grads: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">pad_labels: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#GPURNNT.cost_and_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.cost_and_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.log_softmax">
<code class="sig-name descname">log_softmax</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">denom: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#GPURNNT.log_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the log softmax denominator of the input activation tensor
and stores the result in denom.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Activation tensor of shape [B, T, U, V+1]. The input must be
represented as a flat tensor of shape [B * T * U * (V+1)] to
allow pointer indexing.</p></li>
<li><p><strong>denom</strong> – A zero tensor of same shape as acts.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>This kernel inplace updates the <cite>denom</cite> tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.score_forward">
<code class="sig-name descname">score_forward</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">pad_labels: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#GPURNNT.score_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT.score_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.</code><code class="sig-name descname">MultiblankGPURNNT</code><span class="sig-paren">(</span><em class="sig-param">sigma: float</em>, <em class="sig-param">num_big_blanks: int</em>, <em class="sig-param">minibatch: int</em>, <em class="sig-param">maxT: int</em>, <em class="sig-param">maxU: int</em>, <em class="sig-param">alphabet_size: int</em>, <em class="sig-param">workspace</em>, <em class="sig-param">big_blank_workspace</em>, <em class="sig-param">blank: int</em>, <em class="sig-param">fastemit_lambda: float</em>, <em class="sig-param">clamp: float</em>, <em class="sig-param">num_threads: int</em>, <em class="sig-param">stream</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#MultiblankGPURNNT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT" title="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.GPURNNT</span></code></a></p>
<dl class="simple">
<dt>Helper class to launch the CUDA Kernels to compute Multi-blank Transducer Loss</dt><dd><p>(<a class="reference external" href="https://arxiv.org/pdf/2211.03541">https://arxiv.org/pdf/2211.03541</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> – Hyper-parameter related to the logit-normalization method
in training multi-blank transducers.</p></li>
<li><p><strong>num_big_blanks</strong> – Number of big blank symbols the model has. This should
not include the standard blank symbol.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V + 1 + num-big-blanks</p></li>
<li><p><strong>workspace</strong> – An allocated chunk of memory that will be sliced off and
reshaped into required blocks used as working memory.</p></li>
<li><p><strong>big_blank_workspace</strong> – An allocated chunk of memory that will be sliced
off and reshaped into required blocks used as working memory
specifically for the multi-blank related computations.</p></li>
<li><p><strong>blank</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with
Sequence-level Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
<li><p><strong>num_threads</strong> – Number of OMP threads to launch.</p></li>
<li><p><strong>stream</strong> – Numba Cuda Stream.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT.compute_cost_and_score">
<code class="sig-name descname">compute_cost_and_score</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor, grads: Optional[torch.Tensor], costs: torch.Tensor, labels: torch.Tensor, label_lengths: torch.Tensor, input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; espnet2.asr.transducer.rnnt_multi_blank.utils.global_constants.RNNTStatus<a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#MultiblankGPURNNT.compute_cost_and_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT.compute_cost_and_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute both the loss and the gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – A flattened tensor of shape [B, T, U, V+1] representing
the activation matrix.</p></li>
<li><p><strong>grad</strong> – A flattented zero tensor of same shape as acts.</p></li>
<li><p><strong>costs</strong> – A zero vector of length B which will be updated inplace
with the log probability costs.</p></li>
<li><p><strong>flat_labels</strong> – A flattened matrix of labels of shape [B, U]</p></li>
<li><p><strong>label_lengths</strong> – A vector of length B that contains the original
lengths of the acoustic sequence.</p></li>
<li><p><strong>input_lengths</strong> – A vector of length B that contains the original
lengths of the target sequence.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>This will launch kernels that will update inline the following variables:
-   grads: Gradients of the activation matrix wrt the costs vector.
-   costs: Negative log likelihood of the forward variable.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>An enum that either represents a successful RNNT operation or failure.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT.cost_and_grad">
<code class="sig-name descname">cost_and_grad</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">grads: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">pad_labels: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#MultiblankGPURNNT.cost_and_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT.cost_and_grad" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT.score_forward">
<code class="sig-name descname">score_forward</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">costs: torch.Tensor</em>, <em class="sig-param">pad_labels: torch.Tensor</em>, <em class="sig-param">label_lengths: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt.html#MultiblankGPURNNT.score_forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt.MultiblankGPURNNT.score_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-kernel-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-kernel"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-gpu-rnnt-kernel-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel"></span><dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_alphas_kernel">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">compute_alphas_kernel</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#compute_alphas_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_alphas_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute alpha (forward variable) probabilities over the transduction step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V+1] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator of the
logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>alphas</strong> – Zero tensor of shape [B, T, U]. Will be updated inside the kernel
with the forward variable probabilities.</p></li>
<li><p><strong>llForward</strong> – Zero tensor of shape [B]. Represents the log-likelihood of the
forward pass. Returned as the forward pass loss that is reduced by
the optimizer.</p></li>
<li><p><strong>xlen</strong> – Vector of length B which contains the actual acoustic sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>ylen</strong> – Vector of length B which contains the actual target sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>mlabels</strong> – Matrix of shape [B, U+1] (+1 here is due to &lt;SOS&gt; token
- usually the RNNT blank). The matrix contains the padded target
transcription that must be predicted.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>blank_</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>Kernel inplace updates the following inputs:
-   alphas: forward variable scores.
-   llForward: log-likelihood of forward variable.</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_betas_kernel">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">compute_betas_kernel</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#compute_betas_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_betas_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute beta (backward variable) probabilities over the transduction step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V+1] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator
of the logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>betas</strong> – Zero tensor of shape [B, T, U]. Will be updated inside the kernel
with the backward variable probabilities.</p></li>
<li><p><strong>llBackward</strong> – Zero tensor of shape [B]. Represents the log-likelihood
of the backward pass. Returned as the backward pass loss that
is reduced by the optimizer.</p></li>
<li><p><strong>xlen</strong> – Vector of length B which contains the actual acoustic
sequence lengths in the padded activation tensor.</p></li>
<li><p><strong>ylen</strong> – Vector of length B which contains the actual target sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>mlabels</strong> – Matrix of shape [B, U+1] (+1 here is due to &lt;SOS&gt; token
- usually the RNNT blank). The matrix contains the padded target
transcription that must be predicted.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>blank_</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>Kernel inplace updates the following inputs:
-   betas: backward variable scores.
-   llBackward: log-likelihood of backward variable.</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_grad_kernel">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">compute_grad_kernel</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#compute_grad_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_grad_kernel" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute gradients over the transduction step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grads</strong> – Zero Tensor of shape [B, T, U, V+1]. Is updated by this kernel to
contain the gradients of this batch of samples.</p></li>
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V+1] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator
of the logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>alphas</strong> – Alpha variable, contains forward probabilities.
A tensor of shape [B, T, U].</p></li>
<li><p><strong>betas</strong> – Beta varoable, contains backward probabilities.
A tensor of shape [B, T, U].</p></li>
<li><p><strong>logll</strong> – Log-likelihood of the forward variable, represented as a vector
of shape [B]. Represents the log-likelihood of the forward pass.</p></li>
<li><p><strong>xlen</strong> – Vector of length B which contains the actual acoustic sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>ylen</strong> – Vector of length B which contains the actual target sequence lengths
in the padded activation tensor.</p></li>
<li><p><strong>mlabels</strong> – Matrix of shape [B, U+1] (+1 here is due to &lt;SOS&gt; token
- usually the RNNT blank). The matrix contains the padded target
transcription that must be predicted.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>blank_</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp the
gradient to [-clamp, clamp].</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>Kernel inplace updates the following inputs:
-   grads: Gradients with respect to the log likelihood (logll).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_multiblank_alphas_kernel">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">compute_multiblank_alphas_kernel</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#compute_multiblank_alphas_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_multiblank_alphas_kernel" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute alpha (forward variable) probabilities for multi-blank transducuer loss</dt><dd><p>(<a class="reference external" href="https://arxiv.org/pdf/2211.03541">https://arxiv.org/pdf/2211.03541</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V + 1 + num_big_blanks] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator of
the logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>sigma</strong> – Hyper-parameter for logit-undernormalization technique for training
multi-blank transducers.</p></li>
<li><p><strong>alphas</strong> – Zero tensor of shape [B, T, U]. Will be updated inside the kernel
with the forward variable probabilities.</p></li>
<li><p><strong>llForward</strong> – Zero tensor of shape [B]. Represents the log-likelihood of the
forward pass. Returned as the forward pass loss that is
reduced by the optimizer.</p></li>
<li><p><strong>xlen</strong> – Vector of length B which contains the actual acoustic sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>ylen</strong> – Vector of length B which contains the actual target sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>mlabels</strong> – Matrix of shape [B, U+1] (+1 here is due to &lt;SOS&gt; token
- usually the RNNT blank). The matrix contains the padded target
transcription that must be predicted.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>blank_</strong> – Index of the RNNT standard blank token in the vocabulary.</p></li>
<li><p><strong>big_blank_durations</strong> – Vector of supported big blank durations of the model.</p></li>
<li><p><strong>num_big_blanks</strong> – Number of big blanks of the model.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>Kernel inplace updates the following inputs:
-   alphas: forward variable scores.
-   llForward: log-likelihood of forward variable.</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_multiblank_betas_kernel">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">compute_multiblank_betas_kernel</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#compute_multiblank_betas_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_multiblank_betas_kernel" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute beta (backward variable) probabilities for multi-blank transducer loss</dt><dd><p>(<a class="reference external" href="https://arxiv.org/pdf/2211.03541">https://arxiv.org/pdf/2211.03541</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V + 1 + num-big-blanks] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator
of the logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>sigma</strong> – Hyper-parameter for logit-undernormalization technique for
training multi-blank transducers.</p></li>
<li><p><strong>betas</strong> – Zero tensor of shape [B, T, U]. Will be updated inside the kernel
with the backward variable probabilities.</p></li>
<li><p><strong>llBackward</strong> – Zero tensor of shape [B]. Represents the log-likelihood
of the backward pass. Returned as the backward pass loss
that is reduced by the optimizer.</p></li>
<li><p><strong>xlen</strong> – Vector of length B which contains the actual acoustic sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>ylen</strong> – Vector of length B which contains the actual target sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>mlabels</strong> – Matrix of shape [B, U+1] (+1 here is due to &lt;SOS&gt; token
- usually the RNNT blank). The matrix contains the padded target
transcription that must be predicted.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>blank_</strong> – Index of the RNNT standard blank token in the vocabulary.</p></li>
<li><p><strong>big_blank_durations</strong> – Vector of supported big blank durations of the model.</p></li>
<li><p><strong>num_big_blanks</strong> – Number of big blanks of the model.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>Kernel inplace updates the following inputs:
-   betas: backward variable scores.
-   llBackward: log-likelihood of backward variable.</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_multiblank_grad_kernel">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">compute_multiblank_grad_kernel</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#compute_multiblank_grad_kernel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.compute_multiblank_grad_kernel" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Compute gradients for multi-blank transducer loss</dt><dd><p>(<a class="reference external" href="https://arxiv.org/pdf/2211.03541">https://arxiv.org/pdf/2211.03541</a>).</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>grads</strong> – Zero Tensor of shape [B, T, U, V + 1 + num_big_blanks].
Is updated by this kernel to contain the gradients of this batch of samples.</p></li>
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V + 1 + num_big_blanks] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator
of the logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>sigma</strong> – Hyper-parameter for logit-undernormalization technique
for training multi-blank transducers.</p></li>
<li><p><strong>alphas</strong> – Alpha variable, contains forward probabilities.
A tensor of shape [B, T, U].</p></li>
<li><p><strong>betas</strong> – Beta varoable, contains backward probabilities.
A tensor of shape [B, T, U].</p></li>
<li><p><strong>logll</strong> – Log-likelihood of the forward variable, represented as
a vector of shape [B]. Represents the log-likelihood of the forward pass.</p></li>
<li><p><strong>xlen</strong> – Vector of length B which contains the actual acoustic
sequence lengths in the padded activation tensor.</p></li>
<li><p><strong>ylen</strong> – Vector of length B which contains the actual target sequence
lengths in the padded activation tensor.</p></li>
<li><p><strong>mlabels</strong> – Matrix of shape [B, U+1] (+1 here is due to &lt;SOS&gt; token
- usually the RNNT blank). The matrix contains the padded target
transcription that must be predicted.</p></li>
<li><p><strong>minibatch</strong> – Int representing the batch size.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>blank_</strong> – Index of the RNNT blank token in the vocabulary.
Generally the first or last token in the vocab.</p></li>
<li><p><strong>fastemit_lambda</strong> – Float scaling factor for FastEmit regularization. Refer to
FastEmit: Low-latency Streaming ASR with Sequence-level
Emission Regularization.</p></li>
<li><p><strong>clamp</strong> – Float value. When set to value &gt;= 0.0, will clamp
the gradient to [-clamp, clamp].</p></li>
<li><p><strong>big_blank_durations</strong> – Vector of supported big blank durations of the model.</p></li>
<li><p><strong>num_big_blanks</strong> – Number of big blanks of the model.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Updates:</dt><dd><p>Kernel inplace updates the following inputs:
-   grads: Gradients with respect to the log likelihood (logll).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.logp">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.</code><code class="sig-name descname">logp</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/gpu_rnnt_kernel.html#logp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.gpu_rnnt_kernel.logp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the sum of log probability from the activation tensor and its denominator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>denom</strong> – Tensor of shape [B, T, U] flattened. Represents the denominator of the
logprobs activation tensor across entire vocabulary.</p></li>
<li><p><strong>acts</strong> – Tensor of shape [B, T, U, V+1] flattened.
Represents the logprobs activation tensor.</p></li>
<li><p><strong>maxT</strong> – The maximum possible acoustic sequence length.
Represents T in the logprobs tensor.</p></li>
<li><p><strong>maxU</strong> – The maximum possible target sequence length.
Represents U in the logprobs tensor.</p></li>
<li><p><strong>alphabet_size</strong> – The vocabulary dimension V+1 (inclusive of RNNT blank).</p></li>
<li><p><strong>mb</strong> – Batch indexer.</p></li>
<li><p><strong>t</strong> – Acoustic sequence timestep indexer.</p></li>
<li><p><strong>u</strong> – Target sequence timestep indexer.</p></li>
<li><p><strong>v</strong> – Vocabulary token indexer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sum of logprobs[mb, t, u, v] + denom[mb, t, u]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-reduce-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-reduce"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-reduce-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce"></span><dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.CTAReduce">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.</code><code class="sig-name descname">CTAReduce</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/reduce.html#CTAReduce"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.CTAReduce" title="Permalink to this definition">¶</a></dt>
<dd><p>CUDA Warp reduction kernel.</p>
<p>It is a device kernel to be called by other kernels.</p>
<p>The data will be read from the right segement recursively, and reduced (ROP) onto
the left half. Operation continues while warp size is larger than a given offset.
Beyond this offset, warp reduction is performed via <cite>shfl_down_sync</cite>,
which halves the reduction space and sums the two halves at each call.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Efficient warp occurs at input shapes of 2 ^ K.</p>
</aside>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Warp Primitives
[<a class="reference external" href="https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/">https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/</a>]</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tid</strong> – CUDA thread index</p></li>
<li><p><strong>x</strong> – activation. Single float.</p></li>
<li><p><strong>storage</strong> – shared memory of size CTA_REDUCE_SIZE used for reduction
in parallel threads.</p></li>
<li><p><strong>count</strong> – equivalent to num_rows, which is equivalent to alphabet_size (V+1)</p></li>
<li><p><strong>R_opid</strong> – Operator ID for reduction. See R_Op for more information.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.I_Op">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.</code><code class="sig-name descname">I_Op</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/reduce.html#I_Op"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.I_Op" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Represents an operation that is performed on the input tensor</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.I_Op.EXPONENTIAL">
<code class="sig-name descname">EXPONENTIAL</code><em class="property"> = 0</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.I_Op.EXPONENTIAL" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.I_Op.IDENTITY">
<code class="sig-name descname">IDENTITY</code><em class="property"> = 1</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.I_Op.IDENTITY" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.R_Op">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.</code><code class="sig-name descname">R_Op</code><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/reduce.html#R_Op"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.R_Op" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Represents a reduction operation performed on the input tensor</p>
<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.R_Op.ADD">
<code class="sig-name descname">ADD</code><em class="property"> = 0</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.R_Op.ADD" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.R_Op.MAXIMUM">
<code class="sig-name descname">MAXIMUM</code><em class="property"> = 1</em><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.R_Op.MAXIMUM" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.ReduceHelper">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.</code><code class="sig-name descname">ReduceHelper</code><span class="sig-paren">(</span><em class="sig-param">I_opid: int</em>, <em class="sig-param">R_opid: int</em>, <em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">output: torch.Tensor</em>, <em class="sig-param">num_rows: int</em>, <em class="sig-param">num_cols: int</em>, <em class="sig-param">minus: bool</em>, <em class="sig-param">stream</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/reduce.html#ReduceHelper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.ReduceHelper" title="Permalink to this definition">¶</a></dt>
<dd><p>CUDA Warp reduction kernel helper which reduces via the R_Op.Add and writes
the result to <cite>output</cite> according to I_op id.</p>
<p>The result is stored in the blockIdx.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Efficient warp occurs at input shapes of 2 ^ K.</p>
</aside>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Warp Primitives
[<a class="reference external" href="https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/">https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/</a>]</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>I_opid</strong> – Operator ID for input. See I_Op for more information.</p></li>
<li><p><strong>R_opid</strong> – Operator ID for reduction. See R_Op for more information.</p></li>
<li><p><strong>acts</strong> – Flatened activation matrix of shape [B * T * U * (V+1)].</p></li>
<li><p><strong>output</strong> – Flatened output matrix of shape [B * T * U * (V+1)].
Data will be overwritten.</p></li>
<li><p><strong>num_rows</strong> – Vocabulary size (including blank token) - V+1.
Represents the number of threads per block.</p></li>
<li><p><strong>num_cols</strong> – Flattened shape of activation matrix, without vocabulary dimension
(B * T * U). Represents number of blocks per grid.</p></li>
<li><p><strong>minus</strong> – Bool flag whether to add or subtract as reduction.
If minus is set; calls _reduce_minus, else calls _reduce_rows kernel.</p></li>
<li><p><strong>stream</strong> – CUDA Stream.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.reduce_exp">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.</code><code class="sig-name descname">reduce_exp</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">denom</em>, <em class="sig-param">rows: int</em>, <em class="sig-param">cols: int</em>, <em class="sig-param">minus: bool</em>, <em class="sig-param">stream</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/reduce.html#reduce_exp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.reduce_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to call the Warp Reduction Kernel to perform <cite>exp</cite> reduction.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Efficient warp occurs at input shapes of 2 ^ K.</p>
</aside>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Warp Primitives
[<a class="reference external" href="https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/">https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/</a>]</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Flatened activation matrix of shape [B * T * U * (V+1)].</p></li>
<li><p><strong>output</strong> – Flatened output matrix of shape [B * T * U * (V+1)].
Data will be overwritten.</p></li>
<li><p><strong>rows</strong> – Vocabulary size (including blank token) - V+1.
Represents the number of threads per block.</p></li>
<li><p><strong>cols</strong> – Flattened shape of activation matrix, without vocabulary dimension
(B * T * U). Represents number of blocks per grid.</p></li>
<li><p><strong>minus</strong> – Bool flag whether to add or subtract as reduction.
If minus is set; calls _reduce_minus, else calls _reduce_rows kernel.</p></li>
<li><p><strong>stream</strong> – CUDA Stream.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.reduce_max">
<code class="sig-prename descclassname">espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.</code><code class="sig-name descname">reduce_max</code><span class="sig-paren">(</span><em class="sig-param">acts: torch.Tensor</em>, <em class="sig-param">denom</em>, <em class="sig-param">rows: int</em>, <em class="sig-param">cols: int</em>, <em class="sig-param">minus: bool</em>, <em class="sig-param">stream</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/transducer/rnnt_multi_blank/utils/cuda_utils/reduce.html#reduce_max"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.reduce.reduce_max" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to call the Warp Reduction Kernel to perform <cite>max</cite> reduction.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Efficient warp occurs at input shapes of 2 ^ K.</p>
</aside>
<p class="rubric">References</p>
<ul class="simple">
<li><p>Warp Primitives
[<a class="reference external" href="https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/">https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/</a>]</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>acts</strong> – Flatened activation matrix of shape [B * T * U * (V+1)].</p></li>
<li><p><strong>output</strong> – Flatened output matrix of shape [B * T * U * (V+1)].
Data will be overwritten.</p></li>
<li><p><strong>rows</strong> – Vocabulary size (including blank token) - V+1.
Represents the number of threads per block.</p></li>
<li><p><strong>cols</strong> – Flattened shape of activation matrix, without vocabulary dimension
(B * T * U). Represents number of blocks per grid.</p></li>
<li><p><strong>minus</strong> – Bool flag whether to add or subtract as reduction.
If minus is set; calls _reduce_minus, else calls _reduce_rows kernel.</p></li>
<li><p><strong>stream</strong> – CUDA Stream.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-init-1">
<span id="espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-init"></span><h2>espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.__init__<a class="headerlink" href="#espnet2-asr-transducer-rnnt-multi-blank-utils-cuda-utils-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.transducer.rnnt_multi_blank.utils.cuda_utils.__init__"></span></section>
<section id="espnet2-asr-layers-fastformer-1">
<span id="espnet2-asr-layers-fastformer"></span><h2>espnet2.asr.layers.fastformer<a class="headerlink" href="#espnet2-asr-layers-fastformer-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.layers.fastformer"></span><p>Fastformer attention definition.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Wu et al., “Fastformer: Additive Attention Can Be All You Need”
<a class="reference external" href="https://arxiv.org/abs/2108.09084">https://arxiv.org/abs/2108.09084</a>
<a class="reference external" href="https://github.com/wuch15/Fastformer">https://github.com/wuch15/Fastformer</a></p>
</dd>
</dl>
<dl class="class">
<dt id="espnet2.asr.layers.fastformer.FastSelfAttention">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.layers.fastformer.</code><code class="sig-name descname">FastSelfAttention</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">attention_heads</em>, <em class="sig-param">dropout_rate</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/fastformer.html#FastSelfAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.fastformer.FastSelfAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Fast self-attention used in Fastformer.</p>
<dl class="method">
<dt id="espnet2.asr.layers.fastformer.FastSelfAttention.espnet_initialization_fn">
<code class="sig-name descname">espnet_initialization_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/fastformer.html#FastSelfAttention.espnet_initialization_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.fastformer.FastSelfAttention.espnet_initialization_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.layers.fastformer.FastSelfAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/fastformer.html#FastSelfAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.fastformer.FastSelfAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – (batch, time, size = n_heads * attn_dim)</p></li>
<li><p><strong>mask</strong> – (batch, 1, time), nonpadding is 1, padding is 0</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(batch, time, size)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.layers.fastformer.FastSelfAttention.init_weights">
<code class="sig-name descname">init_weights</code><span class="sig-paren">(</span><em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/fastformer.html#FastSelfAttention.init_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.fastformer.FastSelfAttention.init_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.layers.fastformer.FastSelfAttention.transpose_for_scores">
<code class="sig-name descname">transpose_for_scores</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/fastformer.html#FastSelfAttention.transpose_for_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.fastformer.FastSelfAttention.transpose_for_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape and transpose to compute scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – (batch, time, size = n_heads * attn_dim)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(batch, n_heads, time, attn_dim)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-layers-cgmlp-1">
<span id="espnet2-asr-layers-cgmlp"></span><h2>espnet2.asr.layers.cgmlp<a class="headerlink" href="#espnet2-asr-layers-cgmlp-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.layers.cgmlp"></span><p>MLP with convolutional gating (cgMLP) definition.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://openreview.net/forum?id=RA-zVvZLYIy">https://openreview.net/forum?id=RA-zVvZLYIy</a>
<a class="reference external" href="https://arxiv.org/abs/2105.08050">https://arxiv.org/abs/2105.08050</a></p>
<dl class="class">
<dt id="espnet2.asr.layers.cgmlp.ConvolutionalGatingMLP">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.layers.cgmlp.</code><code class="sig-name descname">ConvolutionalGatingMLP</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">linear_units: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">dropout_rate: float</em>, <em class="sig-param">use_linear_after_conv: bool</em>, <em class="sig-param">gate_activation: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/cgmlp.html#ConvolutionalGatingMLP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.cgmlp.ConvolutionalGatingMLP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional Gating MLP (cgMLP).</p>
<dl class="method">
<dt id="espnet2.asr.layers.cgmlp.ConvolutionalGatingMLP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/cgmlp.html#ConvolutionalGatingMLP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.cgmlp.ConvolutionalGatingMLP.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.layers.cgmlp.ConvolutionalSpatialGatingUnit">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.layers.cgmlp.</code><code class="sig-name descname">ConvolutionalSpatialGatingUnit</code><span class="sig-paren">(</span><em class="sig-param">size: int</em>, <em class="sig-param">kernel_size: int</em>, <em class="sig-param">dropout_rate: float</em>, <em class="sig-param">use_linear_after_conv: bool</em>, <em class="sig-param">gate_activation: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/cgmlp.html#ConvolutionalSpatialGatingUnit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.cgmlp.ConvolutionalSpatialGatingUnit" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Convolutional Spatial Gating Unit (CSGU).</p>
<dl class="method">
<dt id="espnet2.asr.layers.cgmlp.ConvolutionalSpatialGatingUnit.espnet_initialization_fn">
<code class="sig-name descname">espnet_initialization_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/cgmlp.html#ConvolutionalSpatialGatingUnit.espnet_initialization_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.cgmlp.ConvolutionalSpatialGatingUnit.espnet_initialization_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.layers.cgmlp.ConvolutionalSpatialGatingUnit.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">gate_add=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/layers/cgmlp.html#ConvolutionalSpatialGatingUnit.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.layers.cgmlp.ConvolutionalSpatialGatingUnit.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward method</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>torch.Tensor</em>) – (N, T, D)</p></li>
<li><p><strong>gate_add</strong> (<em>torch.Tensor</em>) – (N, T, D/2)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(N, T, D/2)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>out (torch.Tensor)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-layers-init-1">
<span id="espnet2-asr-layers-init"></span><h2>espnet2.asr.layers.__init__<a class="headerlink" href="#espnet2-asr-layers-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.layers.__init__"></span></section>
<section id="espnet2-asr-postencoder-length-adaptor-postencoder-1">
<span id="espnet2-asr-postencoder-length-adaptor-postencoder"></span><h2>espnet2.asr.postencoder.length_adaptor_postencoder<a class="headerlink" href="#espnet2-asr-postencoder-length-adaptor-postencoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.postencoder.length_adaptor_postencoder"></span><p>Length adaptor PostEncoder.</p>
<dl class="class">
<dt id="espnet2.asr.postencoder.length_adaptor_postencoder.LengthAdaptorPostEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.postencoder.length_adaptor_postencoder.</code><code class="sig-name descname">LengthAdaptorPostEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">length_adaptor_n_layers: int = 0</em>, <em class="sig-param">input_layer: Optional[str] = None</em>, <em class="sig-param">output_size: Optional[int] = None</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">return_int_enc: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/postencoder/length_adaptor_postencoder.html#LengthAdaptorPostEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.length_adaptor_postencoder.LengthAdaptorPostEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder" title="espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder</span></code></a></p>
<p>Length Adaptor PostEncoder.</p>
<p>Initialize the module.</p>
<dl class="method">
<dt id="espnet2.asr.postencoder.length_adaptor_postencoder.LengthAdaptorPostEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/postencoder/length_adaptor_postencoder.html#LengthAdaptorPostEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.length_adaptor_postencoder.LengthAdaptorPostEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.postencoder.length_adaptor_postencoder.LengthAdaptorPostEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/postencoder/length_adaptor_postencoder.html#LengthAdaptorPostEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.length_adaptor_postencoder.LengthAdaptorPostEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the output size.</p>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-postencoder-abs-postencoder-1">
<span id="espnet2-asr-postencoder-abs-postencoder"></span><h2>espnet2.asr.postencoder.abs_postencoder<a class="headerlink" href="#espnet2-asr-postencoder-abs-postencoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.postencoder.abs_postencoder"></span><dl class="class">
<dt id="espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.postencoder.abs_postencoder.</code><code class="sig-name descname">AbsPostEncoder</code><a class="reference internal" href="../_modules/espnet2/asr/postencoder/abs_postencoder.html#AbsPostEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/postencoder/abs_postencoder.html#AbsPostEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder.output_size">
<em class="property">abstract </em><code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/postencoder/abs_postencoder.html#AbsPostEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-postencoder-init-1">
<span id="espnet2-asr-postencoder-init"></span><h2>espnet2.asr.postencoder.__init__<a class="headerlink" href="#espnet2-asr-postencoder-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.postencoder.__init__"></span></section>
<section id="espnet2-asr-postencoder-hugging-face-transformers-postencoder-1">
<span id="espnet2-asr-postencoder-hugging-face-transformers-postencoder"></span><h2>espnet2.asr.postencoder.hugging_face_transformers_postencoder<a class="headerlink" href="#espnet2-asr-postencoder-hugging-face-transformers-postencoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.postencoder.hugging_face_transformers_postencoder"></span><p>Hugging Face Transformers PostEncoder.</p>
<dl class="class">
<dt id="espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.postencoder.hugging_face_transformers_postencoder.</code><code class="sig-name descname">HuggingFaceTransformersPostEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">model_name_or_path: str</em>, <em class="sig-param">length_adaptor_n_layers: int = 0</em>, <em class="sig-param">lang_token_id: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/postencoder/hugging_face_transformers_postencoder.html#HuggingFaceTransformersPostEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder" title="espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.postencoder.abs_postencoder.AbsPostEncoder</span></code></a></p>
<p>Hugging Face Transformers PostEncoder.</p>
<p>Initialize the module.</p>
<dl class="method">
<dt id="espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/postencoder/hugging_face_transformers_postencoder.html#HuggingFaceTransformersPostEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/postencoder/hugging_face_transformers_postencoder.html#HuggingFaceTransformersPostEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the output size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/postencoder/hugging_face_transformers_postencoder.html#HuggingFaceTransformersPostEncoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.postencoder.hugging_face_transformers_postencoder.HuggingFaceTransformersPostEncoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-abs-encoder-1">
<span id="espnet2-asr-encoder-abs-encoder"></span><h2>espnet2.asr.encoder.abs_encoder<a class="headerlink" href="#espnet2-asr-encoder-abs-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.abs_encoder"></span><dl class="class">
<dt id="espnet2.asr.encoder.abs_encoder.AbsEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.abs_encoder.</code><code class="sig-name descname">AbsEncoder</code><a class="reference internal" href="../_modules/espnet2/asr/encoder/abs_encoder.html#AbsEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="espnet2.asr.encoder.abs_encoder.AbsEncoder.forward">
<em class="property">abstract </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/abs_encoder.html#AbsEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.abs_encoder.AbsEncoder.output_size">
<em class="property">abstract </em><code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/abs_encoder.html#AbsEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-e-branchformer-encoder-1">
<span id="espnet2-asr-encoder-e-branchformer-encoder"></span><h2>espnet2.asr.encoder.e_branchformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-e-branchformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.e_branchformer_encoder"></span><p>E-Branchformer encoder definition.
Reference:</p>
<blockquote>
<div><p>Kwangyoun Kim, Felix Wu, Yifan Peng, Jing Pan,
Prashant Sridhar, Kyu J. Han, Shinji Watanabe,
“E-Branchformer: Branchformer with Enhanced merging
for speech recognition,” in SLT 2022.</p>
</div></blockquote>
<dl class="class">
<dt id="espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.e_branchformer_encoder.</code><code class="sig-name descname">EBranchformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">pos_enc_layer_type: str = 'rel_pos'</em>, <em class="sig-param">rel_pos_type: str = 'latest'</em>, <em class="sig-param">cgmlp_linear_units: int = 2048</em>, <em class="sig-param">cgmlp_conv_kernel: int = 31</em>, <em class="sig-param">use_linear_after_conv: bool = False</em>, <em class="sig-param">gate_activation: str = 'identity'</em>, <em class="sig-param">num_blocks: int = 12</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">zero_triu: bool = False</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">layer_drop_rate: float = 0.0</em>, <em class="sig-param">max_pos_emb_len: int = 5000</em>, <em class="sig-param">use_ffn: bool = False</em>, <em class="sig-param">macaron_ffn: bool = False</em>, <em class="sig-param">ffn_activation_type: str = 'swish'</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">merge_conv_kernel: int = 3</em>, <em class="sig-param">interctc_layer_idx=None</em>, <em class="sig-param">interctc_use_conditioning: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/e_branchformer_encoder.html#EBranchformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>E-Branchformer encoder module.</p>
<dl class="method">
<dt id="espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">ctc: espnet2.asr.ctc.CTC = None</em>, <em class="sig-param">max_layer: int = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/e_branchformer_encoder.html#EBranchformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, L, input_size).</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – Input length (#batch).</p></li>
<li><p><strong>prev_states</strong> (<em>torch.Tensor</em>) – Not to be used now.</p></li>
<li><p><strong>ctc</strong> (<a class="reference internal" href="espnet.nets.html#espnet.nets.pytorch_backend.ctc.CTC" title="espnet.nets.pytorch_backend.ctc.CTC"><em>CTC</em></a>) – Intermediate CTC module.</p></li>
<li><p><strong>max_layer</strong> (<em>int</em>) – Layer depth below which InterCTC is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, L, output_size).
torch.Tensor: Output length (#batch).
torch.Tensor: Not to be used now.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/e_branchformer_encoder.html#EBranchformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.e_branchformer_encoder.</code><code class="sig-name descname">EBranchformerEncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size: int, attn: torch.nn.modules.module.Module, cgmlp: torch.nn.modules.module.Module, feed_forward: Optional[torch.nn.modules.module.Module], feed_forward_macaron: Optional[torch.nn.modules.module.Module], dropout_rate: float, merge_conv_kernel: int = 3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/e_branchformer_encoder.html#EBranchformerEncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E-Branchformer encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – model dimension</p></li>
<li><p><strong>attn</strong> – standard self-attention or efficient attention</p></li>
<li><p><strong>cgmlp</strong> – ConvolutionalGatingMLP</p></li>
<li><p><strong>feed_forward</strong> – feed-forward module, optional</p></li>
<li><p><strong>feed_forward</strong> – macaron-style feed-forward module, optional</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout probability</p></li>
<li><p><strong>merge_conv_kernel</strong> (<em>int</em>) – kernel size of the depth-wise conv in merge module</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x_input</em>, <em class="sig-param">mask</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/e_branchformer_encoder.html#EBranchformerEncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.e_branchformer_encoder.EBranchformerEncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>Union</em><em>[</em><em>Tuple</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Input tensor w/ or w/o pos emb.
- w/ pos emb: Tuple of tensors [(#batch, time, size), (1, time, size)].
- w/o pos emb: Tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, 1, time).</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-transformer-encoder-1">
<span id="espnet2-asr-encoder-transformer-encoder"></span><h2>espnet2.asr.encoder.transformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-transformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.transformer_encoder"></span><p>Transformer encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.transformer_encoder.TransformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.transformer_encoder.</code><code class="sig-name descname">TransformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 1</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">interctc_layer_idx: List[int] = []</em>, <em class="sig-param">interctc_use_conditioning: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/transformer_encoder.html#TransformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.transformer_encoder.TransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Transformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>attention_heads</strong> – the number of heads of multi head attention</p></li>
<li><p><strong>linear_units</strong> – the number of units of position-wise feed forward</p></li>
<li><p><strong>num_blocks</strong> – the number of decoder blocks</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>attention_dropout_rate</strong> – dropout rate in attention</p></li>
<li><p><strong>positional_dropout_rate</strong> – dropout rate after adding positional encoding</p></li>
<li><p><strong>input_layer</strong> – input layer type</p></li>
<li><p><strong>pos_enc_class</strong> – PositionalEncoding or ScaledPositionalEncoding</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>concat_after</strong> – whether to concat attention layer’s input and output
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied.
i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> – linear of conv1d</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> – kernel size of positionwise conv1d layer</p></li>
<li><p><strong>padding_idx</strong> – padding_idx for input_layer=embed</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.transformer_encoder.TransformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">ctc: espnet2.asr.ctc.CTC = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/transformer_encoder.html#TransformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.transformer_encoder.TransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.transformer_encoder.TransformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/transformer_encoder.html#TransformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.transformer_encoder.TransformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-vgg-rnn-encoder-1">
<span id="espnet2-asr-encoder-vgg-rnn-encoder"></span><h2>espnet2.asr.encoder.vgg_rnn_encoder<a class="headerlink" href="#espnet2-asr-encoder-vgg-rnn-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.vgg_rnn_encoder"></span><dl class="class">
<dt id="espnet2.asr.encoder.vgg_rnn_encoder.VGGRNNEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.vgg_rnn_encoder.</code><code class="sig-name descname">VGGRNNEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">rnn_type: str = 'lstm'</em>, <em class="sig-param">bidirectional: bool = True</em>, <em class="sig-param">use_projection: bool = True</em>, <em class="sig-param">num_layers: int = 4</em>, <em class="sig-param">hidden_size: int = 320</em>, <em class="sig-param">output_size: int = 320</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">in_channel: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/vgg_rnn_encoder.html#VGGRNNEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.vgg_rnn_encoder.VGGRNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>VGGRNNEncoder class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input</p></li>
<li><p><strong>bidirectional</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code> becomes a bidirectional LSTM</p></li>
<li><p><strong>use_projection</strong> – Use projection layer or not</p></li>
<li><p><strong>num_layers</strong> – Number of recurrent layers</p></li>
<li><p><strong>hidden_size</strong> – The number of hidden features</p></li>
<li><p><strong>output_size</strong> – The number of output features</p></li>
<li><p><strong>dropout</strong> – dropout probability</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.vgg_rnn_encoder.VGGRNNEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/encoder/vgg_rnn_encoder.html#VGGRNNEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.vgg_rnn_encoder.VGGRNNEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.vgg_rnn_encoder.VGGRNNEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/vgg_rnn_encoder.html#VGGRNNEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.vgg_rnn_encoder.VGGRNNEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-hubert-encoder-1">
<span id="espnet2-asr-encoder-hubert-encoder"></span><h2>espnet2.asr.encoder.hubert_encoder<a class="headerlink" href="#espnet2-asr-encoder-hubert-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.hubert_encoder"></span><p>Encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.hubert_encoder.</code><code class="sig-name descname">FairseqHubertEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">hubert_url: str = './'</em>, <em class="sig-param">hubert_dir_path: str = './'</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">normalize_before: bool = False</em>, <em class="sig-param">freeze_finetune_updates: int = 0</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">activation_dropout: float = 0.1</em>, <em class="sig-param">attention_dropout: float = 0.0</em>, <em class="sig-param">mask_length: int = 10</em>, <em class="sig-param">mask_prob: float = 0.75</em>, <em class="sig-param">mask_selection: str = 'static'</em>, <em class="sig-param">mask_other: int = 0</em>, <em class="sig-param">apply_mask: bool = True</em>, <em class="sig-param">mask_channel_length: int = 64</em>, <em class="sig-param">mask_channel_prob: float = 0.5</em>, <em class="sig-param">mask_channel_other: int = 0</em>, <em class="sig-param">mask_channel_selection: str = 'static'</em>, <em class="sig-param">layerdrop: float = 0.1</em>, <em class="sig-param">feature_grad_mult: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>FairSeq Hubert encoder module, used for loading pretrained weight and finetuning</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>hubert_url</strong> – url to Hubert pretrained model</p></li>
<li><p><strong>hubert_dir_path</strong> – directory to download the Wav2Vec2.0 pretrained model.</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>freeze_finetune_updates</strong> – steps that freeze all layers except output layer
before tuning the whole model (nessasary to prevent overfit).</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>activation_dropout</strong> – dropout rate in activation function</p></li>
<li><p><strong>attention_dropout</strong> – dropout rate in attention</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Hubert specific Args:</dt><dd><p>Please refer to:
<a class="reference external" href="https://github.com/pytorch/fairseq/blob/master/fairseq/models/hubert/hubert.py">https://github.com/pytorch/fairseq/blob/master/fairseq/models/hubert/hubert.py</a></p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward Hubert ASR Encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertEncoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertEncoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.hubert_encoder.</code><code class="sig-name descname">FairseqHubertPretrainEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int = 1</em>, <em class="sig-param">output_size: int = 1024</em>, <em class="sig-param">linear_units: int = 1024</em>, <em class="sig-param">attention_heads: int = 12</em>, <em class="sig-param">num_blocks: int = 12</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">activation_dropout_rate: float = 0.0</em>, <em class="sig-param">hubert_dict: str = './dict.txt'</em>, <em class="sig-param">label_rate: int = 100</em>, <em class="sig-param">checkpoint_activations: bool = False</em>, <em class="sig-param">sample_rate: int = 16000</em>, <em class="sig-param">use_amp: bool = False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertPretrainEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>FairSeq Hubert pretrain encoder module, only used for pretraining stage</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>linear_units</strong> – dimension of feedforward layers</p></li>
<li><p><strong>attention_heads</strong> – the number of heads of multi head attention</p></li>
<li><p><strong>num_blocks</strong> – the number of encoder blocks</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>attention_dropout_rate</strong> – dropout rate in attention</p></li>
<li><p><strong>hubert_dict</strong> – target dictionary for Hubert pretraining</p></li>
<li><p><strong>label_rate</strong> – label frame rate. -1 for sequence label</p></li>
<li><p><strong>sample_rate</strong> – target sample rate.</p></li>
<li><p><strong>use_amp</strong> – whether to use automatic mixed precision</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.cast_mask_emb">
<code class="sig-name descname">cast_mask_emb</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertPretrainEncoder.cast_mask_emb"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.cast_mask_emb" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">ys_pad: torch.Tensor</em>, <em class="sig-param">ys_pad_length: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertPretrainEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward Hubert Pretrain Encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertPretrainEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#FairseqHubertPretrainEncoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.FairseqHubertPretrainEncoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.hubert_encoder.</code><code class="sig-name descname">TorchAudioHuBERTPretrainEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int = None, extractor_mode: str = 'group_norm', extractor_conv_layer_config: Optional[List[List[int]]] = [[512, 10, 5], [512, 3, 2], [512, 3, 2], [512, 3, 2], [512, 3, 2], [512, 2, 2], [512, 2, 2]], extractor_conv_bias: bool = False, encoder_embed_dim: int = 768, encoder_projection_dropout: float = 0.1, encoder_pos_conv_kernel: int = 128, encoder_pos_conv_groups: int = 16, encoder_num_layers: int = 12, encoder_num_heads: int = 12, encoder_attention_dropout: float = 0.1, encoder_ff_interm_features: int = 3072, encoder_ff_interm_dropout: float = 0.0, encoder_dropout: float = 0.1, encoder_layer_norm_first: bool = False, encoder_layer_drop: float = 0.05, mask_prob: float = 0.8, mask_selection: str = 'static', mask_other: float = 0.0, mask_length: int = 10, no_mask_overlap: bool = False, mask_min_space: int = 1, mask_channel_prob: float = 0.0, mask_channel_selection: str = 'static', mask_channel_other: float = 0.0, mask_channel_length: int = 10, no_mask_channel_overlap: bool = False, mask_channel_min_space: int = 1, skip_masked: bool = False, skip_nomask: bool = False, num_classes: int = 100, final_dim: int = 256, feature_grad_mult: Optional[float] = 0.1, finetuning: bool = False, freeze_encoder_updates: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#TorchAudioHuBERTPretrainEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Torch Audio Hubert encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>extractor_mode</strong> – Operation mode of feature extractor.
Valid values are “group_norm” or “layer_norm”.</p></li>
<li><p><strong>extractor_conv_layer_config</strong> – Configuration of convolution layers in feature
extractor. List of convolution configuration,
i.e. [[output_channel, kernel_size, stride], …]</p></li>
<li><p><strong>extractor_conv_bias</strong> – Whether to include bias term to each convolution
operation.</p></li>
<li><p><strong>encoder_embed_dim</strong> – The dimension of embedding in encoder.</p></li>
<li><p><strong>encoder_projection_dropout</strong> – The dropout probability applied after the input
feature is projected to “encoder_embed_dim”.</p></li>
<li><p><strong>encoder_pos_conv_kernel</strong> – Kernel size of convolutional positional embeddings.</p></li>
<li><p><strong>encoder_pos_conv_groups</strong> – Number of groups of convolutional positional
embeddings.</p></li>
<li><p><strong>encoder_num_layers</strong> – Number of self attention layers in transformer block.</p></li>
<li><p><strong>encoder_num_heads</strong> – Number of heads in self attention layers.</p></li>
<li><p><strong>encoder_attention_dropout</strong> – Dropout probability applied after softmax in
self-attention layer.</p></li>
<li><p><strong>encoder_ff_interm_features</strong> – Dimension of hidden features in feed forward layer.</p></li>
<li><p><strong>encoder_ff_interm_dropout</strong> – Dropout probability applied in feedforward layer.</p></li>
<li><p><strong>encoder_dropout</strong> – Dropout probability applied at the end of feed forward layer.</p></li>
<li><p><strong>encoder_layer_norm_first</strong> – Control the order of layer norm in transformer layer
and each encoder layer. If True, in transformer layer, layer norm is
applied before features are fed to encoder layers.</p></li>
<li><p><strong>encoder_layer_drop</strong> – Probability to drop each encoder layer during training.</p></li>
<li><p><strong>mask_prob</strong> – Probability for each token to be chosen as start of the span
to be masked.</p></li>
<li><p><strong>mask_selection</strong> – How to choose the mask length.
Options: [static, uniform, normal, poisson].</p></li>
<li><p><strong>mask_other</strong> – Secondary mask argument (used for more complex distributions).</p></li>
<li><p><strong>mask_length</strong> – The lengths of the mask.</p></li>
<li><p><strong>no_mask_overlap</strong> – Whether to allow masks to overlap.</p></li>
<li><p><strong>mask_min_space</strong> – Minimum space between spans (if no overlap is enabled).</p></li>
<li><p><strong>mask_channel_prob</strong> – (float): The probability of replacing a feature with 0.</p></li>
<li><p><strong>mask_channel_selection</strong> – How to choose the mask length for channel masking.
Options: [static, uniform, normal, poisson].</p></li>
<li><p><strong>mask_channel_other</strong> – Secondary mask argument for channel masking(used for more
complex distributions).</p></li>
<li><p><strong>mask_channel_length</strong> – Minimum space between spans (if no overlap is enabled)
for channel masking.</p></li>
<li><p><strong>no_mask_channel_overlap</strong> – Whether to allow channel masks to overlap.</p></li>
<li><p><strong>mask_channel_min_space</strong> – Minimum space between spans for channel
masking(if no overlap is enabled).</p></li>
<li><p><strong>skip_masked</strong> – If True, skip computing losses over masked frames.</p></li>
<li><p><strong>skip_nomask</strong> – If True, skip computing losses over unmasked frames.</p></li>
<li><p><strong>num_classes</strong> – The number of classes in the labels.</p></li>
<li><p><strong>final_dim</strong> – Project final representations and targets to final_dim.</p></li>
<li><p><strong>feature_grad_mult</strong> – The factor to scale the convolutional feature extraction
layer gradients by. The scale factor will not affect the forward pass.</p></li>
<li><p><strong>finetuning</strong> – Whether to finetuning the model with ASR or other tasks.</p></li>
<li><p><strong>freeze_encoder_updates</strong> – The number of steps to freeze the encoder parameters
in ASR finetuning.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Hubert specific Args:</dt><dd><p>Please refer to:
<a class="reference external" href="https://pytorch.org/audio/stable/generated/torchaudio.models.hubert_pretrain_model.html#torchaudio.models.hubert_pretrain_model">https://pytorch.org/audio/stable/generated/torchaudio.models.hubert_pretrain_model.html#torchaudio.models.hubert_pretrain_model</a></p>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">ys_pad: torch.Tensor = None</em>, <em class="sig-param">ys_pad_length: torch.Tensor = None</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#TorchAudioHuBERTPretrainEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward Hubert Pretrain Encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#TorchAudioHuBERTPretrainEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#TorchAudioHuBERTPretrainEncoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.TorchAudioHuBERTPretrainEncoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.encoder.hubert_encoder.download_hubert">
<code class="sig-prename descclassname">espnet2.asr.encoder.hubert_encoder.</code><code class="sig-name descname">download_hubert</code><span class="sig-paren">(</span><em class="sig-param">model_url</em>, <em class="sig-param">dir_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hubert_encoder.html#download_hubert"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hubert_encoder.download_hubert" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-encoder-conformer-encoder-1">
<span id="espnet2-asr-encoder-conformer-encoder"></span><h2>espnet2.asr.encoder.conformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-conformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.conformer_encoder"></span><p>Conformer encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.conformer_encoder.ConformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.conformer_encoder.</code><code class="sig-name descname">ConformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 3</em>, <em class="sig-param">macaron_style: bool = False</em>, <em class="sig-param">rel_pos_type: str = 'legacy'</em>, <em class="sig-param">pos_enc_layer_type: str = 'rel_pos'</em>, <em class="sig-param">selfattention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">use_cnn_module: bool = True</em>, <em class="sig-param">zero_triu: bool = False</em>, <em class="sig-param">cnn_module_kernel: int = 31</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">interctc_layer_idx: List[int] = []</em>, <em class="sig-param">interctc_use_conditioning: bool = False</em>, <em class="sig-param">stochastic_depth_rate: Union[float</em>, <em class="sig-param">List[float]] = 0.0</em>, <em class="sig-param">layer_drop_rate: float = 0.0</em>, <em class="sig-param">max_pos_emb_len: int = 5000</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/conformer_encoder.html#ConformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.conformer_encoder.ConformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Conformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>output_size</strong> (<em>int</em>) – Dimension of attention.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of heads of multi head attention.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of units of position-wise feed forward.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of decoder blocks.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate in attention.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after adding positional encoding.</p></li>
<li><p><strong>input_layer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.nn.Module</em><em>]</em>) – Input layer type.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
If True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
If False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – “linear”, “conv1d”, or “conv1d-linear”.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Kernel size of positionwise conv1d layer.</p></li>
<li><p><strong>rel_pos_type</strong> (<em>str</em>) – Whether to use the latest relative positional encoding or
the legacy one. The legacy relative positional encoding will be deprecated
in the future. More Details can be found in
<a class="reference external" href="https://github.com/espnet/espnet/pull/2816">https://github.com/espnet/espnet/pull/2816</a>.</p></li>
<li><p><strong>encoder_pos_enc_layer_type</strong> (<em>str</em>) – Encoder positional encoding layer type.</p></li>
<li><p><strong>encoder_attn_layer_type</strong> (<em>str</em>) – Encoder attention layer type.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – Encoder activation function type.</p></li>
<li><p><strong>macaron_style</strong> (<em>bool</em>) – Whether to use macaron style for positionwise layer.</p></li>
<li><p><strong>use_cnn_module</strong> (<em>bool</em>) – Whether to use convolution module.</p></li>
<li><p><strong>zero_triu</strong> (<em>bool</em>) – Whether to zero the upper triangular part of attention matrix.</p></li>
<li><p><strong>cnn_module_kernel</strong> (<em>int</em>) – Kernerl size of convolution module.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>) – Padding idx for input_layer=embed.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.conformer_encoder.ConformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">ctc: espnet2.asr.ctc.CTC = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/conformer_encoder.html#ConformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.conformer_encoder.ConformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, L, input_size).</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – Input length (#batch).</p></li>
<li><p><strong>prev_states</strong> (<em>torch.Tensor</em>) – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, L, output_size).
torch.Tensor: Output length (#batch).
torch.Tensor: Not to be used now.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.conformer_encoder.ConformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/conformer_encoder.html#ConformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.conformer_encoder.ConformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-transformer-encoder-multispkr-1">
<span id="espnet2-asr-encoder-transformer-encoder-multispkr"></span><h2>espnet2.asr.encoder.transformer_encoder_multispkr<a class="headerlink" href="#espnet2-asr-encoder-transformer-encoder-multispkr-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.transformer_encoder_multispkr"></span><p>Encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.transformer_encoder_multispkr.TransformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.transformer_encoder_multispkr.</code><code class="sig-name descname">TransformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">num_blocks_sd: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.PositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 1</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">num_inf: int = 1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/transformer_encoder_multispkr.html#TransformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.transformer_encoder_multispkr.TransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Transformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>attention_heads</strong> – the number of heads of multi head attention</p></li>
<li><p><strong>linear_units</strong> – the number of units of position-wise feed forward</p></li>
<li><p><strong>num_blocks</strong> – the number of recognition encoder blocks</p></li>
<li><p><strong>num_blocks_sd</strong> – the number of speaker dependent encoder blocks</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>attention_dropout_rate</strong> – dropout rate in attention</p></li>
<li><p><strong>positional_dropout_rate</strong> – dropout rate after adding positional encoding</p></li>
<li><p><strong>input_layer</strong> – input layer type</p></li>
<li><p><strong>pos_enc_class</strong> – PositionalEncoding or ScaledPositionalEncoding</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>concat_after</strong> – whether to concat attention layer’s input and output
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied.
i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> – linear of conv1d</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> – kernel size of positionwise conv1d layer</p></li>
<li><p><strong>padding_idx</strong> – padding_idx for input_layer=embed</p></li>
<li><p><strong>num_inf</strong> – number of inference output</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.transformer_encoder_multispkr.TransformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/transformer_encoder_multispkr.html#TransformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.transformer_encoder_multispkr.TransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.transformer_encoder_multispkr.TransformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/transformer_encoder_multispkr.html#TransformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.transformer_encoder_multispkr.TransformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-branchformer-encoder-1">
<span id="espnet2-asr-encoder-branchformer-encoder"></span><h2>espnet2.asr.encoder.branchformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-branchformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.branchformer_encoder"></span><p>Branchformer encoder definition.</p>
<dl class="simple">
<dt>Reference:</dt><dd><p>Yifan Peng, Siddharth Dalmia, Ian Lane, and Shinji Watanabe,
“Branchformer: Parallel MLP-Attention Architectures to Capture
Local and Global Context for Speech Recognition and Understanding,”
in Proceedings of ICML, 2022.</p>
</dd>
</dl>
<dl class="class">
<dt id="espnet2.asr.encoder.branchformer_encoder.BranchformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.branchformer_encoder.</code><code class="sig-name descname">BranchformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">use_attn: bool = True</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">attention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">pos_enc_layer_type: str = 'rel_pos'</em>, <em class="sig-param">rel_pos_type: str = 'latest'</em>, <em class="sig-param">use_cgmlp: bool = True</em>, <em class="sig-param">cgmlp_linear_units: int = 2048</em>, <em class="sig-param">cgmlp_conv_kernel: int = 31</em>, <em class="sig-param">use_linear_after_conv: bool = False</em>, <em class="sig-param">gate_activation: str = 'identity'</em>, <em class="sig-param">merge_method: str = 'concat'</em>, <em class="sig-param">cgmlp_weight: Union[float</em>, <em class="sig-param">List[float]] = 0.5</em>, <em class="sig-param">attn_branch_drop_rate: Union[float</em>, <em class="sig-param">List[float]] = 0.0</em>, <em class="sig-param">num_blocks: int = 12</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">zero_triu: bool = False</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">stochastic_depth_rate: Union[float</em>, <em class="sig-param">List[float]] = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/branchformer_encoder.html#BranchformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.branchformer_encoder.BranchformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Branchformer encoder module.</p>
<dl class="method">
<dt id="espnet2.asr.encoder.branchformer_encoder.BranchformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/branchformer_encoder.html#BranchformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.branchformer_encoder.BranchformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, L, input_size).</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – Input length (#batch).</p></li>
<li><p><strong>prev_states</strong> (<em>torch.Tensor</em>) – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, L, output_size).
torch.Tensor: Output length (#batch).
torch.Tensor: Not to be used now.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.branchformer_encoder.BranchformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/branchformer_encoder.html#BranchformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.branchformer_encoder.BranchformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet2.asr.encoder.branchformer_encoder.BranchformerEncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.branchformer_encoder.</code><code class="sig-name descname">BranchformerEncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">size: int, attn: Optional[torch.nn.modules.module.Module], cgmlp: Optional[torch.nn.modules.module.Module], dropout_rate: float, merge_method: str, cgmlp_weight: float = 0.5, attn_branch_drop_rate: float = 0.0, stochastic_depth_rate: float = 0.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/branchformer_encoder.html#BranchformerEncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.branchformer_encoder.BranchformerEncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Branchformer encoder layer module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – model dimension</p></li>
<li><p><strong>attn</strong> – standard self-attention or efficient attention, optional</p></li>
<li><p><strong>cgmlp</strong> – ConvolutionalGatingMLP, optional</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – dropout probability</p></li>
<li><p><strong>merge_method</strong> (<em>str</em>) – concat, learned_ave, fixed_ave</p></li>
<li><p><strong>cgmlp_weight</strong> (<em>float</em>) – weight of the cgmlp branch, between 0 and 1,
used if merge_method is fixed_ave</p></li>
<li><p><strong>attn_branch_drop_rate</strong> (<em>float</em>) – probability of dropping the attn branch,
used if merge_method is learned_ave</p></li>
<li><p><strong>stochastic_depth_rate</strong> (<em>float</em>) – stochastic depth probability</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.branchformer_encoder.BranchformerEncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x_input</em>, <em class="sig-param">mask</em>, <em class="sig-param">cache=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/branchformer_encoder.html#BranchformerEncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.branchformer_encoder.BranchformerEncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encoded features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x_input</strong> (<em>Union</em><em>[</em><em>Tuple</em><em>, </em><em>torch.Tensor</em><em>]</em>) – Input tensor w/ or w/o pos emb.
- w/ pos emb: Tuple of tensors [(#batch, time, size), (1, time, size)].
- w/o pos emb: Tensor (#batch, time, size).</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – Mask tensor for the input (#batch, 1, time).</p></li>
<li><p><strong>cache</strong> (<em>torch.Tensor</em>) – Cache tensor of the input (#batch, time - 1, size).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, time, size).
torch.Tensor: Mask tensor (#batch, time).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-whisper-encoder-1">
<span id="espnet2-asr-encoder-whisper-encoder"></span><h2>espnet2.asr.encoder.whisper_encoder<a class="headerlink" href="#espnet2-asr-encoder-whisper-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.whisper_encoder"></span><dl class="class">
<dt id="espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.whisper_encoder.</code><code class="sig-name descname">OpenAIWhisperEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int = 1</em>, <em class="sig-param">dropout_rate: float = 0.0</em>, <em class="sig-param">whisper_model: str = 'small'</em>, <em class="sig-param">download_dir: str = None</em>, <em class="sig-param">use_specaug: bool = False</em>, <em class="sig-param">specaug_conf: Optional[dict] = None</em>, <em class="sig-param">do_pad_trim: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/whisper_encoder.html#OpenAIWhisperEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Transformer-based Speech Encoder from OpenAI’s Whisper Model:</p>
<p>URL: <a class="reference external" href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></p>
<dl class="method">
<dt id="espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/whisper_encoder.html#OpenAIWhisperEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.log_mel_spectrogram">
<code class="sig-name descname">log_mel_spectrogram</code><span class="sig-paren">(</span><em class="sig-param">audio: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/encoder/whisper_encoder.html#OpenAIWhisperEncoder.log_mel_spectrogram"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.log_mel_spectrogram" title="Permalink to this definition">¶</a></dt>
<dd><p>Use log-mel spectrogram computation native to Whisper training</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/whisper_encoder.html#OpenAIWhisperEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.pad_or_trim">
<code class="sig-name descname">pad_or_trim</code><span class="sig-paren">(</span><em class="sig-param">array: torch.Tensor</em>, <em class="sig-param">length: int</em>, <em class="sig-param">axis: int = -1</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/encoder/whisper_encoder.html#OpenAIWhisperEncoder.pad_or_trim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.pad_or_trim" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad or trim the audio array to N_SAMPLES.</p>
<p>Used in zero-shot inference cases.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.whisper_encode">
<code class="sig-name descname">whisper_encode</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; torch.Tensor<a class="reference internal" href="../_modules/espnet2/asr/encoder/whisper_encoder.html#OpenAIWhisperEncoder.whisper_encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.whisper_encoder.OpenAIWhisperEncoder.whisper_encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-wav2vec2-encoder-1">
<span id="espnet2-asr-encoder-wav2vec2-encoder"></span><h2>espnet2.asr.encoder.wav2vec2_encoder<a class="headerlink" href="#espnet2-asr-encoder-wav2vec2-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.wav2vec2_encoder"></span><p>Encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.wav2vec2_encoder.</code><code class="sig-name descname">FairSeqWav2Vec2Encoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">w2v_url: str</em>, <em class="sig-param">w2v_dir_path: str = './'</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">normalize_before: bool = False</em>, <em class="sig-param">freeze_finetune_updates: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/wav2vec2_encoder.html#FairSeqWav2Vec2Encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>FairSeq Wav2Vec2 encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>w2v_url</strong> – url to Wav2Vec2.0 pretrained model</p></li>
<li><p><strong>w2v_dir_path</strong> – directory to download the Wav2Vec2.0 pretrained model.</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>finetune_last_n_layers</strong> – last n layers to be finetuned in Wav2Vec2.0
0 means to finetune every layer if freeze_w2v=False.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/wav2vec2_encoder.html#FairSeqWav2Vec2Encoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward FairSeqWav2Vec2 Encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/wav2vec2_encoder.html#FairSeqWav2Vec2Encoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/wav2vec2_encoder.html#FairSeqWav2Vec2Encoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.wav2vec2_encoder.FairSeqWav2Vec2Encoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet2.asr.encoder.wav2vec2_encoder.download_w2v">
<code class="sig-prename descclassname">espnet2.asr.encoder.wav2vec2_encoder.</code><code class="sig-name descname">download_w2v</code><span class="sig-paren">(</span><em class="sig-param">model_url</em>, <em class="sig-param">dir_path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/wav2vec2_encoder.html#download_w2v"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.wav2vec2_encoder.download_w2v" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</section>
<section id="espnet2-asr-encoder-contextual-block-transformer-encoder-1">
<span id="espnet2-asr-encoder-contextual-block-transformer-encoder"></span><h2>espnet2.asr.encoder.contextual_block_transformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-contextual-block-transformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.contextual_block_transformer_encoder"></span><p>Encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.contextual_block_transformer_encoder.</code><code class="sig-name descname">ContextualBlockTransformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding'&gt;</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 1</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">block_size: int = 40</em>, <em class="sig-param">hop_size: int = 16</em>, <em class="sig-param">look_ahead: int = 16</em>, <em class="sig-param">init_average: bool = True</em>, <em class="sig-param">ctx_pos_enc: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_transformer_encoder.html#ContextualBlockTransformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Contextual Block Transformer encoder module.</p>
<p>Details in Tsunoo et al. “Transformer ASR with contextual block processing”
(<a class="reference external" href="https://arxiv.org/abs/1910.07204">https://arxiv.org/abs/1910.07204</a>)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>attention_heads</strong> – the number of heads of multi head attention</p></li>
<li><p><strong>linear_units</strong> – the number of units of position-wise feed forward</p></li>
<li><p><strong>num_blocks</strong> – the number of encoder blocks</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>attention_dropout_rate</strong> – dropout rate in attention</p></li>
<li><p><strong>positional_dropout_rate</strong> – dropout rate after adding positional encoding</p></li>
<li><p><strong>input_layer</strong> – input layer type</p></li>
<li><p><strong>pos_enc_class</strong> – PositionalEncoding or ScaledPositionalEncoding</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>concat_after</strong> – whether to concat attention layer’s input and output
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied.
i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> – linear of conv1d</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> – kernel size of positionwise conv1d layer</p></li>
<li><p><strong>padding_idx</strong> – padding_idx for input_layer=embed</p></li>
<li><p><strong>block_size</strong> – block size for contextual block processing</p></li>
<li><p><strong>hop_Size</strong> – hop size for block processing</p></li>
<li><p><strong>look_ahead</strong> – look-ahead size for block_processing</p></li>
<li><p><strong>init_average</strong> – whether to use average as initial context (otherwise max values)</p></li>
<li><p><strong>ctx_pos_enc</strong> – whether to use positional encoding to the context vectors</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">is_final=True</em>, <em class="sig-param">infer_mode=False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_transformer_encoder.html#ContextualBlockTransformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
<li><p><strong>infer_mode</strong> – whether to be used for inference. This is used to
distinguish between forward_train (train and validate) and
forward_infer (decode).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.forward_infer">
<code class="sig-name descname">forward_infer</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">is_final: bool = True</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_transformer_encoder.html#ContextualBlockTransformerEncoder.forward_infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.forward_infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.forward_train">
<code class="sig-name descname">forward_train</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_transformer_encoder.html#ContextualBlockTransformerEncoder.forward_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_transformer_encoder.html#ContextualBlockTransformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_transformer_encoder.ContextualBlockTransformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-contextual-block-conformer-encoder-1">
<span id="espnet2-asr-encoder-contextual-block-conformer-encoder"></span><h2>espnet2.asr.encoder.contextual_block_conformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-contextual-block-conformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.contextual_block_conformer_encoder"></span><p>Created on Sat Aug 21 17:27:16 2021.</p>
<p>&#64;author: Keqi Deng (UCAS)</p>
<dl class="class">
<dt id="espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.contextual_block_conformer_encoder.</code><code class="sig-name descname">ContextualBlockConformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">output_size: int = 256</em>, <em class="sig-param">attention_heads: int = 4</em>, <em class="sig-param">linear_units: int = 2048</em>, <em class="sig-param">num_blocks: int = 6</em>, <em class="sig-param">dropout_rate: float = 0.1</em>, <em class="sig-param">positional_dropout_rate: float = 0.1</em>, <em class="sig-param">attention_dropout_rate: float = 0.0</em>, <em class="sig-param">input_layer: Optional[str] = 'conv2d'</em>, <em class="sig-param">normalize_before: bool = True</em>, <em class="sig-param">concat_after: bool = False</em>, <em class="sig-param">positionwise_layer_type: str = 'linear'</em>, <em class="sig-param">positionwise_conv_kernel_size: int = 3</em>, <em class="sig-param">macaron_style: bool = False</em>, <em class="sig-param">pos_enc_class=&lt;class 'espnet.nets.pytorch_backend.transformer.embedding.StreamPositionalEncoding'&gt;</em>, <em class="sig-param">selfattention_layer_type: str = 'rel_selfattn'</em>, <em class="sig-param">activation_type: str = 'swish'</em>, <em class="sig-param">use_cnn_module: bool = True</em>, <em class="sig-param">cnn_module_kernel: int = 31</em>, <em class="sig-param">padding_idx: int = -1</em>, <em class="sig-param">block_size: int = 40</em>, <em class="sig-param">hop_size: int = 16</em>, <em class="sig-param">look_ahead: int = 16</em>, <em class="sig-param">init_average: bool = True</em>, <em class="sig-param">ctx_pos_enc: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_conformer_encoder.html#ContextualBlockConformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Contextual Block Conformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – input dim</p></li>
<li><p><strong>output_size</strong> – dimension of attention</p></li>
<li><p><strong>attention_heads</strong> – the number of heads of multi head attention</p></li>
<li><p><strong>linear_units</strong> – the number of units of position-wise feed forward</p></li>
<li><p><strong>num_blocks</strong> – the number of decoder blocks</p></li>
<li><p><strong>dropout_rate</strong> – dropout rate</p></li>
<li><p><strong>attention_dropout_rate</strong> – dropout rate in attention</p></li>
<li><p><strong>positional_dropout_rate</strong> – dropout rate after adding positional encoding</p></li>
<li><p><strong>input_layer</strong> – input layer type</p></li>
<li><p><strong>pos_enc_class</strong> – PositionalEncoding or ScaledPositionalEncoding</p></li>
<li><p><strong>normalize_before</strong> – whether to use layer_norm before the first block</p></li>
<li><p><strong>concat_after</strong> – whether to concat attention layer’s input and output
if True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
if False, no additional linear will be applied.
i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> – linear of conv1d</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> – kernel size of positionwise conv1d layer</p></li>
<li><p><strong>padding_idx</strong> – padding_idx for input_layer=embed</p></li>
<li><p><strong>block_size</strong> – block size for contextual block processing</p></li>
<li><p><strong>hop_Size</strong> – hop size for block processing</p></li>
<li><p><strong>look_ahead</strong> – look-ahead size for block_processing</p></li>
<li><p><strong>init_average</strong> – whether to use average as initial context (otherwise max values)</p></li>
<li><p><strong>ctx_pos_enc</strong> – whether to use positional encoding to the context vectors</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">is_final=True</em>, <em class="sig-param">infer_mode=False</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_conformer_encoder.html#ContextualBlockConformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
<li><p><strong>infer_mode</strong> – whether to be used for inference. This is used to
distinguish between forward_train (train and validate) and
forward_infer (decode).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.forward_infer">
<code class="sig-name descname">forward_infer</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">is_final: bool = True</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_conformer_encoder.html#ContextualBlockConformerEncoder.forward_infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.forward_infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.forward_train">
<code class="sig-name descname">forward_train</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_conformer_encoder.html#ContextualBlockConformerEncoder.forward_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.forward_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Embed positions in tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> – input tensor (B, L, D)</p></li>
<li><p><strong>ilens</strong> – input length (B)</p></li>
<li><p><strong>prev_states</strong> – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>position embedded tensor and mask</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/contextual_block_conformer_encoder.html#ContextualBlockConformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.contextual_block_conformer_encoder.ContextualBlockConformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-hugging-face-transformers-encoder-1">
<span id="espnet2-asr-encoder-hugging-face-transformers-encoder"></span><h2>espnet2.asr.encoder.hugging_face_transformers_encoder<a class="headerlink" href="#espnet2-asr-encoder-hugging-face-transformers-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.hugging_face_transformers_encoder"></span><p>Hugging Face Transformers PostEncoder.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.hugging_face_transformers_encoder.</code><code class="sig-name descname">HuggingFaceTransformersEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">model_name_or_path: str</em>, <em class="sig-param">lang_token_id: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hugging_face_transformers_encoder.html#HuggingFaceTransformersEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>Hugging Face Transformers PostEncoder.</p>
<p>Initialize the module.</p>
<dl class="method">
<dt id="espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input: torch.Tensor</em>, <em class="sig-param">input_lengths: torch.Tensor</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/encoder/hugging_face_transformers_encoder.html#HuggingFaceTransformersEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/hugging_face_transformers_encoder.html#HuggingFaceTransformersEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the output size.</p>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder.reload_pretrained_parameters">
<code class="sig-name descname">reload_pretrained_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/hugging_face_transformers_encoder.html#HuggingFaceTransformersEncoder.reload_pretrained_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.hugging_face_transformers_encoder.HuggingFaceTransformersEncoder.reload_pretrained_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-longformer-encoder-1">
<span id="espnet2-asr-encoder-longformer-encoder"></span><h2>espnet2.asr.encoder.longformer_encoder<a class="headerlink" href="#espnet2-asr-encoder-longformer-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.longformer_encoder"></span><p>Conformer encoder definition.</p>
<dl class="class">
<dt id="espnet2.asr.encoder.longformer_encoder.LongformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.longformer_encoder.</code><code class="sig-name descname">LongformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int, output_size: int = 256, attention_heads: int = 4, linear_units: int = 2048, num_blocks: int = 6, dropout_rate: float = 0.1, positional_dropout_rate: float = 0.1, attention_dropout_rate: float = 0.0, input_layer: str = 'conv2d', normalize_before: bool = True, concat_after: bool = False, positionwise_layer_type: str = 'linear', positionwise_conv_kernel_size: int = 3, macaron_style: bool = False, rel_pos_type: str = 'legacy', pos_enc_layer_type: str = 'abs_pos', selfattention_layer_type: str = 'lf_selfattn', activation_type: str = 'swish', use_cnn_module: bool = True, zero_triu: bool = False, cnn_module_kernel: int = 31, padding_idx: int = -1, interctc_layer_idx: List[int] = [], interctc_use_conditioning: bool = False, attention_windows: list = [100, 100, 100, 100, 100, 100], attention_dilation: list = [1, 1, 1, 1, 1, 1], attention_mode: str = 'sliding_chunks'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/longformer_encoder.html#LongformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.longformer_encoder.LongformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.conformer_encoder.ConformerEncoder" title="espnet2.asr.encoder.conformer_encoder.ConformerEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.conformer_encoder.ConformerEncoder</span></code></a></p>
<p>Longformer SA Conformer encoder module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – Input dimension.</p></li>
<li><p><strong>output_size</strong> (<em>int</em>) – Dimension of attention.</p></li>
<li><p><strong>attention_heads</strong> (<em>int</em>) – The number of heads of multi head attention.</p></li>
<li><p><strong>linear_units</strong> (<em>int</em>) – The number of units of position-wise feed forward.</p></li>
<li><p><strong>num_blocks</strong> (<em>int</em>) – The number of decoder blocks.</p></li>
<li><p><strong>dropout_rate</strong> (<em>float</em>) – Dropout rate.</p></li>
<li><p><strong>attention_dropout_rate</strong> (<em>float</em>) – Dropout rate in attention.</p></li>
<li><p><strong>positional_dropout_rate</strong> (<em>float</em>) – Dropout rate after adding positional encoding.</p></li>
<li><p><strong>input_layer</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.nn.Module</em><em>]</em>) – Input layer type.</p></li>
<li><p><strong>normalize_before</strong> (<em>bool</em>) – Whether to use layer_norm before the first block.</p></li>
<li><p><strong>concat_after</strong> (<em>bool</em>) – Whether to concat attention layer’s input and output.
If True, additional linear will be applied.
i.e. x -&gt; x + linear(concat(x, att(x)))
If False, no additional linear will be applied. i.e. x -&gt; x + att(x)</p></li>
<li><p><strong>positionwise_layer_type</strong> (<em>str</em>) – “linear”, “conv1d”, or “conv1d-linear”.</p></li>
<li><p><strong>positionwise_conv_kernel_size</strong> (<em>int</em>) – Kernel size of positionwise conv1d layer.</p></li>
<li><p><strong>rel_pos_type</strong> (<em>str</em>) – Whether to use the latest relative positional encoding or
the legacy one. The legacy relative positional encoding will be deprecated
in the future. More Details can be found in
<a class="reference external" href="https://github.com/espnet/espnet/pull/2816">https://github.com/espnet/espnet/pull/2816</a>.</p></li>
<li><p><strong>encoder_pos_enc_layer_type</strong> (<em>str</em>) – Encoder positional encoding layer type.</p></li>
<li><p><strong>encoder_attn_layer_type</strong> (<em>str</em>) – Encoder attention layer type.</p></li>
<li><p><strong>activation_type</strong> (<em>str</em>) – Encoder activation function type.</p></li>
<li><p><strong>macaron_style</strong> (<em>bool</em>) – Whether to use macaron style for positionwise layer.</p></li>
<li><p><strong>use_cnn_module</strong> (<em>bool</em>) – Whether to use convolution module.</p></li>
<li><p><strong>zero_triu</strong> (<em>bool</em>) – Whether to zero the upper triangular part of attention matrix.</p></li>
<li><p><strong>cnn_module_kernel</strong> (<em>int</em>) – Kernerl size of convolution module.</p></li>
<li><p><strong>padding_idx</strong> (<em>int</em>) – Padding idx for input_layer=embed.</p></li>
<li><p><strong>attention_windows</strong> (<em>list</em>) – Layer-wise attention window sizes
for longformer self-attn</p></li>
<li><p><strong>attention_dilation</strong> (<em>list</em>) – Layer-wise attention dilation sizes
for longformer self-attn</p></li>
<li><p><strong>attention_mode</strong> (<em>str</em>) – Implementation for longformer self-attn.
Default=”sliding_chunks”
Choose ‘n2’, ‘tvm’ or ‘sliding_chunks’. More details in
<a class="reference external" href="https://github.com/allenai/longformer">https://github.com/allenai/longformer</a></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.longformer_encoder.LongformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em>, <em class="sig-param">ctc: espnet2.asr.ctc.CTC = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]<a class="reference internal" href="../_modules/espnet2/asr/encoder/longformer_encoder.html#LongformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.longformer_encoder.LongformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs_pad</strong> (<em>torch.Tensor</em>) – Input tensor (#batch, L, input_size).</p></li>
<li><p><strong>ilens</strong> (<em>torch.Tensor</em>) – Input length (#batch).</p></li>
<li><p><strong>prev_states</strong> (<em>torch.Tensor</em>) – Not to be used now.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor (#batch, L, output_size).
torch.Tensor: Output length (#batch).
torch.Tensor: Not to be used now.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.longformer_encoder.LongformerEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/longformer_encoder.html#LongformerEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.longformer_encoder.LongformerEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-rnn-encoder-1">
<span id="espnet2-asr-encoder-rnn-encoder"></span><h2>espnet2.asr.encoder.rnn_encoder<a class="headerlink" href="#espnet2-asr-encoder-rnn-encoder-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.rnn_encoder"></span><dl class="class">
<dt id="espnet2.asr.encoder.rnn_encoder.RNNEncoder">
<em class="property">class </em><code class="sig-prename descclassname">espnet2.asr.encoder.rnn_encoder.</code><code class="sig-name descname">RNNEncoder</code><span class="sig-paren">(</span><em class="sig-param">input_size: int</em>, <em class="sig-param">rnn_type: str = 'lstm'</em>, <em class="sig-param">bidirectional: bool = True</em>, <em class="sig-param">use_projection: bool = True</em>, <em class="sig-param">num_layers: int = 4</em>, <em class="sig-param">hidden_size: int = 320</em>, <em class="sig-param">output_size: int = 320</em>, <em class="sig-param">dropout: float = 0.0</em>, <em class="sig-param">subsample: Optional[Sequence[int]] = (2</em>, <em class="sig-param">2</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/espnet2/asr/encoder/rnn_encoder.html#RNNEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.rnn_encoder.RNNEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet2.asr.encoder.abs_encoder.AbsEncoder" title="espnet2.asr.encoder.abs_encoder.AbsEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet2.asr.encoder.abs_encoder.AbsEncoder</span></code></a></p>
<p>RNNEncoder class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input</p></li>
<li><p><strong>output_size</strong> – The number of output features</p></li>
<li><p><strong>hidden_size</strong> – The number of hidden features</p></li>
<li><p><strong>bidirectional</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code> becomes a bidirectional LSTM</p></li>
<li><p><strong>use_projection</strong> – Use projection layer or not</p></li>
<li><p><strong>num_layers</strong> – Number of recurrent layers</p></li>
<li><p><strong>dropout</strong> – dropout probability</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="espnet2.asr.encoder.rnn_encoder.RNNEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs_pad: torch.Tensor</em>, <em class="sig-param">ilens: torch.Tensor</em>, <em class="sig-param">prev_states: torch.Tensor = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]<a class="reference internal" href="../_modules/espnet2/asr/encoder/rnn_encoder.html#RNNEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.rnn_encoder.RNNEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</aside>
</dd></dl>

<dl class="method">
<dt id="espnet2.asr.encoder.rnn_encoder.RNNEncoder.output_size">
<code class="sig-name descname">output_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="../_modules/espnet2/asr/encoder/rnn_encoder.html#RNNEncoder.output_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#espnet2.asr.encoder.rnn_encoder.RNNEncoder.output_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="espnet2-asr-encoder-init-1">
<span id="espnet2-asr-encoder-init"></span><h2>espnet2.asr.encoder.__init__<a class="headerlink" href="#espnet2-asr-encoder-init-1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet2.asr.encoder.__init__"></span></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet2.tts.html" class="btn btn-neutral float-left" title="espnet2.tts package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet2.asr_transducer.html" class="btn btn-neutral float-right" title="espnet2.asr_transducer package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>