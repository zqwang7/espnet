<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>CMU 11492/11692 Spring 2023: Spoken Language Understanding &mdash; ESPnet 202308 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../_static/nbsphinx-code-cells.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="CMU 11492/11692 Spring 2023: Text to Speech" href="TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html" />
    <link rel="prev" title="CMU 11492/11692 Spring 2023: Speech Enhancement" href="SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ESPnet
          </a>
              <div class="version">
                202308
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Common usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../parallelization.html">Using job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet1_tutorial.html">Usage</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html">ESPnet2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_tutorial.html#instruction-for-run-sh">Instruction for run.sh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_format_wav_scp.html">Converting audio file formats using format_wav_scp.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="DataPreparation_CMU_11492_692_Spring2023(Assignment0).html">CMU 11492/11692 Spring 2023: Data preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="DataPreparation_CMU_11492_692_Spring2023(Assignment0).html#Data-preparation-in-ESPnet">Data preparation in ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html">CMU 11492/11692 Spring 2023: Speech Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html#Contents">Contents</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">CMU 11492/11692 Spring 2023: Spoken Language Understanding</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Objectives">Objectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="#❗Important-Notes❗">❗Important Notes❗</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ESPnet-installation">ESPnet installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Spoken-Language-Understanding">Spoken Language Understanding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Overview-of-the-ESPnet-SLU">Overview of the ESPnet-SLU</a></li>
<li class="toctree-l2"><a class="reference internal" href="#1.-E2E-SLU">1. E2E SLU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#1.1-Download-Sample-Audio-File">1.1 Download Sample Audio File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Question1-(✅-Checkpoint-1-(1-points))">Question1 (✅ Checkpoint 1 (1 points))</a></li>
<li class="toctree-l3"><a class="reference internal" href="#1.2-Download-and-Load-pretrained-E2E-SLU-Model">1.2 Download and Load pretrained E2E SLU Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#2.-Two-Pass-E2E-SLU">2. Two Pass E2E SLU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Question2-(✅-Checkpoint-2-(1-points))">Question2 (✅ Checkpoint 2 (1 points))</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#3.-E2E-SLU-for-Slot-Filling">3. E2E SLU for Slot Filling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Question3-(✅-Checkpoint-3-(1-point))">Question3 (✅ Checkpoint 3 (1 point))</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#4.-E2E-SLU-for-Sentiment-Analysis">4. E2E SLU for Sentiment Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Question4-(✅-Checkpoint-4-(1-point))">Question4 (✅ Checkpoint 4 (1 point))</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Question5-(✅-Checkpoint-5-(1-point))">Question5 (✅ Checkpoint 5 (1 point))</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html">CMU 11492/11692 Spring 2023: Text to Speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.asr_transducer.html">espnet2.asr_transducer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.asvspoof.html">espnet2.asvspoof package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.gan_svs.html">espnet2.gan_svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.spk.html">espnet2.spk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_gen/espnet2.diar.html">espnet2.diar package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">CMU 11492/11692 Spring 2023: Spoken Language Understanding</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebook/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="CMU-11492/11692-Spring-2023:-Spoken-Language-Understanding">
<h1>CMU 11492/11692 Spring 2023: Spoken Language Understanding<a class="headerlink" href="#CMU-11492/11692-Spring-2023:-Spoken-Language-Understanding" title="Permalink to this headline">¶</a></h1>
<p>In this demonstration, we will show you the procedure to conduct spoken language understanding in ESPnet.</p>
<p>Main references: - <a class="reference external" href="https://github.com/espnet/espnet">ESPnet repository</a> - <a class="reference external" href="https://espnet.github.io/espnet/">ESPnet documentation</a></p>
<p>Author: - Siddhant Arora (<a class="reference external" href="mailto:siddhana&#37;&#52;&#48;andrew&#46;cmu&#46;edu">siddhana<span>&#64;</span>andrew<span>&#46;</span>cmu<span>&#46;</span>edu</a>)</p>
<section id="Objectives">
<h2>Objectives<a class="headerlink" href="#Objectives" title="Permalink to this headline">¶</a></h2>
<p>After this demonstration, you are expected to understand some latest advancements in spoken language understanding.</p>
</section>
<section id="❗Important-Notes❗">
<h2>❗Important Notes❗<a class="headerlink" href="#❗Important-Notes❗" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>We are using Colab to show the demo. However, Colab has some constraints on the total GPU runtime. If you use too much GPU time, you may not be able to use GPU for some time.</p></li>
<li><p>There are multiple in-class checkpoints ✅ throughout this tutorial. <strong>Your participation points are based on these tasks.</strong> Please try your best to follow all the steps! If you encounter issues, please notify the TAs as soon as possible so that we can make an adjustment for you.</p></li>
<li><p>Please submit PDF files of your completed notebooks to Gradescope. You can print the notebook using <code class="docutils literal notranslate"><span class="pre">File</span> <span class="pre">-&gt;</span> <span class="pre">Print</span></code> in the menu bar.</p></li>
</ul>
</section>
<section id="ESPnet-installation">
<h2>ESPnet installation<a class="headerlink" href="#ESPnet-installation" title="Permalink to this headline">¶</a></h2>
<p>We follow the ESPnet installation as the previous tutorials (takes around 15 minutes).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>! python -m pip install transformers
!git clone https://github.com/espnet/espnet /espnet
!pip install /espnet
%pip install -q espnet_model_zoo
%pip install fairseq@git+https://github.com//pytorch/fairseq.git@f2146bdc7abf293186de9449bfa2272775e39e1d#egg=fairseq
</pre></div>
</div>
</div>
</section>
<section id="Spoken-Language-Understanding">
<h2>Spoken Language Understanding<a class="headerlink" href="#Spoken-Language-Understanding" title="Permalink to this headline">¶</a></h2>
<p>Spoken Language Understanding (SLU) refers to the task of extracting semantic meaning or linguistic structure from spoken utterances. Some examples include recognizing the intent and their associated entities of a user’s command to take appropriate action, or even understanding the emotion behind a particular utterance, and engaging in conversations with a user by modeling the topic of a conversation. SLU is an essential component of many commercial applications like voice assistants, social
bots, and intelligent home devices which have to map speech signals to executable commands every day.</p>
<p>Conventional SLU systems employ a cascaded approach for sequence labeling, where an automatic speech recognition (ASR) system first recognizes the spoken words from the input audio and a natural language understanding (NLU) system then extracts the intent from the predicted text. These cascaded approaches can effectively utilize pretrained ASR and NLU systems. However, they suffer from error propagation as errors in the ASR transcripts can adversely affect downstream SLU performance.
Consequently, in this demo, we focus on end-to-end (E2E) SLU systems. E2E SLU systems aim to predict intent directly from speech. These E2E SLU systems can avoid the cascading of errors but cannot directly utilize strong acoustic and semantic representations from pretrained ASR systems and language models.</p>
<p>In this tutorial, we will show you some latest E2E SLU model architectures (in ESPnet-SLU) in the field of spoken language understanding, including</p>
<ul class="simple">
<li><p>E2E SLU (<a class="reference external" href="https://arxiv.org/abs/2111.14706">https://arxiv.org/abs/2111.14706</a>)</p></li>
<li><p>Two Pass E2E SLU (<a class="reference external" href="https://arxiv.org/abs/2207.06670">https://arxiv.org/abs/2207.06670</a>)</p></li>
</ul>
</section>
<section id="Overview-of-the-ESPnet-SLU">
<h2>Overview of the ESPnet-SLU<a class="headerlink" href="#Overview-of-the-ESPnet-SLU" title="Permalink to this headline">¶</a></h2>
<p>As ASR systems are getting better, there is an increasing interest in using the ASR output directly to do downstream Natural Language Processing (NLP) tasks. With the increase in SLU datasets and methodologies proposed, ESPnet-SLU is an open-source SLU toolkit built on an already existing open-source speech processing toolkit ESPnet. ESPnet-SLU standardize the pipelines involved in building an SLU model like data preparation, model training, and its evaluation. Having ESPnet-SLU would help users
build systems for real world scenarios where many speech processing steps need to be applied before running the downstream task. ESPnet also provides an easy access to other speech technologies being developed like data augmentation, encoder sub-sampling, and speech-focused encoders like conformers. They also support many pretrained ASR and NLU systems that can be used as feature extractors in a SLU framework.</p>
<p>We have shown a sample architecure of our E2E SLU Model in the figure below:</p>
<p><img alt="picture" src="https://drive.google.com/uc?id=1qzWcOV3x5-cj9OHB-iVtCGfY1tQCWk76" /></p>
</section>
<section id="1.-E2E-SLU">
<h2>1. E2E SLU<a class="headerlink" href="#1.-E2E-SLU" title="Permalink to this headline">¶</a></h2>
<section id="1.1-Download-Sample-Audio-File">
<h3>1.1 Download Sample Audio File<a class="headerlink" href="#1.1-Download-Sample-Audio-File" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!gdown --id 18ANT62ittt7Ai2E8bQRlvT0ZVXXsf1eE -O /content/audio_file.wav
import os

import soundfile
from IPython.display import display, Audio
mixwav_mc, sr = soundfile.read(&quot;/content/audio_file.wav&quot;)
display(Audio(mixwav_mc.T, rate=sr))
</pre></div>
</div>
</div>
</section>
<section id="Question1-(✅-Checkpoint-1-(1-points))">
<h3>Question1 (✅ Checkpoint 1 (1 points))<a class="headerlink" href="#Question1-(✅-Checkpoint-1-(1-points))" title="Permalink to this headline">¶</a></h3>
<p>Run inference on given audio using E2E SLU for intent classification</p>
</section>
<section id="1.2-Download-and-Load-pretrained-E2E-SLU-Model">
<h3>1.2 Download and Load pretrained E2E SLU Model<a class="headerlink" href="#1.2-Download-and-Load-pretrained-E2E-SLU-Model" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!git lfs clone https://huggingface.co/espnet/siddhana_slurp_new_asr_train_asr_conformer_raw_en_word_valid.acc.ave_10best /content/slurp_first_pass_model
from espnet2.bin.asr_inference import Speech2Text
speech2text_slurp = Speech2Text.from_pretrained(
    asr_train_config=&quot;/content/slurp_first_pass_model/exp/asr_train_asr_conformer_raw_en_word/config.yaml&quot;,
    asr_model_file=&quot;/content/slurp_first_pass_model/exp/asr_train_asr_conformer_raw_en_word/valid.acc.ave_10best.pth&quot;,
    nbest=1,
)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nbests_orig</span> <span class="o">=</span> <span class="n">speech2text_slurp</span><span class="p">(</span><span class="n">mixwav_mc</span><span class="p">)</span>
<span class="n">text</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">nbests_orig</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">text_normalizer</span><span class="p">(</span><span class="n">sub_word_transcript</span><span class="p">):</span>
    <span class="n">transcript</span> <span class="o">=</span> <span class="n">sub_word_transcript</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;▁&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">sub_word</span> <span class="ow">in</span> <span class="n">sub_word_transcript</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="k">if</span> <span class="s2">&quot;▁&quot;</span> <span class="ow">in</span> <span class="n">sub_word</span><span class="p">:</span>
            <span class="n">transcript</span> <span class="o">=</span> <span class="n">transcript</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">sub_word</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;▁&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transcript</span> <span class="o">=</span> <span class="n">transcript</span> <span class="o">+</span> <span class="n">sub_word</span>
    <span class="k">return</span> <span class="n">transcript</span>
<span class="n">intent_text</span><span class="o">=</span><span class="s2">&quot;{scenario: &quot;</span><span class="o">+</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s2">&quot;, action: &quot;</span><span class="o">+</span><span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span><span class="o">+</span><span class="s2">&quot;}&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INTENT: </span><span class="si">{</span><span class="n">intent_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">transcript</span><span class="o">=</span><span class="n">text_normalizer</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ASR hypothesis: </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;E2E SLU model fails to predict the correct action.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="2.-Two-Pass-E2E-SLU">
<h2>2. Two Pass E2E SLU<a class="headerlink" href="#2.-Two-Pass-E2E-SLU" title="Permalink to this headline">¶</a></h2>
<p>However, recent work has shown that E2E-SLU systems struggle to generalize to unique phrasing for the same intent, suggesting an opportunity for enhancing semantic modeling of existing SLU systems. A number of approaches have been proposed to learn semantic content directly from audio. These approaches aim to incorporate pretrained language models to improve semantic processing of SLU architectures. In this demo, we use the Two Pass E2E SLU model where the second pass model improves on the
initial prediction by combining acoustic information from the entire speech and semantic information from ASR-hypothesis using a deliberation network.</p>
<p><img alt="pitcture" src="https://drive.google.com/uc?id=1imEA98mIqcC6i-Cgdc84msHKliaVgtdf" /></p>
<section id="Question2-(✅-Checkpoint-2-(1-points))">
<h3>Question2 (✅ Checkpoint 2 (1 points))<a class="headerlink" href="#Question2-(✅-Checkpoint-2-(1-points))" title="Permalink to this headline">¶</a></h3>
<p>Run inference on given audio using 2 pass SLU</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!git lfs clone https://huggingface.co/espnet/slurp_slu_2pass /content/slurp_second_pass_model
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">espnet2.bin.slu_inference</span> <span class="kn">import</span> <span class="n">Speech2Understand</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="n">speech2text_second_pass_slurp</span> <span class="o">=</span> <span class="n">Speech2Understand</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">slu_train_config</span><span class="o">=</span><span class="s2">&quot;/content/slurp_second_pass_model/exp/slu_train_asr_bert_conformer_deliberation_raw_en_word/config.yaml&quot;</span><span class="p">,</span>
    <span class="n">slu_model_file</span><span class="o">=</span><span class="s2">&quot;/content/slurp_second_pass_model/exp/slu_train_asr_bert_conformer_deliberation_raw_en_word/valid.acc.ave_10best.pth&quot;</span><span class="p">,</span>
    <span class="n">nbest</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">espnet2.tasks.slu</span> <span class="kn">import</span> <span class="n">SLUTask</span>
<span class="n">preprocess_fn</span><span class="o">=</span><span class="n">SLUTask</span><span class="o">.</span><span class="n">build_preprocess_fn</span><span class="p">(</span>
            <span class="n">speech2text_second_pass_slurp</span><span class="o">.</span><span class="n">asr_train_args</span><span class="p">,</span> <span class="kc">False</span>
        <span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">transcript</span> <span class="o">=</span> <span class="n">preprocess_fn</span><span class="o">.</span><span class="n">text_cleaner</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">preprocess_fn</span><span class="o">.</span><span class="n">transcript_tokenizer</span><span class="o">.</span><span class="n">text2tokens</span><span class="p">(</span><span class="n">transcript</span><span class="p">)</span>
<span class="n">text_ints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">preprocess_fn</span><span class="o">.</span><span class="n">transcript_token_id_converter</span><span class="o">.</span><span class="n">tokens2ids</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">nbests</span> <span class="o">=</span> <span class="n">speech2text_second_pass_slurp</span><span class="p">(</span><span class="n">mixwav_mc</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">text_ints</span><span class="p">))</span>
<span class="n">text1</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">nbests</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">intent_text</span><span class="o">=</span><span class="s2">&quot;{scenario: &quot;</span><span class="o">+</span><span class="n">text1</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s2">&quot;, action: &quot;</span><span class="o">+</span><span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text1</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span><span class="o">+</span><span class="s2">&quot;}&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INTENT: </span><span class="si">{</span><span class="n">intent_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">transcript</span><span class="o">=</span><span class="n">text_normalizer</span><span class="p">(</span><span class="n">text1</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ASR hypothesis: </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Second pass SLU model successfully recognizes the correct action.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="3.-E2E-SLU-for-Slot-Filling">
<h2>3. E2E SLU for Slot Filling<a class="headerlink" href="#3.-E2E-SLU-for-Slot-Filling" title="Permalink to this headline">¶</a></h2>
<section id="Question3-(✅-Checkpoint-3-(1-point))">
<h3>Question3 (✅ Checkpoint 3 (1 point))<a class="headerlink" href="#Question3-(✅-Checkpoint-3-(1-point))" title="Permalink to this headline">¶</a></h3>
<p>Run inference on given audio using E2E SLU for slot filling</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!gdown --id 1ezs8IPutLr-C0PXKb6pfOlb6XXFDXcPd -O /content/audio_slurp_entity_file.wav
import os

import soundfile
from IPython.display import display, Audio
mixwav_mc, sr = soundfile.read(&quot;/content/audio_slurp_entity_file.wav&quot;)
display(Audio(mixwav_mc.T, rate=sr))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!git lfs clone https://huggingface.co/espnet/siddhana_slurp_entity_asr_train_asr_conformer_raw_en_word_valid.acc.ave_10best /content/slurp_entity_model
from espnet2.bin.asr_inference import Speech2Text
speech2text_slurp = Speech2Text.from_pretrained(
    asr_train_config=&quot;/content/slurp_entity_model/exp/asr_train_asr_conformer_raw_en_word/config.yaml&quot;,
    asr_model_file=&quot;/content/slurp_entity_model/exp/asr_train_asr_conformer_raw_en_word/valid.acc.ave_10best.pth&quot;,
    nbest=1,
)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nbests_orig</span> <span class="o">=</span> <span class="n">speech2text_slurp</span><span class="p">(</span><span class="n">mixwav_mc</span><span class="p">)</span>
<span class="n">text</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">nbests_orig</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">entity_text_normalizer</span><span class="p">(</span><span class="n">sub_word_transcript_list</span><span class="p">):</span>
    <span class="n">transcript_dict</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">sub_word_transcript_new</span> <span class="ow">in</span> <span class="n">sub_word_transcript_list</span><span class="p">:</span>
      <span class="n">sub_word_transcript</span><span class="o">=</span><span class="n">sub_word_transcript_new</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
      <span class="c1"># print(sub_word_transcript_list)</span>
      <span class="c1"># print(sub_word_transcript)</span>
      <span class="n">transcript</span> <span class="o">=</span> <span class="n">sub_word_transcript</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;▁&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">sub_word</span> <span class="ow">in</span> <span class="n">sub_word_transcript</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
          <span class="k">if</span> <span class="s2">&quot;▁&quot;</span> <span class="ow">in</span> <span class="n">sub_word</span><span class="p">:</span>
              <span class="n">transcript</span> <span class="o">=</span> <span class="n">transcript</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">sub_word</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;▁&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
              <span class="n">transcript</span> <span class="o">=</span> <span class="n">transcript</span> <span class="o">+</span> <span class="n">sub_word</span>
      <span class="n">transcript_dict</span><span class="p">[</span><span class="n">transcript</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; FILL &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span><span class="o">=</span><span class="n">transcript</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; FILL &quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">transcript_dict</span>
<span class="n">intent_text</span><span class="o">=</span><span class="s2">&quot;{scenario: &quot;</span><span class="o">+</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s2">&quot;, action: &quot;</span><span class="o">+</span><span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span><span class="o">+</span><span class="s2">&quot;}&quot;</span>
<span class="c1"># print(text)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;INTENT: </span><span class="si">{</span><span class="n">intent_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="c1"># print(&quot; &quot;.join(text.split()[1:]).split(&quot;▁SEP&quot;)[-1].split())</span>
<span class="n">transcript</span><span class="o">=</span><span class="n">text_normalizer</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;▁SEP&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ASR hypothesis: </span><span class="si">{</span><span class="n">transcript</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">entity_transcript</span><span class="o">=</span><span class="n">entity_text_normalizer</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;▁SEP&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Slot dictionary: </span><span class="si">{</span><span class="n">entity_transcript</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="4.-E2E-SLU-for-Sentiment-Analysis">
<h2>4. E2E SLU for Sentiment Analysis<a class="headerlink" href="#4.-E2E-SLU-for-Sentiment-Analysis" title="Permalink to this headline">¶</a></h2>
<section id="Question4-(✅-Checkpoint-4-(1-point))">
<h3>Question4 (✅ Checkpoint 4 (1 point))<a class="headerlink" href="#Question4-(✅-Checkpoint-4-(1-point))" title="Permalink to this headline">¶</a></h3>
<p>Run inference on given audio using E2E SLU for sentiment analysis</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!gdown --id 1CZzmpMliwSzja9TdBV7wmidlGepZBEUi -O /content/audio_iemocap_file.wav
import os

import soundfile
from IPython.display import display, Audio
mixwav_mc, sr = soundfile.read(&quot;/content/audio_iemocap_file.wav&quot;)
display(Audio(mixwav_mc.T, rate=sr))
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span>!git lfs clone https://huggingface.co/espnet/YushiUeda_iemocap_sentiment_asr_train_asr_conformer /content/iemocap_model
from espnet2.bin.asr_inference import Speech2Text
speech2text_iemocap = Speech2Text.from_pretrained(
    asr_train_config=&quot;/content/iemocap_model/exp/asr_train_asr_conformer_raw_en_word/config.yaml&quot;,
    asr_model_file=&quot;/content/iemocap_model/exp/asr_train_asr_conformer_raw_en_word/valid.acc.ave_10best.pth&quot;,
    nbest=1,
)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nbests_orig</span> <span class="o">=</span> <span class="n">speech2text_iemocap</span><span class="p">(</span><span class="n">mixwav_mc</span><span class="p">)</span>
<span class="n">text</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">nbests_orig</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sentiment_text</span><span class="o">=</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SENTIMENT: </span><span class="si">{</span><span class="n">sentiment_text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Question5-(✅-Checkpoint-5-(1-point))">
<h3>Question5 (✅ Checkpoint 5 (1 point))<a class="headerlink" href="#Question5-(✅-Checkpoint-5-(1-point))" title="Permalink to this headline">¶</a></h3>
<p>Discuss about potential advantages of integrating pre-trained LMs inside E2E SLU framework compared to using them in cascaded manner?</p>
<p>[ANSWER HERE]</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html" class="btn btn-neutral float-left" title="CMU 11492/11692 Spring 2023: Speech Enhancement" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html" class="btn btn-neutral float-right" title="CMU 11492/11692 Spring 2023: Text to Speech" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>