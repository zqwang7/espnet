<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ESPnet2 &mdash; ESPnet 202308 documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Change the configuration for training" href="espnet2_training_option.html" />
    <link rel="prev" title="Usage" href="espnet1_tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            ESPnet
          </a>
              <div class="version">
                202308
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Common usages</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallelization.html">Using job scheduling system</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="docker.html">Docker</a></li>
</ul>
<p><span class="caption-text">ESPnet1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="espnet1_tutorial.html">Usage</a></li>
</ul>
<p><span class="caption-text">ESPnet2:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">ESPnet2</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#main-changing-from-espnet1">Main changing from ESPnet1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#recipes-using-espnet2">Recipes using ESPnet2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#see-training-status">See training status</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#show-the-log-file">Show the log file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#show-the-training-status-in-a-image-file">Show the training status in a image file</a></li>
<li class="toctree-l3"><a class="reference internal" href="#use-tensorboard">Use tensorboard</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#instruction-for-run-sh">Instruction for run.sh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#how-to-parse-command-line-arguments-in-shell-scripts">How to parse command-line arguments in shell scripts?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#start-from-a-specified-stage-and-stop-at-a-specified-stage">Start from a specified stage and stop at a specified stage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#change-the-configuration-for-training">Change the configuration for training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#change-the-number-of-parallel-jobs">Change the number of parallel jobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#multi-gpus-training-and-distributed-training">Multi GPUs training and distributed training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#relationship-between-mini-batch-size-and-number-of-gpus">Relationship between mini-batch size and number of GPUs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#use-specified-experiment-directory-for-evaluation">Use specified experiment directory for evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#evaluation-without-training-using-pretrained-model">Evaluation without training using pretrained model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#evaluation-using-openai-whisper">Evaluation using OpenAI Whisper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#packing-and-sharing-your-trained-model">Packing and sharing your trained model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage-of-self-supervised-learning-representations-as-feature">Usage of Self-Supervised Learning Representations as feature</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisite">Prerequisite</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage">Usage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#streaming-asr">Streaming ASR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decoding">Decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#faq">FAQ</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#real-time-factor-and-latency">Real-Time-Factor and Latency</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#usage-1">Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#notes">Notes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#transducer-asr">Transducer ASR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#general-usage">General usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#architecture">Architecture</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#encoder">Encoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decoder">Decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="#joint-network">Joint network</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#multi-task-learning">Multi-task learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#inference">Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#streaming">Streaming</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-1">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decoding-1">Decoding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#faq-1">FAQ</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#how-to-add-a-new-block-type-to-the-custom-encoder">How to add a new block type to the custom encoder?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_training_option.html">Change the configuration for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_format_wav_scp.html">Converting audio file formats using format_wav_scp.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_task.html">Task class and data input system for training</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet2_distributed.html">Distributed training</a></li>
</ul>
<p><span class="caption-text">Notebook:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html">CMU 11492/11692 Spring 2023: Data preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/DataPreparation_CMU_11492_692_Spring2023(Assignment0).html#Data-preparation-in-ESPnet">Data preparation in ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html">CMU 11492/11692 Spring 2023: Speech Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/SpeechEnhancement_CMU_11492_692_Spring2023(Assignment7).html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/SpokenLanguageUnderstanding_CMU_11492_692_Spring2023(Assignment6).html">CMU 11492/11692 Spring 2023: Spoken Language Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/TextToSpeech_CMU_11492_692_Spring2023(Assignment8).html">CMU 11492/11692 Spring 2023: Text to Speech</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/asr_cli.html">Speech Recognition (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/asr_library.html">Speech Recognition (Library)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_2pass_slu_demo.html">ESPNET 2 pass SLU Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_asr_realtime_demo.html">ESPnet2-ASR realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_asr_transfer_learning_demo.html"><strong>Use transfer learning for ASR in ESPnet2</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_asr_transfer_learning_demo.html#Abstract">Abstract</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_asr_transfer_learning_demo.html#ESPnet-installation-(about-10-minutes-in-total)">ESPnet installation (about 10 minutes in total)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_asr_transfer_learning_demo.html#mini_an4-recipe-as-a-transfer-learning-example">mini_an4 recipe as a transfer learning example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial2 (New task)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet-(Almost-same-procedure-as-your-first-tutorial)">Install ESPnet (Almost same procedure as your first tutorial)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_new_task_tutorial_CMU_11751_18781_Fall2022.html#What-we-provide-you-and-what-you-need-to-proceed">What we provide you and what you need to proceed</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html">CMU 11751/18781 Fall 2022: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Install-ESPnet">Install ESPnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Run-an-existing-recipe">Run an existing recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Make-a-new-recipe">Make a new recipe</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_recipe_tutorial_CMU_11751_18781_Fall2022.html#Additional-resources">Additional resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_streaming_asr_demo.html">ESPnet2 real streaming Transformer demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_tts_realtime_demo.html">ESPnet2-TTS realtime demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_tutorial_2021_CMU_11751_18781.html">CMU 11751/18781 2021: ESPnet Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-an-inference-example">Run an inference example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Full-installation">Full installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet2_tutorial_2021_CMU_11751_18781.html#Run-a-recipe-example">Run a recipe example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet_se_demonstration_for_waspaa_2021.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet_se_demonstration_for_waspaa_2021.html#Contents">Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet_se_demonstration_for_waspaa_2021.html#(1)-Tutorials-on-the-Basic-Usage">(1) Tutorials on the Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/espnet_se_demonstration_for_waspaa_2021.html#(2)-Tutorials-on-Contributing-to-ESPNet-SE-Project">(2) Tutorials on Contributing to ESPNet-SE Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/onnx_conversion_demo.html">espnet_onnx demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/onnx_conversion_demo.html#Install-Dependency">Install Dependency</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/onnx_conversion_demo.html#Export-your-model">Export your model</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/onnx_conversion_demo.html#Inference-with-onnx">Inference with onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/onnx_conversion_demo.html#Using-streaming-model">Using streaming model</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/pretrained.html">Pretrained Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/se_demo.html">ESPnet Speech Enhancement Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/st_demo.html">ESPnet Speech Translation Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/tts_cli.html">Text-to-Speech (Recipe)</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook/tts_realtime_demo.html">ESPnet real time E2E-TTS demonstration</a></li>
</ul>
<p><span class="caption-text">Package Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.distributed.html">espnet.distributed package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.st.html">espnet.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.bin.html">espnet.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.optimizer.html">espnet.optimizer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.nets.html">espnet.nets package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.scheduler.html">espnet.scheduler package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.vc.html">espnet.vc package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.mt.html">espnet.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.lm.html">espnet.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet.utils.html">espnet.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.svs.html">espnet2.svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.tts.html">espnet2.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.asr.html">espnet2.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.asr_transducer.html">espnet2.asr_transducer package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.st.html">espnet2.st package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.bin.html">espnet2.bin package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.asvspoof.html">espnet2.asvspoof package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.schedulers.html">espnet2.schedulers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.gan_svs.html">espnet2.gan_svs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.fileio.html">espnet2.fileio package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.slu.html">espnet2.slu package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.hubert.html">espnet2.hubert package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.gan_tts.html">espnet2.gan_tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.optimizers.html">espnet2.optimizers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.uasr.html">espnet2.uasr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.spk.html">espnet2.spk package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.enh.html">espnet2.enh package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.train.html">espnet2.train package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.main_funcs.html">espnet2.main_funcs package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.samplers.html">espnet2.samplers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.mt.html">espnet2.mt package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.fst.html">espnet2.fst package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.lm.html">espnet2.lm package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.layers.html">espnet2.layers package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.utils.html">espnet2.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.tasks.html">espnet2.tasks package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.iterators.html">espnet2.iterators package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.text.html">espnet2.text package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.torch_utils.html">espnet2.torch_utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="_gen/espnet2.diar.html">espnet2.diar package</a></li>
</ul>
<p><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="apis/espnet2_bin.html">core tools (espnet2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="apis/utils_sh.html">bash utility tools</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ESPnet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ESPnet2</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/espnet2_tutorial.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="espnet2">
<h1>ESPnet2<a class="headerlink" href="#espnet2" title="Permalink to this headline">¶</a></h1>
<p>We are planning a super major update, called <code class="docutils literal notranslate"><span class="pre">ESPnet2</span></code>. The developing status is still <strong>under construction</strong> yet, so please be very careful to use with understanding following cautions:</p>
<ul class="simple">
<li><p>There might be fatal bugs related to essential parts.</p></li>
<li><p>We haven’t achieved comparable results to espnet1 on each task yet.</p></li>
</ul>
<section id="main-changing-from-espnet1">
<h2>Main changing from ESPnet1<a class="headerlink" href="#main-changing-from-espnet1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><strong>Chainer free</strong></p>
<ul>
<li><p>Discarding Chainer completely.</p></li>
<li><p>The development of Chainer is stopped at v7: https://chainer.org/announcement/2019/12/05/released-v7.html</p></li>
</ul>
</li>
<li><p><strong>Kaldi free</strong></p>
<ul>
<li><p>It’s not mandatory to compile Kaldi.</p></li>
<li><p><strong>If you find some recipes requiring Kaldi mandatory, please report it. It should be dealt with as a bug in ESPnet2.</strong></p></li>
<li><p>We still support the features made by Kaldi optionally.</p></li>
<li><p>We still follow Kaldi style. i.e. depending on <code class="docutils literal notranslate"><span class="pre">utils/</span></code> of Kaldi.</p></li>
</ul>
</li>
<li><p><strong>On the fly</strong> feature extraction &amp; text preprocessing for training</p>
<ul>
<li><p>You don’t need to create the feature file before training, but just input wave data directly.</p></li>
<li><p>We support both raw wave input and extracted features.</p></li>
<li><p>The preprocessing for text, tokenization to characters, or sentencepieces, can be also applied during training.</p></li>
<li><p>Support <strong>self-supervised learning representations</strong> from s3prl</p></li>
</ul>
</li>
<li><p>Discarding the JSON format describing the training corpus.</p>
<ul>
<li><p>Why do we discard the JSON format? Because a dict object generated from a large JSON file requires much memory and it also takes much time to parse such a large JSON file.</p></li>
</ul>
</li>
<li><p>Support distributed data-parallel training (Not enough tested)</p>
<ul>
<li><p>Single node multi GPU training with <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> is also supported.</p></li>
</ul>
</li>
</ul>
</section>
<section id="recipes-using-espnet2">
<h2>Recipes using ESPnet2<a class="headerlink" href="#recipes-using-espnet2" title="Permalink to this headline">¶</a></h2>
<p>You can find the new recipes in <code class="docutils literal notranslate"><span class="pre">egs2</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">espnet</span><span class="o">/</span>  <span class="c1"># Python modules of espnet1</span>
<span class="n">espnet2</span><span class="o">/</span> <span class="c1"># Python modules of espnet2</span>
<span class="n">egs</span><span class="o">/</span>     <span class="c1"># espnet1 recipes</span>
<span class="n">egs2</span><span class="o">/</span>    <span class="c1"># espnet2 recipes</span>
</pre></div>
</div>
<p>The usage of recipes is <strong>almost the same</strong> as that of ESPnet1.</p>
<ol>
<li><p>Change directory to the base directory</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># e.g.</span>
<span class="nb">cd</span><span class="w"> </span>egs2/an4/asr1/
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">an4</span></code> is a tiny corpus and can be freely obtained, so it might be suitable for this tutorial.
You can perform any other recipes as the same way. e.g. <code class="docutils literal notranslate"><span class="pre">wsj</span></code>, <code class="docutils literal notranslate"><span class="pre">librispeech</span></code>, and etc.</p>
<p>Keep in mind that all scripts should be ran at the level of <code class="docutils literal notranslate"><span class="pre">egs2/*/{asr1,tts1,...}</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Doesn&#39;t work</span>
<span class="nb">cd</span><span class="w"> </span>egs2/an4/
./asr1/run.sh
./asr1/scripts/&lt;some-script&gt;.sh

<span class="c1"># Doesn&#39;t work</span>
<span class="nb">cd</span><span class="w"> </span>egs2/an4/asr1/local/
./data.sh

<span class="c1"># Work</span>
<span class="nb">cd</span><span class="w"> </span>egs2/an4/asr1
./run.sh
./scripts/&lt;some-script&gt;.sh
</pre></div>
</div>
</li>
<li><p>Change the configuration
Describing the directory structure as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">egs2</span><span class="o">/</span><span class="n">an4</span><span class="o">/</span><span class="n">asr1</span><span class="o">/</span>
 <span class="o">-</span> <span class="n">conf</span><span class="o">/</span>      <span class="c1"># Configuration files for training, inference, etc.</span>
 <span class="o">-</span> <span class="n">scripts</span><span class="o">/</span>   <span class="c1"># Bash utilities of espnet2</span>
 <span class="o">-</span> <span class="n">pyscripts</span><span class="o">/</span> <span class="c1"># Python utilities of espnet2</span>
 <span class="o">-</span> <span class="n">steps</span><span class="o">/</span>     <span class="c1"># From Kaldi utilities</span>
 <span class="o">-</span> <span class="n">utils</span><span class="o">/</span>     <span class="c1"># From Kaldi utilities</span>
 <span class="o">-</span> <span class="n">db</span><span class="o">.</span><span class="n">sh</span>      <span class="c1"># The directory path of each corpora</span>
 <span class="o">-</span> <span class="n">path</span><span class="o">.</span><span class="n">sh</span>    <span class="c1"># Setup script for environment variables</span>
 <span class="o">-</span> <span class="n">cmd</span><span class="o">.</span><span class="n">sh</span>     <span class="c1"># Configuration for your backend of job scheduler</span>
 <span class="o">-</span> <span class="n">run</span><span class="o">.</span><span class="n">sh</span>     <span class="c1"># Entry point</span>
 <span class="o">-</span> <span class="n">asr</span><span class="o">.</span><span class="n">sh</span>     <span class="c1"># Invoked by run.sh</span>
</pre></div>
</div>
<ul>
<li><p>You need to modify <code class="docutils literal notranslate"><span class="pre">db.sh</span></code> for specifying your corpus before executing <code class="docutils literal notranslate"><span class="pre">run.sh</span></code>. For example, when you touch the recipe of <code class="docutils literal notranslate"><span class="pre">egs2/wsj</span></code>, you need to change the paths of <code class="docutils literal notranslate"><span class="pre">WSJ0</span></code> and <code class="docutils literal notranslate"><span class="pre">WSJ1</span></code> in <code class="docutils literal notranslate"><span class="pre">db.sh</span></code>.</p></li>
<li><p>Some corpora can be freely obtained from the WEB and they are written as “downloads/” at the initial state. You can also change them to your corpus path if it’s already downloaded.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">path.sh</span></code> is used to set up the environment for <code class="docutils literal notranslate"><span class="pre">run.sh</span></code>. Note that the Python interpreter used for ESPnet is not the current Python of your terminal, but it’s the Python which was installed at <code class="docutils literal notranslate"><span class="pre">tools/</span></code>. Thus you need to source <code class="docutils literal notranslate"><span class="pre">path.sh</span></code> to use this Python.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>.<span class="w"> </span>path.sh
python
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cmd.sh</span></code> is used for specifying the backend of the job scheduler. If you don’t have such a system in your local machine environment, you don’t need to change anything about this file. See <a class="reference internal" href="parallelization.html"><span class="doc">Using Job scheduling system</span></a></p></li>
</ul>
</li>
<li><p>Run <code class="docutils literal notranslate"><span class="pre">run.sh</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./run.sh
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">run.sh</span></code> is an example script, which we often call as “recipe”, to run all stages related to DNN experiments; data-preparation, training, and evaluation.</p>
</li>
</ol>
</section>
<section id="see-training-status">
<h2>See training status<a class="headerlink" href="#see-training-status" title="Permalink to this headline">¶</a></h2>
<section id="show-the-log-file">
<h3>Show the log file<a class="headerlink" href="#show-the-log-file" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%<span class="w"> </span>tail<span class="w"> </span>-f<span class="w"> </span>exp/*_train_*/train.log
<span class="o">[</span>host<span class="o">]</span><span class="w"> </span><span class="m">2020</span>-04-05<span class="w"> </span><span class="m">16</span>:34:54,278<span class="w"> </span><span class="o">(</span>trainer:192<span class="o">)</span><span class="w"> </span>INFO:<span class="w"> </span><span class="m">2</span>/40epoch<span class="w"> </span>started.<span class="w"> </span>Estimated<span class="w"> </span><span class="nb">time</span><span class="w"> </span>to<span class="w"> </span>finish:<span class="w"> </span><span class="m">7</span><span class="w"> </span>minutes<span class="w"> </span>and<span class="w"> </span><span class="m">58</span>.63<span class="w"> </span>seconds
<span class="o">[</span>host<span class="o">]</span><span class="w"> </span><span class="m">2020</span>-04-05<span class="w"> </span><span class="m">16</span>:34:56,315<span class="w"> </span><span class="o">(</span>trainer:453<span class="o">)</span><span class="w"> </span>INFO:<span class="w"> </span>2epoch:train:1-10batch:<span class="w"> </span><span class="nv">iter_time</span><span class="o">=</span><span class="m">0</span>.006,<span class="w"> </span><span class="nv">forward_time</span><span class="o">=</span><span class="m">0</span>.076,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="m">50</span>.873,<span class="w"> </span>los
<span class="nv">s_att</span><span class="o">=</span><span class="m">35</span>.801,<span class="w"> </span><span class="nv">loss_ctc</span><span class="o">=</span><span class="m">65</span>.945,<span class="w"> </span><span class="nv">acc</span><span class="o">=</span><span class="m">0</span>.471,<span class="w"> </span><span class="nv">backward_time</span><span class="o">=</span><span class="m">0</span>.072,<span class="w"> </span><span class="nv">optim_step_time</span><span class="o">=</span><span class="m">0</span>.006,<span class="w"> </span><span class="nv">lr_0</span><span class="o">=</span><span class="m">1</span>.000,<span class="w"> </span><span class="nv">train_time</span><span class="o">=</span><span class="m">0</span>.203
<span class="o">[</span>host<span class="o">]</span><span class="w"> </span><span class="m">2020</span>-04-05<span class="w"> </span><span class="m">16</span>:34:58,046<span class="w"> </span><span class="o">(</span>trainer:453<span class="o">)</span><span class="w"> </span>INFO:<span class="w"> </span>2epoch:train:11-20batch:<span class="w"> </span><span class="nv">iter_time</span><span class="o">=</span><span class="m">4</span>.280e-05,<span class="w"> </span><span class="nv">forward_time</span><span class="o">=</span><span class="m">0</span>.068,<span class="w"> </span><span class="nv">loss</span><span class="o">=</span><span class="m">44</span>.369
,<span class="w"> </span><span class="nv">loss_att</span><span class="o">=</span><span class="m">28</span>.776,<span class="w"> </span><span class="nv">loss_ctc</span><span class="o">=</span><span class="m">59</span>.962,<span class="w"> </span><span class="nv">acc</span><span class="o">=</span><span class="m">0</span>.506,<span class="w"> </span><span class="nv">backward_time</span><span class="o">=</span><span class="m">0</span>.055,<span class="w"> </span><span class="nv">optim_step_time</span><span class="o">=</span><span class="m">0</span>.006,<span class="w"> </span><span class="nv">lr_0</span><span class="o">=</span><span class="m">1</span>.000,<span class="w"> </span><span class="nv">train_time</span><span class="o">=</span><span class="m">0</span>.173
</pre></div>
</div>
</section>
<section id="show-the-training-status-in-a-image-file">
<h3>Show the training status in a image file<a class="headerlink" href="#show-the-training-status-in-a-image-file" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Accuracy plot</span>
<span class="c1"># (eog is Eye of GNOME Image Viewer)</span>
eog<span class="w"> </span>exp/*_train_*/images/acc.img
<span class="c1"># Attention plot</span>
eog<span class="w"> </span>exp/*_train_*/att_ws/&lt;sample-id&gt;/&lt;param-name&gt;.img
</pre></div>
</div>
</section>
<section id="use-tensorboard">
<h3>Use tensorboard<a class="headerlink" href="#use-tensorboard" title="Permalink to this headline">¶</a></h3>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>tensorboard<span class="w"> </span>--logdir<span class="w"> </span>exp/*_train_*/tensorboard/
</pre></div>
</div>
</section>
</section>
</section>
<section id="instruction-for-run-sh">
<h1>Instruction for run.sh<a class="headerlink" href="#instruction-for-run-sh" title="Permalink to this headline">¶</a></h1>
<section id="how-to-parse-command-line-arguments-in-shell-scripts">
<h2>How to parse command-line arguments in shell scripts?<a class="headerlink" href="#how-to-parse-command-line-arguments-in-shell-scripts" title="Permalink to this headline">¶</a></h2>
<p>All shell scripts in espnet/espnet2 depend on <a class="reference external" href="https://github.com/kaldi-asr/kaldi/blob/master/egs/wsj/s5/utils/parse_options.sh">utils/parse_options.sh</a> to parase command line arguments.</p>
<p>e.g. If the script has <code class="docutils literal notranslate"><span class="pre">ngpu</span></code> option</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>
<span class="c1"># run.sh</span>
<span class="nv">ngpu</span><span class="o">=</span><span class="m">1</span>
.<span class="w"> </span>utils/parse_options.sh
<span class="nb">echo</span><span class="w"> </span><span class="si">${</span><span class="nv">ngpu</span><span class="si">}</span>
</pre></div>
</div>
<p>Then you can change the value as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./run.sh<span class="w"> </span>--ngpu<span class="w"> </span><span class="m">2</span>
<span class="nb">echo</span><span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<p>You can also show the help message:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--help
</pre></div>
</div>
</section>
<section id="start-from-a-specified-stage-and-stop-at-a-specified-stage">
<h2>Start from a specified stage and stop at a specified stage<a class="headerlink" href="#start-from-a-specified-stage-and-stop-at-a-specified-stage" title="Permalink to this headline">¶</a></h2>
<p>The procedures in <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> can be divided into some stages, e.g. data preparation, training, and evaluation. You can specify the starting stage and the stopping stage.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">2</span><span class="w"> </span>--stop-stage<span class="w"> </span><span class="m">6</span>
</pre></div>
</div>
<p>There are also some altenative otpions to skip specified stages:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>run.sh<span class="w"> </span>--skip_data_prep<span class="w"> </span><span class="nb">true</span><span class="w">  </span><span class="c1"># Skip data preparation stages.</span>
run.sh<span class="w"> </span>--skip_train<span class="w"> </span><span class="nb">true</span><span class="w">      </span><span class="c1"># Skip training stages.</span>
run.sh<span class="w"> </span>--skip_eval<span class="w"> </span><span class="nb">true</span><span class="w">       </span><span class="c1"># Skip decoding and evaluation stages.</span>
run.sh<span class="w"> </span>--skip_upload<span class="w"> </span><span class="nb">false</span><span class="w">    </span><span class="c1"># Enable packing and uploading stages.</span>
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">skip_upload</span></code> is true by default. Please change it to false when uploading your model.</p>
</section>
<section id="change-the-configuration-for-training">
<h2>Change the configuration for training<a class="headerlink" href="#change-the-configuration-for-training" title="Permalink to this headline">¶</a></h2>
<p>Please keep in mind that <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> is a wrapper script of several tools including DNN training command.
You need to do one of the following two ways to change the training configuration.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># Give a configuration file</span>
./run.sh<span class="w"> </span>--asr_config<span class="w"> </span>conf/train_asr.yaml
<span class="c1"># Give arguments to &quot;espnet2/bin/asr_train.py&quot; directly</span>
./run.sh<span class="w"> </span>--asr_args<span class="w"> </span><span class="s2">&quot;--foo arg --bar arg2&quot;</span>
</pre></div>
</div>
<p>e.g. To change learning rate for the LM training</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--lm_args<span class="w"> </span><span class="s2">&quot;--optim_conf lr=0.1&quot;</span>
</pre></div>
</div>
<p>This is the case of ASR training and you need to replace it accordingly for the other task. e.g. For TTS</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--tts_args<span class="w"> </span><span class="s2">&quot;--optim_conf lr=0.1&quot;</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="espnet2_training_option.html"><span class="doc">Change the configuration for training</span></a> for more detail about the usage of training tools.</p>
</section>
<section id="change-the-number-of-parallel-jobs">
<h2>Change the number of parallel jobs<a class="headerlink" href="#change-the-number-of-parallel-jobs" title="Permalink to this headline">¶</a></h2>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--nj<span class="w"> </span><span class="m">10</span><span class="w">             </span><span class="c1"># Chnage the number of parallels for data preparation stages.</span>
./run.sh<span class="w"> </span>--inference_nj<span class="w"> </span><span class="m">10</span><span class="w">   </span><span class="c1"># Chnage the number of parallels for inference jobs.</span>
</pre></div>
</div>
<p>We also support submitting jobs to multiple hosts to accelerate your experiment: See <a class="reference internal" href="parallelization.html"><span class="doc">Using Job scheduling system</span></a></p>
</section>
<section id="multi-gpus-training-and-distributed-training">
<h2>Multi GPUs training and distributed training<a class="headerlink" href="#multi-gpus-training-and-distributed-training" title="Permalink to this headline">¶</a></h2>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--ngpu<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="c1"># 4GPUs in a single node</span>
./run.sh<span class="w"> </span>--ngpu<span class="w"> </span><span class="m">2</span><span class="w"> </span>--num_nodes<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="c1"># 2GPUs x 2nodes</span>
</pre></div>
</div>
<p>Note that you need to setup your environment correctly to use distributed training. See the following two:</p>
<ul class="simple">
<li><p><a class="reference internal" href="espnet2_distributed.html"><span class="doc">Distributed training</span></a></p></li>
<li><p><a class="reference internal" href="parallelization.html"><span class="doc">Using Job scheduling system</span></a></p></li>
</ul>
<section id="relationship-between-mini-batch-size-and-number-of-gpus">
<h3>Relationship between mini-batch size and number of GPUs<a class="headerlink" href="#relationship-between-mini-batch-size-and-number-of-gpus" title="Permalink to this headline">¶</a></h3>
<p>The behavior of batch size in ESPnet2 during multi-GPU training is different from that in ESPnet1. <strong>In ESPnet2, the total batch size is not changed regardless of the number of GPUs.</strong> Therefore, you need to manually increase the batch size if you increase the number of GPUs. Please refer to this <a class="reference external" href="https://espnet.github.io/espnet/espnet2_training_option.html#the-relation-between-mini-batch-size-and-number-of-gpus">doc</a> for more information.</p>
</section>
</section>
<section id="use-specified-experiment-directory-for-evaluation">
<h2>Use specified experiment directory for evaluation<a class="headerlink" href="#use-specified-experiment-directory-for-evaluation" title="Permalink to this headline">¶</a></h2>
<p>If you already have trained a model, you may wonder how to give it to run.sh when you’ll evaluate it later.
By default the directory name is determined according to given options, <code class="docutils literal notranslate"><span class="pre">asr_args</span></code>, <code class="docutils literal notranslate"><span class="pre">lm_args</span></code>, or etc.
You can overwrite it by <code class="docutils literal notranslate"><span class="pre">--asr_exp</span></code> and <code class="docutils literal notranslate"><span class="pre">--lm_exp</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># For ASR recipe</span>
./run.sh<span class="w"> </span>--skip_data_prep<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--skip_train<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--asr_exp<span class="w"> </span>&lt;your_asr_exp_directory&gt;<span class="w"> </span>--lm_exp<span class="w"> </span>&lt;your_lm_exp_directory&gt;

<span class="c1"># For TTS recipe</span>
./run.sh<span class="w"> </span>--skip_data_prep<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--skip_train<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--tts_exp<span class="w"> </span>&lt;your_tts_exp_directory&gt;
</pre></div>
</div>
</section>
<section id="evaluation-without-training-using-pretrained-model">
<h2>Evaluation without training using pretrained model<a class="headerlink" href="#evaluation-without-training-using-pretrained-model" title="Permalink to this headline">¶</a></h2>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--download_model<span class="w"> </span>&lt;model_name&gt;<span class="w"> </span>--skip_train<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>You need to fill <code class="docutils literal notranslate"><span class="pre">model_name</span></code> by yourself. You can search for pretrained models on Hugging Face using the tag <a class="reference external" href="https://huggingface.co/models?library=espnet">espnet</a></p>
<p>(Deprecated: See the following link about our pretrain models: https://github.com/espnet/espnet_model_zoo)</p>
<section id="evaluation-using-openai-whisper">
<h3>Evaluation using OpenAI Whisper<a class="headerlink" href="#evaluation-using-openai-whisper" title="Permalink to this headline">¶</a></h3>
<p>ESPnet2 provides a <a class="reference external" href="../egs2/TEMPLATE/asr1/scripts/utils/evaluate_asr.sh">script</a> to run inference and scoring using OpenAI’s Whisper. This can be used to evaluate speech generation models. Here is an example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>
<span class="c1"># Set bash to &#39;debug&#39; mode, it will exit on :</span>
<span class="c1"># -e &#39;error&#39;, -u &#39;undefined variable&#39;, -o ... &#39;error in pipeline&#39;, -x &#39;print commands&#39;,</span>
<span class="nb">set</span><span class="w"> </span>-e
<span class="nb">set</span><span class="w"> </span>-u
<span class="nb">set</span><span class="w"> </span>-o<span class="w"> </span>pipefail

<span class="nv">whisper_tag</span><span class="o">=</span>medium<span class="w">    </span><span class="c1"># whisper model tag, e.g., small, medium, large, etc</span>
<span class="nv">cleaner</span><span class="o">=</span>whisper_en
<span class="nv">hyp_cleaner</span><span class="o">=</span>whisper_en
<span class="nv">nj</span><span class="o">=</span><span class="m">1</span>
<span class="nv">test_sets</span><span class="o">=</span><span class="s2">&quot;test/WSJ/test_eval92&quot;</span>
<span class="c1"># decode_options is used in Whisper model&#39;s transcribe method</span>
<span class="nv">decode_options</span><span class="o">=</span><span class="s2">&quot;{language: en, task: transcribe, temperature: 0, beam_size: 10, fp16: False}&quot;</span>

<span class="k">for</span><span class="w"> </span>x<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="si">${</span><span class="nv">test_sets</span><span class="si">}</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span><span class="nv">wavscp</span><span class="o">=</span>dump/raw/<span class="si">${</span><span class="nv">x</span><span class="si">}</span>/wav.scp<span class="w">    </span><span class="c1"># path to wav.scp</span>
<span class="w">    </span><span class="nv">outdir</span><span class="o">=</span>whisper-<span class="si">${</span><span class="nv">whisper_tag</span><span class="si">}</span>_outputs/<span class="si">${</span><span class="nv">x</span><span class="si">}</span><span class="w">  </span><span class="c1"># path to save output</span>
<span class="w">    </span><span class="nv">gt_text</span><span class="o">=</span>dump/raw/<span class="si">${</span><span class="nv">x</span><span class="si">}</span>/text<span class="w">      </span><span class="c1"># path to groundtruth text file (for scoring only)</span>

<span class="w">    </span>scripts/utils/evaluate_asr.sh<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--whisper_tag<span class="w"> </span><span class="si">${</span><span class="nv">whisper_tag</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--nj<span class="w"> </span><span class="si">${</span><span class="nv">nj</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--gpu_inference<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--stage<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--stop_stage<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--cleaner<span class="w"> </span><span class="si">${</span><span class="nv">cleaner</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--hyp_cleaner<span class="w"> </span><span class="si">${</span><span class="nv">hyp_cleaner</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--decode_options<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">decode_options</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--gt_text<span class="w"> </span><span class="si">${</span><span class="nv">gt_text</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span><span class="si">${</span><span class="nv">wavscp</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span><span class="si">${</span><span class="nv">outdir</span><span class="si">}</span>
<span class="k">done</span>
</pre></div>
</div>
</section>
</section>
<section id="packing-and-sharing-your-trained-model">
<h2>Packing and sharing your trained model<a class="headerlink" href="#packing-and-sharing-your-trained-model" title="Permalink to this headline">¶</a></h2>
<p>ESPnet encourages you to share your results using platforms like <a class="reference external" href="https://huggingface.co/">Hugging Face</a> or <a class="reference external" href="https://zenodo.org/">Zenodo</a> (This last will become deprecated.)</p>
<p>For sharing your models, the last three stages of each task simplify this process. The model is packed into a zip file and uploaded to the selected platform (one or both).</p>
<p>For <strong>Hugging Face</strong>, you need to first create a repository (<code class="docutils literal notranslate"><span class="pre">&lt;my_repo&gt;</span> <span class="pre">=</span> <span class="pre">&lt;user_name&gt;/&lt;repo_name&gt;</span></code>).
Remember to install <code class="docutils literal notranslate"><span class="pre">git-lfs</span></code> before continuing.
Then, execute <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># For ASR recipe</span>
./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">14</span><span class="w"> </span>--skip-upload-hf<span class="w"> </span><span class="nb">false</span><span class="w"> </span>--hf-repo<span class="w"> </span>&lt;my_repo&gt;

<span class="c1"># For TTS recipe</span>
./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">8</span><span class="w"> </span>--skip-upload-hf<span class="w"> </span><span class="nb">false</span><span class="w"> </span>--hf-repo<span class="w"> </span>&lt;my_repo&gt;
</pre></div>
</div>
<p>For <strong>Zenodo</strong>, you need to register your account first. Then, execute <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># For ASR recipe</span>
./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">14</span><span class="w"> </span>--skip-upload<span class="w"> </span><span class="nb">false</span>

<span class="c1"># For TTS recipe</span>
./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">8</span><span class="w"> </span>--skip-upload<span class="w"> </span><span class="nb">false</span>
</pre></div>
</div>
<p>The packed model can be uploaded to both platforms by setting the previously mentioned flags.</p>
</section>
<section id="usage-of-self-supervised-learning-representations-as-feature">
<h2>Usage of Self-Supervised Learning Representations as feature<a class="headerlink" href="#usage-of-self-supervised-learning-representations-as-feature" title="Permalink to this headline">¶</a></h2>
<p>ESPnet supports self-supervised learning representations (SSLR) to replace traditional spectrum features. In some cases, SSLRs can boost the performance.</p>
<p>To use SSLRs in your task, you need to make several modifications.</p>
<section id="prerequisite">
<h3>Prerequisite<a class="headerlink" href="#prerequisite" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Install <a class="reference external" href="https://github.com/s3prl/s3prl">S3PRL</a> by <code class="docutils literal notranslate"><span class="pre">tools/installers/install_s3prl.sh</span></code>.</p></li>
<li><p>If HuBERT / Wav2Vec is needed, <a class="reference external" href="https://github.com/pytorch/fairseq">fairseq</a> should be installed by <code class="docutils literal notranslate"><span class="pre">tools/installers/install_fairseq.sh</span></code>.</p></li>
</ol>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>To reduce the time used in <code class="docutils literal notranslate"><span class="pre">collect_stats</span></code> step, please specify <code class="docutils literal notranslate"><span class="pre">--feats_normalize</span> <span class="pre">uttmvn</span></code> in <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> and pass it as arguments to <code class="docutils literal notranslate"><span class="pre">asr.sh</span></code> or other task-specific scripts. (Recommended)</p></li>
<li><p>In the configuration file, specify the <code class="docutils literal notranslate"><span class="pre">frontend</span></code> and <code class="docutils literal notranslate"><span class="pre">preencoder</span></code>. Taking <code class="docutils literal notranslate"><span class="pre">HuBERT</span></code> as an example:
The <code class="docutils literal notranslate"><span class="pre">upstream</span></code> name can be whatever supported in S3PRL. <code class="docutils literal notranslate"><span class="pre">multilayer-feature=True</span></code> means the final representation is a weighted-sum of all layers’ hidden states from SSLR model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">frontend</span><span class="p">:</span> <span class="n">s3prl</span>
<span class="n">frontend_conf</span><span class="p">:</span>
   <span class="n">frontend_conf</span><span class="p">:</span>
      <span class="n">upstream</span><span class="p">:</span> <span class="n">hubert_large_ll60k</span>  <span class="c1"># Note: If the upstream is changed, please change the input_size in the preencoder.</span>
   <span class="n">download_dir</span><span class="p">:</span> <span class="o">./</span><span class="n">hub</span>
   <span class="n">multilayer_feature</span><span class="p">:</span> <span class="kc">True</span>
</pre></div>
</div>
<p>Here the <code class="docutils literal notranslate"><span class="pre">preencoder</span></code> is to reduce the input dimension to the encoder, to reduce the memory cost. The <code class="docutils literal notranslate"><span class="pre">input_size</span></code> depends on the upstream model, while the <code class="docutils literal notranslate"><span class="pre">output_size</span></code> can be set to any values.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">preencoder</span><span class="p">:</span> <span class="n">linear</span>
<span class="n">preencoder_conf</span><span class="p">:</span>
   <span class="n">input_size</span><span class="p">:</span> <span class="mi">1024</span>  <span class="c1"># Note: If the upstream is changed, please change this value accordingly.</span>
   <span class="n">output_size</span><span class="p">:</span> <span class="mi">80</span>
</pre></div>
</div>
</li>
<li><p>Because the shift sizes of different <code class="docutils literal notranslate"><span class="pre">upstream</span></code> models are different, e.g. <code class="docutils literal notranslate"><span class="pre">HuBERT</span></code> and <code class="docutils literal notranslate"><span class="pre">Wav2Vec2.0</span></code> have <code class="docutils literal notranslate"><span class="pre">20ms</span></code> frameshift. Sometimes, the downsampling rate (<code class="docutils literal notranslate"><span class="pre">input_layer</span></code>) in the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> configuration need to be changed. For example, using <code class="docutils literal notranslate"><span class="pre">input_layer:</span> <span class="pre">conv2d2</span></code> will results in a total frameshift of <code class="docutils literal notranslate"><span class="pre">40ms</span></code>, which is enough for some tasks.</p></li>
</ol>
</section>
</section>
<section id="streaming-asr">
<h2>Streaming ASR<a class="headerlink" href="#streaming-asr" title="Permalink to this headline">¶</a></h2>
<p>ESPnet supports streaming Transformer/Conformer ASR with blockwise synchronous beam search.</p>
<p>For more details, please refer to the <a class="reference external" href="https://arxiv.org/pdf/2006.14941.pdf">paper</a>.</p>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>To achieve streaming ASR, please employ blockwise Transformer/Conformer encoder in the configuration file. Taking <code class="docutils literal notranslate"><span class="pre">blockwise</span> <span class="pre">Transformer</span></code> as an example:
The <code class="docutils literal notranslate"><span class="pre">encoder</span></code> name can be <code class="docutils literal notranslate"><span class="pre">contextual_block_transformer</span></code> or <code class="docutils literal notranslate"><span class="pre">contextual_block_conformer</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>encoder:<span class="w"> </span>contextual_block_transformer
encoder_conf:
<span class="w">    </span>block_size:<span class="w"> </span><span class="m">40</span><span class="w">         </span><span class="c1"># block size for block processing</span>
<span class="w">    </span>hop_size:<span class="w"> </span><span class="m">16</span><span class="w">           </span><span class="c1"># hop size for block processing</span>
<span class="w">    </span>look_ahead:<span class="w"> </span><span class="m">16</span><span class="w">         </span><span class="c1"># look-ahead size for block processing</span>
<span class="w">    </span>init_average:<span class="w"> </span><span class="nb">true</span><span class="w">     </span><span class="c1"># whether to use average input as initial context</span>
<span class="w">    </span>ctx_pos_enc:<span class="w"> </span><span class="nb">true</span><span class="w">      </span><span class="c1"># whether to use positional encoding for the context vectors</span>
</pre></div>
</div>
</section>
<section id="decoding">
<h3>Decoding<a class="headerlink" href="#decoding" title="Permalink to this headline">¶</a></h3>
<p>To enable online decoding, the argument <code class="docutils literal notranslate"><span class="pre">--use_streaming</span> <span class="pre">true</span></code> should be added to <code class="docutils literal notranslate"><span class="pre">run.sh</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">12</span><span class="w"> </span>--use_streaming<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
</section>
<section id="faq">
<h3>FAQ<a class="headerlink" href="#faq" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Issue about <code class="docutils literal notranslate"><span class="pre">'NoneType'</span> <span class="pre">object</span> <span class="pre">has</span> <span class="pre">no</span> <span class="pre">attribute</span> <span class="pre">'max'</span></code> during training: Please make sure you employ <code class="docutils literal notranslate"><span class="pre">forward_train</span></code> function during traininig, check more details <a class="reference external" href="https://github.com/espnet/espnet/issues/3803">here</a>.</p></li>
<li><p>I successfully trained the model, but encountered the above issue during decoding: You may forget to specify <code class="docutils literal notranslate"><span class="pre">--use_streaming</span> <span class="pre">true</span></code> to select streaming inference.</p></li>
</ol>
</section>
</section>
<section id="real-time-factor-and-latency">
<h2>Real-Time-Factor and Latency<a class="headerlink" href="#real-time-factor-and-latency" title="Permalink to this headline">¶</a></h2>
<p>In order to calculate real-time-factor and (non-streaming) latency the script <code class="docutils literal notranslate"><span class="pre">utils/calculate_rtf.py</span></code> has been reworked and can now be used for both ESPnet1 and ESPnet2. The script calculates inference times based on time markers in the decoding log files and reports the average real-time-factor (RTF) and average latency over all decoded utterances. For ESPnet2, the script will automatically be run (see <a class="reference internal" href="#limitations"><span class="std std-ref">Limitations</span></a> section below) after the decoding stage has finished but can also be run as a stand-alone script:</p>
<section id="usage-1">
<h3>Usage<a class="headerlink" href="#usage-1" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">calculate_rtf</span><span class="o">.</span><span class="n">py</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">log</span><span class="o">-</span><span class="nb">dir</span> <span class="n">LOG_DIR</span><span class="p">]</span>
                        <span class="p">[</span><span class="o">--</span><span class="n">log</span><span class="o">-</span><span class="n">name</span> <span class="p">{</span><span class="n">decode</span><span class="p">,</span><span class="n">asr_inference</span><span class="p">}]</span>
                        <span class="p">[</span><span class="o">--</span><span class="nb">input</span><span class="o">-</span><span class="n">shift</span> <span class="n">INPUT_SHIFT</span><span class="p">]</span>
                        <span class="p">[</span><span class="o">--</span><span class="n">start</span><span class="o">-</span><span class="n">times</span><span class="o">-</span><span class="n">marker</span> <span class="p">{</span><span class="nb">input</span> <span class="n">lengths</span><span class="p">,</span><span class="n">speech</span> <span class="n">length</span><span class="p">}]</span>
                        <span class="p">[</span><span class="o">--</span><span class="n">end</span><span class="o">-</span><span class="n">times</span><span class="o">-</span><span class="n">marker</span> <span class="p">{</span><span class="n">prediction</span><span class="p">,</span><span class="n">best</span> <span class="n">hypo</span><span class="p">}]</span>

<span class="n">calculate</span> <span class="n">real</span> <span class="n">time</span> <span class="n">factor</span> <span class="p">(</span><span class="n">RTF</span><span class="p">)</span>

<span class="n">optional</span> <span class="n">arguments</span><span class="p">:</span>
  <span class="o">-</span><span class="n">h</span><span class="p">,</span> <span class="o">--</span><span class="n">help</span>            <span class="n">show</span> <span class="n">this</span> <span class="n">help</span> <span class="n">message</span> <span class="ow">and</span> <span class="n">exit</span>
  <span class="o">--</span><span class="n">log</span><span class="o">-</span><span class="nb">dir</span> <span class="n">LOG_DIR</span>     <span class="n">path</span> <span class="n">to</span> <span class="n">logging</span> <span class="n">directory</span>
  <span class="o">--</span><span class="n">log</span><span class="o">-</span><span class="n">name</span> <span class="p">{</span><span class="n">decode</span><span class="p">,</span><span class="n">asr_inference</span><span class="p">}</span>
                        <span class="n">name</span> <span class="n">of</span> <span class="n">logfile</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="p">,</span> <span class="s1">&#39;decode&#39;</span> <span class="p">(</span><span class="n">espnet1</span><span class="p">)</span> <span class="ow">and</span>
                        <span class="s1">&#39;asr_inference&#39;</span> <span class="p">(</span><span class="n">espnet2</span><span class="p">)</span>
  <span class="o">--</span><span class="nb">input</span><span class="o">-</span><span class="n">shift</span> <span class="n">INPUT_SHIFT</span>
                        <span class="n">shift</span> <span class="n">of</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">milliseconds</span>
  <span class="o">--</span><span class="n">start</span><span class="o">-</span><span class="n">times</span><span class="o">-</span><span class="n">marker</span> <span class="p">{</span><span class="nb">input</span> <span class="n">lengths</span><span class="p">,</span><span class="n">speech</span> <span class="n">length</span><span class="p">}</span>
                        <span class="n">String</span> <span class="n">marking</span> <span class="n">start</span> <span class="n">of</span> <span class="n">decoding</span> <span class="ow">in</span> <span class="n">logfile</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="p">,</span>
                        <span class="s1">&#39;input lengths&#39;</span> <span class="p">(</span><span class="n">espnet1</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39;speech length&#39;</span>
                        <span class="p">(</span><span class="n">espnet2</span><span class="p">)</span>
  <span class="o">--</span><span class="n">end</span><span class="o">-</span><span class="n">times</span><span class="o">-</span><span class="n">marker</span> <span class="p">{</span><span class="n">prediction</span><span class="p">,</span><span class="n">best</span> <span class="n">hypo</span><span class="p">}</span>
                        <span class="n">String</span> <span class="n">marking</span> <span class="n">end</span> <span class="n">of</span> <span class="n">decoding</span> <span class="ow">in</span> <span class="n">logfile</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="p">,</span>
                        <span class="s1">&#39;prediction&#39;</span> <span class="p">(</span><span class="n">espnet1</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39;best hypo&#39;</span> <span class="p">(</span><span class="n">espnet2</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="notes">
<h3>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Default settings still target ESPnet1 usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">log</span><span class="o">-</span><span class="n">name</span> <span class="s1">&#39;decode&#39;</span>
<span class="o">--</span><span class="nb">input</span><span class="o">-</span><span class="n">shift</span> <span class="mf">10.0</span>
<span class="o">--</span><span class="n">start</span><span class="o">-</span><span class="n">times</span><span class="o">-</span><span class="n">marker</span> <span class="s1">&#39;input lengths&#39;</span>
<span class="o">--</span><span class="n">end</span><span class="o">-</span><span class="n">times</span><span class="o">-</span><span class="n">marker</span> <span class="s1">&#39;prediction&#39;</span>
</pre></div>
</div>
</li>
<li><p>For ESPnet2, other frame shifts than 10ms are possible via different front-end/feature configurations. So different to ESPnet1, which logs the input feature frames at a fixed 10ms frame shift, in ESPnet2 the number of speech samples is logged instead and the audio sample shift in milliseconds (1/sampleRate x 1000) needs to be specified for <code class="docutils literal notranslate"><span class="pre">--input-shift</span></code> parameter (see <code class="docutils literal notranslate"><span class="pre">--input-shift</span> <span class="pre">0.0625</span></code> in example below for 16000 Hz sample rate).</p></li>
</ul>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>From <code class="docutils literal notranslate"><span class="pre">espnet/egs2/librispeech/asr1</span></code> the following call runs the decoding stage with pretrained ESPnet2 model:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>./run.sh<span class="w"> </span>--stage<span class="w"> </span><span class="m">12</span><span class="w">  </span>--use_streaming<span class="w"> </span><span class="nb">false</span><span class="w"> </span>--skip_data_prep<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--skip_train<span class="w"> </span><span class="nb">true</span><span class="w"> </span>--download_model<span class="w"> </span>byan/librispeech_asr_train_asr_conformer_raw_bpe_batch_bins30000000_accum_grad3_optim_conflr0.001_sp
</pre></div>
</div>
<p>Results for latency and rtf calculation on Librispeech test_clean subset can then be found in <code class="docutils literal notranslate"><span class="pre">espnet/egs2/librispeech/asr1/exp/byan/librispeech_asr_train_asr_conformer_raw_bpe_batch_bins30000000_accum_grad3_optim_conflr0.001_sp/decode_asr_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean/logdir/calculate_rtf.log</span></code> file:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1"># ../../../utils/calculate_rtf.py --log-dir exp/byan/librispeech_asr_train_asr_conformer_raw_bpe_batch_bins30000000_accum_grad3_optim_conflr0.001_sp/decode_as</span>
r_lm_lm_train_lm_transformer2_en_bpe5000_valid.loss.ave_asr_model_valid.acc.ave/test_clean/logdir<span class="w"> </span>--log-name<span class="w"> </span>asr_inference<span class="w"> </span>--input-shift<span class="w"> </span><span class="m">0</span>.0625<span class="w"> </span>--start-times-
marker<span class="w"> </span><span class="s2">&quot;speech length&quot;</span><span class="w"> </span>--end-times-marker<span class="w"> </span><span class="s2">&quot;best hypo&quot;</span>
Total<span class="w"> </span>audio<span class="w"> </span>duration:<span class="w"> </span><span class="m">19452</span>.481<span class="w"> </span><span class="o">[</span>sec<span class="o">]</span>
Total<span class="w"> </span>decoding<span class="w"> </span>time:<span class="w"> </span><span class="m">137762</span>.231<span class="w"> </span><span class="o">[</span>sec<span class="o">]</span>
RTF:<span class="w"> </span><span class="m">7</span>.082
Latency:<span class="w"> </span><span class="m">52581</span>.004<span class="w"> </span><span class="o">[</span>ms/sentence<span class="o">]</span>
</pre></div>
</div>
</section>
<section id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Only non-streaming inference mode is supported currently</p></li>
<li><p>The decoding stage 12 in <code class="docutils literal notranslate"><span class="pre">asr.sh</span></code> automatically runs the rtf &amp; latency calculation if <code class="docutils literal notranslate"><span class="pre">&quot;asr_inference_tool</span> <span class="pre">==</span> <span class="pre">&quot;espnet2.bin.asr_inference&quot;</span></code>; other inference tools like k2 &amp; maskctc are still left to do</p></li>
</ul>
</section>
</section>
<section id="transducer-asr">
<h2>Transducer ASR<a class="headerlink" href="#transducer-asr" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p><em><strong>Important</strong></em>: If you encounter any issue related to <code class="docutils literal notranslate"><span class="pre">warp-transducer</span></code>, please open an issue in <a class="reference external" href="https://github.com/b-flo/warp-transducer">our forked repo</a>.</p>
</div></blockquote>
<p>ESPnet2 supports models trained with the (RNN-)Tranducer loss, aka Transducer models. Currently, two versions of these models exist within ESPnet2: one under <code class="docutils literal notranslate"><span class="pre">asr</span></code> and the other under <code class="docutils literal notranslate"><span class="pre">asr_transducer</span></code>. The first one is designed as a supplement of CTC-Attention ASR models while the second is designed independently and purely for the Transducer task. For that, we rely on <code class="docutils literal notranslate"><span class="pre">ESPnetASRTransducerModel</span></code> instead of <code class="docutils literal notranslate"><span class="pre">ESPnetASRModel</span></code> and a new task called <code class="docutils literal notranslate"><span class="pre">ASRTransducerTask</span></code> is used in place of <code class="docutils literal notranslate"><span class="pre">ASRTask</span></code>.</p>
<p>For the user, it means two things. First, some features or modules may not be supported depending on the version used. Second, the usage of some common ASR features or modules may differ between the models. In addition, some core modules (e.g.: <code class="docutils literal notranslate"><span class="pre">preencoder</span></code> or <code class="docutils literal notranslate"><span class="pre">postencoder</span></code>) may be missing in the standalone version until validation.</p>
<p><em><strong>The following sections of this tutorial are dedicated to the introduction of the version under asr_transducer</strong></em>. Thus, the user should keep in mind that most features described here may not be available in the other version.</p>
<section id="general-usage">
<h3>General usage<a class="headerlink" href="#general-usage" title="Permalink to this headline">¶</a></h3>
<p>To enable Transducer model training or decoding in your experiments, the following option should be supplied to <code class="docutils literal notranslate"><span class="pre">asr.sh</span></code> in your <code class="docutils literal notranslate"><span class="pre">run.sh</span></code>:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>asr.sh<span class="w"> </span>--asr_task<span class="w"> </span>asr_transducer<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
</pre></div>
</div>
<p>For Transducer loss computation during training, we rely by default on a fork of <code class="docutils literal notranslate"><span class="pre">warp-transducer</span></code>. The installation procedure is described <a class="reference external" href="https://espnet.github.io/espnet/installation.html#step-3-optional-custom-tool-installation">here</a>.</p>
<p><strong>Note:</strong> We made available FastEmit regularization <a class="reference external" href="https://arxiv.org/pdf/2010.11148">[Yu et al., 2021]</a> during loss computation. To enable it, <code class="docutils literal notranslate"><span class="pre">fastemit_lambda</span></code> need to be set in <code class="docutils literal notranslate"><span class="pre">model_conf</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_conf</span><span class="p">:</span>
  <span class="n">fastemit_lambda</span><span class="p">:</span> <span class="n">Regularization</span> <span class="n">parameter</span> <span class="k">for</span> <span class="n">FastEmit</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
<p>Optionnaly, we also support training with the Pruned RNN-T loss <a class="reference external" href="https://arxiv.org/pdf/2206.13236.pdf">[Kuang et al. 2022]</a> made available in the <a class="reference external" href="https://github.com/k2-fsa/k2">k2</a> toolkit. To use it, the parameter <code class="docutils literal notranslate"><span class="pre">use_k2_pruned_loss</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">model_conf</span></code>. From here, the loss computation can be controlled by setting the following parameters through <code class="docutils literal notranslate"><span class="pre">k2_pruned_loss_args</span></code> in <code class="docutils literal notranslate"><span class="pre">model_conf</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_conf</span><span class="p">:</span>
  <span class="n">use_k2_pruned_loss</span><span class="p">:</span> <span class="kc">True</span>
  <span class="n">k2_pruned_loss_args</span><span class="p">:</span>
    <span class="n">prune_range</span><span class="p">:</span> <span class="n">How</span> <span class="n">many</span> <span class="n">tokens</span> <span class="n">by</span> <span class="n">frame</span> <span class="n">are</span> <span class="n">used</span> <span class="n">compute</span> <span class="n">the</span> <span class="n">pruned</span> <span class="n">loss</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">simple_loss_scaling</span><span class="p">:</span> <span class="n">The</span> <span class="n">weight</span> <span class="n">to</span> <span class="n">scale</span> <span class="n">the</span> <span class="n">simple</span> <span class="n">loss</span> <span class="n">after</span> <span class="n">warm</span><span class="o">-</span><span class="n">up</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">lm_scale</span><span class="p">:</span> <span class="n">The</span> <span class="n">scale</span> <span class="n">factor</span> <span class="n">to</span> <span class="n">smooth</span> <span class="n">the</span> <span class="n">LM</span> <span class="n">part</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">am_scale</span><span class="p">:</span> <span class="n">The</span> <span class="n">scale</span> <span class="n">factor</span> <span class="n">to</span> <span class="n">smooth</span> <span class="n">the</span> <span class="n">AM</span> <span class="n">part</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">loss_type</span><span class="p">:</span> <span class="n">Define</span> <span class="n">the</span> <span class="nb">type</span> <span class="n">of</span> <span class="n">path</span> <span class="n">to</span> <span class="n">take</span> <span class="k">for</span> <span class="n">loss</span> <span class="n">computation</span><span class="p">,</span> <span class="n">either</span> <span class="s1">&#39;regular&#39;</span><span class="p">,</span> <span class="s1">&#39;smoothed&#39;</span> <span class="ow">or</span> <span class="s1">&#39;constrained&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;regular&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Note:</strong> Because the number of tokens emitted by timestep can be restricted during training with this version, we also make available the parameter <code class="docutils literal notranslate"><span class="pre">validation_nstep</span></code>. It let the users apply similar constraints during the validation process, when reporting CER or/and WER:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_conf</span><span class="p">:</span>
  <span class="n">validation_nstep</span><span class="p">:</span> <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">symbol</span> <span class="n">expansions</span> <span class="n">at</span> <span class="n">each</span> <span class="n">time</span> <span class="n">step</span> <span class="n">when</span> <span class="n">reporting</span> <span class="n">CER</span> <span class="ow">or</span><span class="o">/</span><span class="ow">and</span> <span class="n">WER</span> <span class="n">using</span> <span class="n">mAES</span><span class="o">.</span>
</pre></div>
</div>
<p>For more information, see section Inference and “modified Adaptive Expansion Search” algorithm.</p>
</section>
<section id="architecture">
<h3>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h3>
<p>The architecture is composed of three modules: encoder, decoder and joint network. Each module has one (or three)  config(s) with various parameters in order to configure the internal parts. The following sections describe the mandatory and optional parameters for each module.</p>
<section id="encoder">
<h4>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline">¶</a></h4>
<p>For the encoder, we propose a unique encoder type encapsulating the following blocks: Branchformer, Conformer, Conv 1D and E-Branchformer.
It is similar to the custom encoder in ESPnet1, meaning we don’t need to set the parameter <code class="docutils literal notranslate"><span class="pre">encoder:</span> <span class="pre">[type]</span></code> here. Instead, the encoder architecture is defined by three configurations passed to <code class="docutils literal notranslate"><span class="pre">encoder_conf</span></code>:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_conf</span></code> (<strong>Dict</strong>): The configuration for the input block.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">main_conf</span></code> (<strong>Dict</strong>): The main configuration for the parameters shared across all blocks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">body_conf</span></code> (<strong>List[Dict]</strong>): The list of configurations for each block of the encoder architecture but the input block.</p></li>
</ol>
<p>The first and second configurations are optional. If needed, the following parameters can be modified in each configuration:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">main_conf</span><span class="p">:</span>
  <span class="n">pos_wise_act_type</span><span class="p">:</span> <span class="n">Conformer</span> <span class="n">position</span><span class="o">-</span><span class="n">wise</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">activation</span> <span class="nb">type</span><span class="o">.</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;swish&quot;</span><span class="p">)</span>
  <span class="n">conv_mod_act_type</span><span class="p">:</span> <span class="n">Conformer</span> <span class="n">convolution</span> <span class="n">module</span> <span class="n">activation</span> <span class="nb">type</span><span class="o">.</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;swish&quot;</span><span class="p">)</span>
  <span class="n">pos_enc_dropout_rate</span><span class="p">:</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">positional</span> <span class="n">encoding</span> <span class="n">layer</span><span class="p">,</span> <span class="k">if</span> <span class="n">used</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">pos_enc_max_len</span><span class="p">:</span> <span class="n">Positional</span> <span class="n">encoding</span> <span class="n">maximum</span> <span class="n">length</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span>
  <span class="n">simplified_att_score</span><span class="p">:</span> <span class="n">Whether</span> <span class="n">to</span> <span class="n">use</span> <span class="n">simplified</span> <span class="n">attention</span> <span class="n">score</span> <span class="n">computation</span><span class="o">.</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
  <span class="n">norm_type</span><span class="p">:</span> <span class="n">X</span><span class="o">-</span><span class="n">former</span> <span class="n">normalization</span> <span class="n">module</span> <span class="nb">type</span><span class="o">.</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;layer_norm&quot;</span><span class="p">)</span>
  <span class="n">conv_mod_norm_type</span><span class="p">:</span> <span class="n">Branchformer</span> <span class="n">convolution</span> <span class="n">module</span> <span class="n">normalization</span> <span class="nb">type</span><span class="o">.</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;layer_norm&quot;</span><span class="p">)</span>
  <span class="n">after_norm_eps</span><span class="p">:</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">final</span> <span class="n">normalization</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span> <span class="ow">or</span> <span class="mf">0.25</span> <span class="k">for</span> <span class="n">BasicNorm</span><span class="p">)</span>
  <span class="n">after_norm_partial</span><span class="p">:</span> <span class="n">Partial</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">final</span> <span class="n">normalization</span> <span class="n">module</span><span class="p">,</span> <span class="k">if</span> <span class="n">norm_type</span> <span class="o">=</span> <span class="s1">&#39;rms_norm&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">blockdrop_rate</span><span class="p">:</span> <span class="n">Probability</span> <span class="n">threshold</span> <span class="n">of</span> <span class="n">dropping</span> <span class="n">out</span> <span class="n">each</span> <span class="n">encoder</span> <span class="n">block</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="c1"># For more information on the parameters below, please refer to espnet2/asr_transducer/activation.py</span>
  <span class="n">ftswish_threshold</span><span class="p">:</span> <span class="n">Threshold</span> <span class="n">value</span> <span class="k">for</span> <span class="n">FTSwish</span> <span class="n">activation</span> <span class="n">formulation</span><span class="o">.</span>
  <span class="n">ftswish_mean_shift</span><span class="p">:</span> <span class="n">Mean</span> <span class="n">shifting</span> <span class="n">value</span> <span class="k">for</span> <span class="n">FTSwish</span> <span class="n">activation</span> <span class="n">formulation</span><span class="o">.</span>
  <span class="n">hardtanh_min_val</span><span class="p">:</span> <span class="n">Minimum</span> <span class="n">value</span> <span class="n">of</span> <span class="n">the</span> <span class="n">linear</span> <span class="n">region</span> <span class="nb">range</span> <span class="k">for</span> <span class="n">HardTanh</span> <span class="n">activation</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">hardtanh_max_val</span><span class="p">:</span> <span class="n">Maximum</span> <span class="n">value</span> <span class="n">of</span> <span class="n">the</span> <span class="n">linear</span> <span class="n">region</span> <span class="nb">range</span> <span class="k">for</span> <span class="n">HardTanh</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">leakyrelu_neg_slope</span><span class="p">:</span> <span class="n">Negative</span> <span class="n">slope</span> <span class="n">value</span> <span class="k">for</span> <span class="n">LeakyReLU</span> <span class="n">activation</span> <span class="n">formulation</span><span class="o">.</span>
  <span class="n">smish_alpha</span><span class="p">:</span> <span class="n">Alpha</span> <span class="n">value</span> <span class="k">for</span> <span class="n">Smish</span> <span class="n">variant</span> <span class="n">activation</span> <span class="n">fomulation</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">smish_beta</span><span class="p">:</span> <span class="n">Beta</span> <span class="n">value</span> <span class="k">for</span> <span class="n">Smish</span> <span class="n">variant</span> <span class="n">activation</span> <span class="n">formulation</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">softplus_beta</span><span class="p">:</span> <span class="n">Beta</span> <span class="n">value</span> <span class="k">for</span> <span class="n">softplus</span> <span class="n">activation</span> <span class="n">formulation</span> <span class="ow">in</span> <span class="n">Mish</span> <span class="n">activation</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">softplus_threshold</span><span class="p">:</span> <span class="n">Values</span> <span class="n">above</span> <span class="n">this</span> <span class="n">revert</span> <span class="n">to</span> <span class="n">a</span> <span class="n">linear</span> <span class="n">function</span> <span class="ow">in</span> <span class="n">Mish</span> <span class="n">activation</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
  <span class="n">swish_beta</span><span class="p">:</span> <span class="n">Beta</span> <span class="n">value</span> <span class="k">for</span> <span class="n">E</span><span class="o">-</span><span class="n">Swish</span> <span class="n">activation</span> <span class="n">formulation</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">input_conf</span><span class="p">:</span>
  <span class="n">block_type</span><span class="p">:</span> <span class="n">Input</span> <span class="n">block</span> <span class="nb">type</span><span class="p">,</span> <span class="n">either</span> <span class="s2">&quot;conv2d&quot;</span> <span class="ow">or</span> <span class="s2">&quot;vgg&quot;</span><span class="o">.</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;conv2d&quot;</span><span class="p">)</span>
  <span class="n">conv_size</span><span class="p">:</span> <span class="n">Convolution</span> <span class="n">output</span> <span class="n">size</span><span class="o">.</span> <span class="n">For</span> <span class="s2">&quot;vgg&quot;</span><span class="p">,</span> <span class="n">the</span> <span class="n">two</span> <span class="n">convolution</span> <span class="n">outputs</span> <span class="n">can</span> <span class="n">be</span> <span class="n">controlled</span> <span class="n">by</span> <span class="n">passing</span> <span class="n">a</span> <span class="nb">tuple</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">256</span><span class="p">)</span>
  <span class="n">subsampling_factor</span><span class="p">:</span> <span class="n">Subsampling</span> <span class="n">factor</span> <span class="n">of</span> <span class="n">the</span> <span class="nb">input</span> <span class="n">block</span><span class="p">,</span> <span class="n">either</span> <span class="mi">2</span> <span class="p">(</span><span class="n">only</span> <span class="n">conv2d</span><span class="p">),</span> <span class="mi">4</span> <span class="ow">or</span> <span class="mf">6.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>The only mandatory configuration is <code class="docutils literal notranslate"><span class="pre">body_conf</span></code>, defining the encoder body architecture block by block. Each block has its own set of mandatory and optional parameters depending on the type, defined by <code class="docutils literal notranslate"><span class="pre">block_type</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Branchformer</span>
<span class="o">-</span> <span class="n">block_type</span><span class="p">:</span> <span class="n">branchformer</span>
  <span class="n">hidden_size</span><span class="p">:</span> <span class="n">Hidden</span> <span class="p">(</span><span class="ow">and</span> <span class="n">output</span><span class="p">)</span> <span class="n">dimension</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">linear_size</span><span class="p">:</span> <span class="n">Dimension</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Linear</span> <span class="n">layers</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">conv_mod_kernel_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">convolving</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">ConvolutionalSpatialGatingUnit</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">heads</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">heads</span> <span class="ow">in</span> <span class="n">multi</span><span class="o">-</span><span class="n">head</span> <span class="n">attention</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
  <span class="n">norm_eps</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">normalization</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span> <span class="ow">or</span> <span class="mf">0.25</span> <span class="k">for</span> <span class="n">BasicNorm</span><span class="p">)</span>
  <span class="n">norm_partial</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Partial</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">normalization</span> <span class="n">module</span><span class="p">,</span> <span class="k">if</span> <span class="n">norm_type</span> <span class="o">=</span> <span class="s1">&#39;rms_norm&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">conv_mod_norm_eps</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">ConvolutionalSpatialGatingUnit</span> <span class="n">module</span> <span class="n">normalization</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span> <span class="ow">or</span> <span class="mf">0.25</span> <span class="k">for</span> <span class="n">BasicNorm</span><span class="p">)</span>
  <span class="n">conv_mod_norm_partial</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Partial</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">ConvolutionalSpatialGatingUnit</span> <span class="n">module</span> <span class="n">normalization</span><span class="p">,</span> <span class="k">if</span> <span class="n">conv_norm_type</span> <span class="o">=</span> <span class="s1">&#39;rms_norm&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">some</span> <span class="n">intermediate</span> <span class="n">layers</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">att_dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">attention</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Conformer</span>
<span class="o">-</span> <span class="n">block_type</span><span class="p">:</span> <span class="n">conformer</span>
  <span class="n">hidden_size</span><span class="p">:</span> <span class="n">Hidden</span> <span class="p">(</span><span class="ow">and</span> <span class="n">output</span><span class="p">)</span> <span class="n">dimension</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">linear_size</span><span class="p">:</span> <span class="n">Dimension</span> <span class="n">of</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">conv_mod_kernel_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">convolving</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">ConformerConvolution</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">heads</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">heads</span> <span class="ow">in</span> <span class="n">multi</span><span class="o">-</span><span class="n">head</span> <span class="n">attention</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
  <span class="n">norm_eps</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">normalization</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span> <span class="ow">or</span> <span class="mf">0.25</span> <span class="k">for</span> <span class="n">BasicNorm</span><span class="p">)</span>
  <span class="n">norm_partial</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Partial</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">normalization</span> <span class="n">module</span><span class="p">,</span> <span class="k">if</span> <span class="n">norm_type</span> <span class="o">=</span> <span class="s1">&#39;rms_norm&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">conv_mod_norm_eps</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">Batchnorm1d</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">ConformerConvolution</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span><span class="p">)</span>
  <span class="n">conv_mod_norm_momentum</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Momentum</span> <span class="n">value</span> <span class="k">for</span> <span class="n">Batchnorm1d</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">ConformerConvolution</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
  <span class="n">dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">some</span> <span class="n">intermediate</span> <span class="n">layers</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">att_dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">attention</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">pos_wise_dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">position</span><span class="o">-</span><span class="n">wise</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># Conv 1D</span>
<span class="o">-</span> <span class="n">block_type</span><span class="p">:</span> <span class="n">conv1d</span>
  <span class="n">output_size</span><span class="p">:</span> <span class="n">Output</span> <span class="n">size</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">convolving</span> <span class="n">kernel</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span> <span class="ow">or</span> <span class="n">Tuple</span><span class="p">)</span>
  <span class="n">stride</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Stride</span> <span class="n">of</span> <span class="n">the</span> <span class="n">sliding</span> <span class="n">blocks</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">dilation</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Parameter</span> <span class="n">to</span> <span class="n">control</span> <span class="n">the</span> <span class="n">stride</span> <span class="n">of</span> <span class="n">elements</span> <span class="n">within</span> <span class="n">the</span> <span class="n">neighborhood</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">groups</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">blocked</span> <span class="n">connections</span> <span class="kn">from</span> <span class="nn">input</span> <span class="n">channels</span> <span class="n">to</span> <span class="n">output</span> <span class="n">channels</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">bias</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Whether</span> <span class="n">to</span> <span class="n">add</span> <span class="n">a</span> <span class="n">learnable</span> <span class="n">bias</span> <span class="n">to</span> <span class="n">the</span> <span class="n">output</span><span class="o">.</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="n">relu</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Whether</span> <span class="n">to</span> <span class="n">use</span> <span class="n">a</span> <span class="n">ReLU</span> <span class="n">activation</span> <span class="n">after</span> <span class="n">convolution</span><span class="o">.</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
  <span class="n">batch_norm</span><span class="p">:</span> <span class="n">Whether</span> <span class="n">to</span> <span class="n">use</span> <span class="n">batch</span> <span class="n">normalization</span> <span class="n">after</span> <span class="n">convolution</span><span class="o">.</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
  <span class="n">dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">Conv1d</span> <span class="n">outputs</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="c1"># E-Branchformer</span>
<span class="o">-</span> <span class="n">block_type</span><span class="p">:</span> <span class="n">ebranchformer</span>
  <span class="n">hidden_size</span><span class="p">:</span> <span class="n">Hidden</span> <span class="p">(</span><span class="ow">and</span> <span class="n">output</span><span class="p">)</span> <span class="n">dimension</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">linear_size</span><span class="p">:</span> <span class="n">Dimension</span> <span class="n">of</span> <span class="n">the</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">module</span> <span class="ow">and</span> <span class="n">othger</span> <span class="n">linear</span> <span class="n">layers</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">conv_mod_kernel_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">convolving</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">ConvolutionalSpatialGatingUnit</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>
  <span class="n">depthwise_conv_kernel_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">convolving</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">DepthwiseConvolution</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="n">conv_mod_kernel_size</span><span class="p">)</span>
  <span class="n">heads</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">heads</span> <span class="ow">in</span> <span class="n">multi</span><span class="o">-</span><span class="n">head</span> <span class="n">attention</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
  <span class="n">norm_eps</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">normalization</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span> <span class="ow">or</span> <span class="mf">0.25</span> <span class="k">for</span> <span class="n">BasicNorm</span><span class="p">)</span>
  <span class="n">norm_partial</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Partial</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">normalization</span> <span class="n">module</span><span class="p">,</span> <span class="k">if</span> <span class="n">norm_type</span> <span class="o">=</span> <span class="s1">&#39;rms_norm&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">conv_mod_norm_eps</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Epsilon</span> <span class="n">value</span> <span class="k">for</span> <span class="n">ConvolutionalSpatialGatingUnit</span> <span class="n">module</span> <span class="n">normalization</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1e-05</span> <span class="ow">or</span> <span class="mf">0.25</span> <span class="k">for</span> <span class="n">BasicNorm</span><span class="p">)</span>
  <span class="n">conv_mod_norm_partial</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Partial</span> <span class="n">value</span> <span class="k">for</span> <span class="n">the</span> <span class="n">ConvolutionalSpatialGatingUnit</span> <span class="n">module</span> <span class="n">normalization</span><span class="p">,</span> <span class="k">if</span> <span class="n">conv_norm_type</span> <span class="o">=</span> <span class="s1">&#39;rms_norm&#39;</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="n">dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">some</span> <span class="n">intermediate</span> <span class="n">layers</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">att_dropout_rate</span> <span class="p">(</span><span class="n">optional</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">attention</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
<p>In addition, each block has a parameter <code class="docutils literal notranslate"><span class="pre">num_blocks</span></code> to build <strong>N</strong> times the defined block (int, default = 1). This is useful if you want to use a group of blocks sharing the same parameters without writing each configuration.</p>
<p><strong>Example 1: conv 2D + 2x Conv 1D + 14x Conformer.</strong></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">encoder_conf</span><span class="p">:</span>
<span class="w">    </span><span class="nt">main_conf</span><span class="p">:</span>
<span class="w">      </span><span class="nt">pos_wise_act_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">swish</span>
<span class="w">      </span><span class="nt">pos_enc_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">      </span><span class="nt">conv_mod_act_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">swish</span>
<span class="w">    </span><span class="nt">input_conf</span><span class="p">:</span>
<span class="w">      </span><span class="nt">block_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conv2d</span>
<span class="w">      </span><span class="nt">conv_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">      </span><span class="nt">subsampling_factor</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">body_conf</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">block_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conv1d</span>
<span class="w">      </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">      </span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">block_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conv1d</span>
<span class="w">      </span><span class="nt">output_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">      </span><span class="nt">kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">block_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conformer</span>
<span class="w">      </span><span class="nt">linear_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">      </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">      </span><span class="nt">heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">      </span><span class="nt">dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">      </span><span class="nt">pos_wise_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">      </span><span class="nt">att_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">      </span><span class="nt">conv_mod_kernel_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">31</span>
<span class="w">      </span><span class="nt">num_blocks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">14</span>
</pre></div>
</div>
</section>
<section id="decoder">
<h4>Decoder<a class="headerlink" href="#decoder" title="Permalink to this headline">¶</a></h4>
<p>For the decoder, four types of blocks are available: stateless (’stateless’), RNN (’rnn’), MEGA (’mega’) or RWKV (’rwkv’). Contrary to the encoder, the parameters are shared across the blocks, meaning we only define one block in the configuration.
The type of the stack of blocks is defined by passing the corresponding type string to the parameter <code class="docutils literal notranslate"><span class="pre">decoder</span></code>. The internal parts are defined through the field <code class="docutils literal notranslate"><span class="pre">decoder_conf</span></code> containing the following controlable parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">decoder_conf</span><span class="p">:</span>
  <span class="n">embed_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">embedding</span> <span class="n">layer</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">256</span><span class="p">)</span><span class="o">.</span>
  <span class="n">num_blocks</span><span class="p">:</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">decoder</span> <span class="n">blocks</span><span class="o">/</span><span class="n">layers</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">4</span> <span class="k">for</span> <span class="n">MEGA</span> <span class="ow">or</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">RNN</span><span class="p">)</span><span class="o">.</span>
  <span class="n">rnn_type</span> <span class="p">(</span><span class="n">RNN</span> <span class="n">only</span><span class="p">):</span> <span class="n">Type</span> <span class="n">of</span> <span class="n">RNN</span> <span class="n">cells</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;lstm&quot;</span><span class="p">)</span><span class="o">.</span>
  <span class="n">hidden_size</span> <span class="p">(</span><span class="n">RNN</span> <span class="n">only</span><span class="p">):</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hidden</span> <span class="n">layers</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">256</span><span class="p">)</span><span class="o">.</span>
  <span class="n">block_size</span> <span class="p">(</span><span class="n">MEGA</span><span class="o">/</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">block</span><span class="s1">&#39;s input/output (int, default = 512).</span>
  <span class="n">linear_size</span> <span class="p">(</span><span class="n">MEGA</span><span class="o">/</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Feed</span><span class="o">-</span><span class="n">Forward</span> <span class="n">module</span> <span class="n">hidden</span> <span class="n">size</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">)</span><span class="o">.</span>
  <span class="n">attention_size</span> <span class="p">(</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Hidden</span><span class="o">-</span><span class="n">size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">attention</span> <span class="n">module</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span>
  <span class="n">context_size</span> <span class="p">(</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Context</span> <span class="n">size</span> <span class="k">for</span> <span class="n">the</span> <span class="n">WKV</span> <span class="n">kernel</span> <span class="n">module</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">)</span><span class="o">.</span>
  <span class="n">qk_size</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Shared</span> <span class="n">query</span> <span class="ow">and</span> <span class="n">key</span> <span class="n">size</span> <span class="k">for</span> <span class="n">attention</span> <span class="n">module</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">128</span><span class="p">)</span><span class="o">.</span>
  <span class="n">v_size</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Value</span> <span class="n">size</span> <span class="k">for</span> <span class="n">attention</span> <span class="n">module</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">)</span><span class="o">.</span>
  <span class="n">chunk_size</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Chunk</span> <span class="n">size</span> <span class="k">for</span> <span class="n">attention</span> <span class="n">computation</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">.</span><span class="n">e</span><span class="o">.</span> <span class="n">full</span> <span class="n">context</span><span class="p">)</span><span class="o">.</span>
  <span class="n">num_heads</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">EMA</span> <span class="n">heads</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span>
  <span class="n">rel_pos_bias</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Type</span> <span class="n">of</span> <span class="n">relative</span> <span class="n">position</span> <span class="n">bias</span> <span class="ow">in</span> <span class="n">attention</span> <span class="n">module</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;simple&quot;</span><span class="p">)</span><span class="o">.</span>
  <span class="n">max_positions</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">position</span> <span class="k">for</span> <span class="n">RelativePositionBias</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">)</span><span class="o">.</span>
  <span class="n">truncation_length</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Maximum</span> <span class="n">length</span> <span class="k">for</span> <span class="n">truncation</span> <span class="ow">in</span> <span class="n">EMA</span> <span class="n">module</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span>
  <span class="n">normalization_type</span> <span class="p">(</span><span class="n">MEGA</span><span class="o">/</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Normalization</span> <span class="n">layer</span> <span class="nb">type</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;layer_norm&quot;</span><span class="p">)</span><span class="o">.</span>
  <span class="n">normalization_args</span> <span class="p">(</span><span class="n">MEGA</span><span class="o">/</span><span class="n">RKWV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Normalization</span> <span class="n">layer</span> <span class="n">arguments</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="p">{})</span><span class="o">.</span>
  <span class="n">activation_type</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Activation</span> <span class="n">function</span> <span class="nb">type</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;swish&quot;</span><span class="p">)</span><span class="o">.</span>
  <span class="n">activation_args</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Activation</span> <span class="n">function</span> <span class="n">arguments</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="p">{})</span><span class="o">.</span>
  <span class="n">rescale_every</span> <span class="p">(</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Whether</span> <span class="n">to</span> <span class="n">rescale</span> <span class="nb">input</span> <span class="n">every</span> <span class="n">N</span> <span class="n">blocks</span> <span class="n">during</span> <span class="n">inference</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">dropout_rate</span> <span class="p">(</span><span class="n">excl</span><span class="o">.</span> <span class="n">RWKV</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">main</span> <span class="n">block</span> <span class="n">modules</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span>
  <span class="n">embed_dropout_rate</span><span class="p">:</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">embedding</span> <span class="n">layer</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span>
  <span class="n">att_dropout_rate</span> <span class="p">(</span><span class="n">MEGA</span><span class="o">/</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">attention</span> <span class="n">module</span><span class="o">.</span>
  <span class="n">ema_dropout_rate</span> <span class="p">(</span><span class="n">MEGA</span> <span class="n">only</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">EMA</span> <span class="n">module</span><span class="o">.</span>
  <span class="n">ffn_dropout_rate</span> <span class="p">(</span><span class="n">MEGA</span><span class="o">/</span><span class="n">RWKV</span> <span class="n">only</span><span class="p">):</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">feed</span><span class="o">-</span><span class="n">forward</span> <span class="n">module</span><span class="o">.</span>
</pre></div>
</div>
<p><strong>Example 1: RNN decoder.</strong></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rnn</span>
<span class="nt">decoder_conf</span><span class="p">:</span>
<span class="w">    </span><span class="nt">rnn_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">lstm</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">    </span><span class="nt">embed_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">embed_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
<p><strong>Example 2: MEGA decoder.</strong></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mega</span>
<span class="nt">decoder_conf</span><span class="p">:</span>
<span class="w">    </span><span class="nt">block_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">linear_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048</span>
<span class="w">    </span><span class="nt">qk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">v_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">max_positions</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1024</span>
<span class="w">    </span><span class="nt">num_heads</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">rel_pos_bias_type</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;rotary&quot;</span>
<span class="w">    </span><span class="nt">chunk_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">num_blocks</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">6</span>
<span class="w">    </span><span class="nt">dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">ffn_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">att_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">embed_dropout_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>
</div>
</section>
<section id="joint-network">
<h4>Joint network<a class="headerlink" href="#joint-network" title="Permalink to this headline">¶</a></h4>
<p>Currently, we only propose the standard joint network module composed of three linear layers and an activation function. The module definition is optional but the following parameters can be modified through the configuration parameter <code class="docutils literal notranslate"><span class="pre">joint_network_conf</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">joint_network_conf</span><span class="p">:</span>
  <span class="n">joint_space_size</span><span class="p">:</span> <span class="n">Size</span> <span class="n">of</span> <span class="n">the</span> <span class="n">joint</span> <span class="n">space</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">256</span><span class="p">)</span><span class="o">.</span>
  <span class="n">joint_act_type</span><span class="p">:</span> <span class="n">Type</span> <span class="n">of</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">joint</span> <span class="n">network</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s2">&quot;tanh&quot;</span><span class="p">)</span><span class="o">.</span>
</pre></div>
</div>
<p>The options related to the activation functions can also be modified through the parameters introduced in the Encoder section (See <code class="docutils literal notranslate"><span class="pre">main_conf</span></code> description).</p>
</section>
</section>
<section id="multi-task-learning">
<h3>Multi-task learning<a class="headerlink" href="#multi-task-learning" title="Permalink to this headline">¶</a></h3>
<p>We also support multi-task learning with two auxiliary tasks: CTC and cross-entropy w/ label smoothing option (called LM loss here). The auxiliary tasks contribute to the overal task defined as:</p>
<p><strong>L_tot = (λ_trans x L_trans) + (λ_auxCTC x L_auxCTC) + (λ_auxLM x L_auxLM)</strong></p>
<p>where the losses (L_*) are respectively, in order: The Transducer loss, the CTC loss and the LM loss. Lambda values define their respective contribution to the total loss. Each task can be parameterized using the following options, passed to <code class="docutils literal notranslate"><span class="pre">model_conf</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_conf</span><span class="p">:</span>
  <span class="n">transducer_weight</span><span class="p">:</span> <span class="n">Weight</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Transducer</span> <span class="n">loss</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">auxiliary_ctc_weight</span><span class="p">:</span> <span class="n">Weight</span> <span class="n">of</span> <span class="n">the</span> <span class="n">CTC</span> <span class="n">loss</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">auxiliary_ctc_dropout_rate</span><span class="p">:</span> <span class="n">Dropout</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">the</span> <span class="n">CTC</span> <span class="n">loss</span> <span class="n">inputs</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
  <span class="n">auxiliary_lm_loss_weight</span><span class="p">:</span> <span class="n">Weight</span> <span class="n">of</span> <span class="n">the</span> <span class="n">LM</span> <span class="n">loss</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
  <span class="n">auxiliary_lm_loss_smoothing</span><span class="p">:</span> <span class="n">Smoothing</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">LM</span> <span class="n">loss</span><span class="o">.</span> <span class="n">If</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span> <span class="n">smoothing</span> <span class="ow">is</span> <span class="n">enabled</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Note:</strong> We do not support other auxiliary tasks in ESPnet2 yet.</p>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h3>
<p>Various decoding algorithms are also available for Transducer by setting <code class="docutils literal notranslate"><span class="pre">search_type</span></code> parameter in your decode config:</p>
<ul class="simple">
<li><p>Beam search algorithm without prefix search <a class="reference external" href="https://arxiv.org/pdf/1211.3711.pdf">[Graves, 2012]</a>. (<code class="docutils literal notranslate"><span class="pre">search_type:</span> <span class="pre">default</span></code>)</p></li>
<li><p>Time Synchronous Decoding <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9053040">[Saon et al., 2020]</a>. (<code class="docutils literal notranslate"><span class="pre">search_type:</span> <span class="pre">tsd</span></code>)</p></li>
<li><p>Alignment-Length Synchronous Decoding <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9053040">[Saon et al., 2020]</a>. (<code class="docutils literal notranslate"><span class="pre">search_type:</span> <span class="pre">alsd</span></code>)</p></li>
<li><p>modified Adaptive Expansion Search, based on <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9250505">[Kim et al., 2021]</a> and <a class="reference external" href="https://arxiv.org/pdf/2201.05420.pdf">[Boyer et al., 2021]</a>. (<code class="docutils literal notranslate"><span class="pre">search_type:</span> <span class="pre">maes</span></code>)</p></li>
</ul>
<p>The algorithms share two parameters to control the beam size (<code class="docutils literal notranslate"><span class="pre">beam_size</span></code>) and the partial/final hypotheses normalization (<code class="docutils literal notranslate"><span class="pre">score_norm</span></code>). In addition, three algorithms have specific parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Time-synchronous decoding</span>
<span class="n">search_type</span><span class="p">:</span> <span class="n">tsd</span>
<span class="n">max_sym_exp</span> <span class="p">:</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">maximum</span> <span class="n">symbol</span> <span class="n">expansions</span> <span class="n">at</span> <span class="n">each</span> <span class="n">time</span> <span class="n">step</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Alignement-Length Synchronous decoding</span>
<span class="n">search_type</span><span class="p">:</span> <span class="n">alsd</span>
<span class="n">u_max</span><span class="p">:</span> <span class="n">Maximum</span> <span class="n">expected</span> <span class="n">target</span> <span class="n">sequence</span> <span class="n">length</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># modified Adaptive Expansion Search</span>
<span class="n">search_type</span><span class="p">:</span> <span class="n">maes</span>
<span class="n">nstep</span><span class="p">:</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">maximum</span> <span class="n">expansion</span> <span class="n">steps</span> <span class="n">at</span> <span class="n">each</span> <span class="n">time</span> <span class="n">step</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">expansion_gamma</span><span class="p">:</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">additional</span> <span class="n">candidates</span> <span class="ow">in</span> <span class="n">expanded</span> <span class="n">hypotheses</span> <span class="n">selection</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">expansion_beta</span><span class="p">:</span> <span class="n">Allowed</span> <span class="n">logp</span> <span class="n">difference</span> <span class="k">for</span> <span class="n">prune</span><span class="o">-</span><span class="n">by</span><span class="o">-</span><span class="n">value</span> <span class="n">method</span><span class="o">.</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mf">2.3</span><span class="p">)</span>
</pre></div>
</div>
<p><em><strong>Note:</strong></em> Except for the default algorithm, the described parameters are used to control the performance and decoding speed. The optimal values for each parameter are task-dependent; a high value will typically increase decoding time to focus on performance while a low value will improve decoding time at the expense of performance.</p>
<p><em><strong>Note 2:</strong></em> The algorithms in the standalone version are the same as the one in the other version.. However, due to design choices, some parts were reworked and minor optimizations were added in the same time.</p>
</section>
<section id="streaming">
<h3>Streaming<a class="headerlink" href="#streaming" title="Permalink to this headline">¶</a></h3>
<p>To enable streaming capabilities for Transducer models, we support dynamic chunk training and chunk-by-chunk decoding as proposed in <a class="reference external" href="https://arxiv.org/pdf/2012.05481.pdf">[Zhang et al., 2021]</a>. Our implementation is based on the version proposed in <a class="reference external" href="https://github.com/k2-fsa/icefall/">Icefall</a>, based itself on the original <a class="reference external" href="https://github.com/wenet-e2e/wenet/">WeNet</a> one.</p>
<p>For a complete explanation on the different procedure and parameters, we refer the reader to the corresponding paper.</p>
<section id="training-1">
<h4>Training<a class="headerlink" href="#training-1" title="Permalink to this headline">¶</a></h4>
<p>To train a streaming model, the parameter <code class="docutils literal notranslate"><span class="pre">dynamic_chunk_training</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">main_conf</span></code> (See section <a class="reference external" href="https://github.com/espnet/espnet/blob/master/doc/espnet2_tutorial.md#encoder">Encoder</a>. From here, the user has access to two parameters in order to control the dynamic chunk selection (<code class="docutils literal notranslate"><span class="pre">short_chunk_threshold</span></code> and <code class="docutils literal notranslate"><span class="pre">short_chunk_size</span></code>) and another one to control the left context in the causal convolution and the attention module (<code class="docutils literal notranslate"><span class="pre">num_left_chunks</span></code>).</p>
<p>All these parameters can be configured through <code class="docutils literal notranslate"><span class="pre">main_conf</span></code>, introduced in the Encoder section:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>dynamic_chunk_training: Whether to train streaming model with dynamic chunks. (bool, default = False)
short_chunk_threshold: Chunk length threshold (in percent) for dynamic chunk selection. (int, default = 0.75)
short_chunk_size: Minimum number of frames during dynamic chunk training. (int, default = 25)
num_left_chunks: The number of left chunks the attention module can see during training, where the actual size is defined by `short_chunk_threshold` and `short_chunk_size`. (int, default = 0, i.e. full context)
</pre></div>
</div>
</section>
<section id="decoding-1">
<h4>Decoding<a class="headerlink" href="#decoding-1" title="Permalink to this headline">¶</a></h4>
<p>To perform chunk-by-chunk inference, the parameter <code class="docutils literal notranslate"><span class="pre">streaming</span></code> should be set to True in the decoding configuration (otherwise, offline decoding will be performed). Two parameters are available to control the decoding process:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">decoding_window</span><span class="p">:</span> <span class="n">The</span> <span class="nb">input</span> <span class="n">audio</span> <span class="n">length</span><span class="p">,</span> <span class="ow">in</span> <span class="n">milliseconds</span><span class="p">,</span> <span class="n">to</span> <span class="n">process</span> <span class="n">during</span> <span class="n">decoding</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">640</span><span class="p">)</span>
<span class="n">left_context</span><span class="p">:</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">previous</span> <span class="n">frames</span> <span class="p">(</span><span class="n">AFTER</span> <span class="n">subsampling</span><span class="p">)</span> <span class="n">the</span> <span class="n">attention</span> <span class="n">module</span> <span class="n">can</span> <span class="n">see</span> <span class="ow">in</span> <span class="n">current</span> <span class="n">chunk</span><span class="o">.</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
<p><em><strong>Note:</strong></em> All search algorithms but ALSD are available with chunk-by-chunk inference.</p>
</section>
</section>
<section id="faq-1">
<h3>FAQ<a class="headerlink" href="#faq-1" title="Permalink to this headline">¶</a></h3>
<section id="how-to-add-a-new-block-type-to-the-custom-encoder">
<h4>How to add a new block type to the custom encoder?<a class="headerlink" href="#how-to-add-a-new-block-type-to-the-custom-encoder" title="Permalink to this headline">¶</a></h4>
<p><em><strong>Provided paths are relative to the directory: <code class="docutils literal notranslate"><span class="pre">espnet2/asr_transducer/encoder/</span></code></strong></em></p>
<p>Adding support to a new block type can be achieved in three main steps:</p>
<ol class="simple">
<li><p>Write your need block class in <code class="docutils literal notranslate"><span class="pre">encoder/blocks/</span></code>. The class should have the following methods: <code class="docutils literal notranslate"><span class="pre">__init__(...)</span></code>, <code class="docutils literal notranslate"><span class="pre">forward(...)</span></code> (training + offline), <code class="docutils literal notranslate"><span class="pre">chunk_forward(...)</span></code> (online decoding), <code class="docutils literal notranslate"><span class="pre">reset_streaming_cache(...)</span></code> (online cache definition). For more details on implementing internal parts, we refer the user to the existing block definition and the Streaming section.</p></li>
<li><p>In <code class="docutils literal notranslate"><span class="pre">building.py</span></code>, write a block constructor method and add a new condition in <code class="docutils literal notranslate"><span class="pre">build_body_blocks(...)</span></code> for your block type, calling the constructor method. If you need additional parameters to share  across blocks, you can add them in <code class="docutils literal notranslate"><span class="pre">build_main_parameters(...)</span></code> and pass <code class="docutils literal notranslate"><span class="pre">main_conf</span></code> to your constructor.</p></li>
<li><p>In <code class="docutils literal notranslate"><span class="pre">validation.py</span></code>, add new conditions to `validate_block_arguments(…) in order to set and validate the mandatory block parameters before building (if not already covered).</p></li>
</ol>
<p>For additional information or examples, please refer to the named files. If you need to add other classes related to the new block, they should be added within the block class or in <code class="docutils literal notranslate"><span class="pre">modules/</span></code>.</p>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="espnet1_tutorial.html" class="btn btn-neutral float-left" title="Usage" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="espnet2_training_option.html" class="btn btn-neutral float-right" title="Change the configuration for training" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2017, Shinji Watanabe.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>